{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PxtlzpwkvEwL"
      },
      "outputs": [],
      "source": [
        "import nltk\n",
        "from nltk import tokenize\n",
        "from operator import itemgetter\n",
        "import math"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9Z9a1o4i8ANs",
        "outputId": "8e52b142-8473-4597-92a6-e529fe84f220"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b6Dt9QJsvEwN",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 218
        },
        "outputId": "2ee74678-f671-4bb8-f9c3-654fdcdde9e8"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-cc05f0b87d83>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mfile\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'doc.txt'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'utf8'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0moriginal\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# doc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'doc.txt'"
          ]
        }
      ],
      "source": [
        "file = open('doc.txt', encoding='utf8')\n",
        "\n",
        "original = file.read()\n",
        "# doc"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S6rEv4a9vEwO"
      },
      "source": [
        "# Method 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bWt0UPHTvEwO",
        "outputId": "216c7689-71a0-4a7f-df66-d4d5ff01769a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "' T5  Text To Text Transfer Transformer As of July 2022  we recommend using T5X  T5X is the new and improved implementation of T5  and more  in JAX and Flax. T5 on Tensorflow with MeshTF is no longer actively developed. If you are new to T5  we recommend starting with T5X.  The t5 library serves primarily as code for reproducing the experiments in Exploring the Limits of Transfer Learning with a Unified Text to Text Transformer. In the paper  we demonstrate how to achieve state of the art results on multiple NLP tasks using a text to text transformer pre trained on a large text corpus. The bulk of the code in this repository is used for loading  preprocessing  mixing  and evaluating datasets. It also provides a way to fine tune the pre trained models released alongside the publication. The t5 library can be used for future model development by providing useful modules for training and fine tuning  potentially huge  models on mixtures of text to text tasks. Table of Contents  Library Usage  Dataset Preparation  C4 Installation Setting up TPUs on GCP Training Fine Tuning Eval Decode Export GPU Usage Reproducing our experiments Useful Options   Released Model Checkpoints How to Cite  Library t5.data t5.data is a package for defining Task objects that provide tf.data.Datasets. Each Task is made up of   a data source text preprocessor function s  a SentencePiece model metric function s   Additionally  you may optionally provide   token preprocessor function s  postprocess function s   The data source can be an arbitrary function that provides a tf.data.Dataset  but we also provide simpler wrappers for datasets available in TensorFlow Datasets  TFDS   a TfdsTask  or stored as text files with one example per line  a TextLineTask . The text preprocessor converts the examples in the source dataset into the appropriate format for a text to text model with fields for inputs and targets.  For example  the predefined t5.data.preprocessors.translate preprocessor converts inputs in the form   de    Das ist gut.    en    That is good.   to the form   inputs    translate German to English  Das ist gut.    targets    That is good.   In addition to text preprocessing  you can also use one or more token preprocessors to modify the inputs post tokenization. We implemented our unsupervised pre training objectives using these token preprocessors. We provide many predefined preprocessors in t5.data.preprocessors  but you may also define your own. The SentencePiece model is used to tokenize the input strings and decode the output tokens. You can create your own model with the google sentencepiece library  or use our default one at t5.data.DEFAULT_SPM_PATH. If you create your own  you must use the flags   pad_id 0   eos_id 1   unk_id 2   bos_id  1 with spm_train to be compatible with our model code. The metric function returns a score given the target and prediction from the model. You may also define a postprocess function to convert the target and prediction text to another format before calling the metric. We provide some predefined metrics in t5.evaluation.metrics. Finally  t5.data contains a Mixture class that can be instantiated to combine multiple Task datasets for multi task training using various functions for specifying the mixture rates. t5.evaluation t5.evaluation contains two core components   metrics to be used during evaluation utilities for applying these metrics at evaluation time  t5.models t5.models contains shims for connecting T5 Tasks and Mixtures to a model implementation for training  evaluation  and inference. Currently there are two shims available  One for the Mesh TensorFlow Transformer that we used in our paper and another for the Hugging Face Transformers library. The Hugging Face API is currently experimental and subject to change  but provides a simple and easy way to load  fine tune  and evaluate our pre trained models using PyTorch on a single GPU. If you want to use our largest models on TPUs and or reproduce the results in our paper  you should use the MtfModel API and the t5_mesh_transformer binary. If you are interested fine tuning our models on a GPU in PyTorch  you should try the HfPyTorchModel API. Since the HfPyTorchModel is experimental  the remainder of this README assumes usage of the MtfModel and its associated binary. A usage example of HfPyTorchModel is available here. Usage The easiest way to try out T5 is with a free TPU in our Colab Tutorial. Below we provide examples for how to pre train  fine tune  evaluate  and decode from a model from the command line with our codebase. You can use these instructions to reproduce our results  fine tune one of our released checkpoints with your own data and or hyperparameters  or pre train a model from scratch. Dataset Preparation You may either use a new or pre existing Task  or you may load examples from a preprocessed TSV file. Using a Task Depending on your data source  see above   you will need to prepare your data appropriately. Task If using a vanilla task  just make sure any file s  loaded by your dataset_fn are accessible to the TPU  i.e.  are in a GCS bucket   and you should be good to go  TfdsTask Most of our predefined Tasks use TensorFlow Datasets  TFDS  as their data source. When you run our training binary  see instructions below  with a TfdsTask  the dataset will automatically be downloaded and prepared on its first use. After preparation is complete  the dataset is cached to your local storage to avoid this overhead in future runs.  If working in the cloud  we recommend you set the   t5_tfds_data_dir flag to point to a persistent storage location  such as a GCS bucket. This is a requirement when training on TPU. C4 The C4 dataset we created for unsupervised pre training is available in TensorFlow Datasets  but it requires a significant amount of bandwidth for downloading the raw Common Crawl scrapes   7 TB  and compute for its preparation   335 CPU days . We suggest you take advantage of the Apache Beam support in TFDS  which enables distributed preprocessing of the dataset and can be run on Google Cloud Dataflow. With 500 workers  the job should complete in  16 hours. After defining MY_PROJECT and MY_BUCKET appropriately  you can build the dataset in DataFlow from GCP using the following commands  pip install tfds nightly c4  echo  tfds nightly c4      tmp beam_requirements.txt python  m tensorflow_datasets.scripts.download_and_prepare      datasets c4 en      data_dir gs    MY_BUCKET tensorflow_datasets      beam_pipeline_options  project  MY_PROJECT job_name c4 staging_location gs    MY_BUCKET binaries temp_location gs    MY_BUCKET temp runner DataflowRunner requirements_file  tmp beam_requirements.txt experiments shuffle_mode service region  MY_REGION  Read more in the TFDS Beam instructions. TextLineTask A TextLineTask is useful when your data source is a text file  or files  with one example per line. You can then use a text preprocessor to convert each line into a dictionary of inputs and targets. Make sure your files are accessible to the TPU  i.e.  are in a GCS bucket   and you should be good to go  Using a TSV File Directly Instead of defining a new Task  you may use a TSV file  or files  directly as your dataset where each line is formatted as  input t target . However  there are a couple of caveats   There is no way to define a text processor  so the TSV will need to contain your data in a preprocessed format. There is also currently no way to set a token preprocessor  postprocess function  or metric function for evaluation when using a TSV file directly.  If you need any of these features  you must define a new Task  TfdsTask  or TextLineTask. Similar to the above cases  your TSV file s  must be accessible to the TPU  i.e.  are in a GCS bucket . Installation To install the T5 package  simply run  pip install t5 gcp  Setting up TPUs on GCP You will first need to launch a Virtual Machine  VM  on Google Cloud. Details about launching the VM can be found at the Google Cloud Documentation. In order to run training or eval on Cloud TPUs  you must set up the following variables based on your project  zone and GCS bucket appropriately. Please refer to the Cloud TPU Quickstart guide for more details. export PROJECT your_project_name export ZONE your_project_zone export BUCKET gs   yourbucket  export TPU_NAME t5 tpu export TPU_SIZE v3 8 export DATA_DIR    BUCKET  your_data_dir  export MODEL_DIR    BUCKET  your_model_dir  Please use the following command to create a TPU device in the Cloud VM. ctpu up   name  TPU_NAME   project  PROJECT   zone  ZONE   tpu size  TPU_SIZE            tpu only   noconf Training In the command below  we train a model on the GLUE Benchmark MRPC task from scratch. You can change the MIXTURE_NAME gin parameter to use any of the tasks or mixtures provided in our package. t5_mesh_transformer       tpu    TPU_NAME        gcp_project    PROJECT        tpu_zone    ZONE        model_dir    MODEL_DIR        t5_tfds_data_dir    DATA_DIR        gin_file  dataset.gin       gin_file  models bi_v1.gin       gin_param  utils.tpu_mesh_shape.model_parallelism   1       gin_param  utils.tpu_mesh_shape.tpu_topology      TPU_SIZE         gin_param  MIXTURE_NAME    glue_mrpc_v002   The full list of tasks and mixtures can be obtained by running  python  c  import t5; print t5.data.MixtureRegistry.names     You may also define additional tasks and mixtures in a new file and import it using the   module_import flag. Alternatively  you could train with a TSV file where each line is formatted as  input t target   see above . Fine tuning In order to fine tune one of our pre trained models  you need to pass the operative config of the pre trained model to the training script. The operative config should be passed in as a gin_file flag. It specifies the model architecture and other hyperparameters. In addition  you need to specify the mixture to fine tune on. For example  to fine tune the T5 small model on the glue_mrpc_v002 mixture  please run  t5_mesh_transformer       tpu    TPU_NAME        gcp_project    PROJECT        tpu_zone    ZONE        model_dir    MODEL_DIR        t5_tfds_data_dir    DATA_DIR        gin_file  dataset.gin       gin_param  utils.tpu_mesh_shape.model_parallelism   1       gin_param  utils.tpu_mesh_shape.tpu_topology      TPU_SIZE         gin_param  MIXTURE_NAME    glue_mrpc_v002        gin_file  gs   t5 data pretrained_models small operative_config.gin  The correct pre trained checkpoint path is included in the operative config. You may also define additional tasks and mixtures in a new file and import it using the   module_import flag. Alternatively  you could fine tune with a TSV file where each line is formatted as  input t target   see above . For example  you could try one of the paired translation datasets from WMT  19 News Commentary 14 training set  e.g.  English French . When using a TSV file  you would replace the MIXTURE_NAME flag with    gin_param  utils.run.train_dataset_fn   @t5.models.mesh_transformer.tsv_dataset_fn    gin_param  tsv_dataset_fn.filename    gs  path to tsv   To fine tune with the same hyperparameters we used in the paper  using a constant learning rate of 0.001   you can pass in this gin file which is included in the T5 package    gin_file  learning_rate_schedules constant_0_001.gin   The operative config for the pre trained models are set so that there is effectively no limit on the number of train steps. If you d like to train for a specific number of steps  you ll need to pass that in. Since the pre trained model has already been trained for 1 000 000 steps  you should specify the total number of steps after pre training and fine tuning. For example  if you want to fine tune for an additional 10 000 steps  you should pass   gin_param  run.train_steps   1010000   You can also use a different batch size for fine tuning. We set the batch size according to the total number of tokens in a batch. By default  a batch uses a sequence length of 512. To set the number of tokens in a batch  you should set   gin_param    tokens_per_batch 1048576   Eval In order to evaluate a model in the T5 framework  you need to use the eval.gin file  specify the model directory  decoding method  and which checkpoint step s  to evaluate. So  to evaluate on the GLUE MRPC task using beam search on all checkpoints  use the following command  t5_mesh_transformer      tpu    TPU_NAME        gcp_project    PROJECT        tpu_zone    ZONE        model_dir    MODEL_DIR        gin_file    MODEL_DIR  operative_config.gin       t5_tfds_data_dir   DATA_DIR       gin_file  eval.gin       gin_file  beam_search.gin       gin_param  run.dataset_split    validation        gin_param  utils.tpu_mesh_shape.tpu_topology      TPU_SIZE         gin_param  MIXTURE_NAME    glue_mrpc_v002        gin_param  eval_checkpoint_step    all   To evaluate a specific checkpoint  simply set the eval_checkpoint_step parameter to appropriate checkpoint.   gin_param  eval_checkpoint_step   100000   You can also use greedy_decode.gin or sample_decode.gin instead of beam_search.gin in the command above. Decode In order to produce predictions from a model in the T5 framework  you need to specify the model directory  decoding method  and which checkpoint step s  to use for decoding. Assuming you have a text file of input sequences stored at  path to intputs.txt  an example command would be  t5_mesh_transformer      tpu    TPU_NAME        gcp_project    PROJECT        tpu_zone    ZONE        model_dir    MODEL_DIR        gin_file    MODEL_DIR  operative_config.gin       gin_file  infer.gin       gin_file  sample_decode.gin       gin_param  input_filename     path to inputs.txt       gin_param  output_filename     tmp outputs.txt       gin_param  utils.tpu_mesh_shape.tpu_topology      TPU_SIZE        gin_param  infer_checkpoint_step    all   To predict with a specific checkpoint  simply set the infer_checkpoint_step parameter to appropriate checkpoint.   gin_param  infer_checkpoint_step   100000   You can also use beam_search.gin or greedy_decode.gin instead of sample_decode.gin in the command above. Export You may also want to export a SavedModel  which is useful for serving your trained model   e.g.  when deploying with ML Engine or in a Docker image . t5_mesh_transformer      gcp_project    PROJECT        tpu_zone    ZONE        model_dir    MODEL_DIR        use_model_api      mode  export_predict       export_dir   path to export dir  The command above exports the latest checkpoint in the model directory. To export a particular checkpoint  add the following flags      checkpoint_mode  specific       checkpoint_steps 1000000 The t5 deploy notebook demonstrates exporting a SavedModel and packaging it in a Docker image for serving. GPU Usage If you would like to use GPU instead of TPUs  you can modify the above commands by removing TPU specific flags    tpu    tpu_zone    gcp_project  and setting the gin params for mesh_shape and mesh_devices based on your desired setup. For example  if your machine has access to 6 GPUs and you d like to do 3 way model parallelism and 2 way data parallelism  the fine tuning command above would become  t5_mesh_transformer       model_dir    MODEL_DIR        t5_tfds_data_dir    DATA_DIR        gin_file  dataset.gin       gin_param  utils.run.mesh_shape    model 3 batch 2        gin_param  utils.run.mesh_devices     gpu 0   gpu 1   gpu 2   gpu 3   gpu 4   gpu 5         gin_param  MIXTURE_NAME    glue_mrpc_v002        gin_file  gs   t5 data pretrained_models small operative_config.gin  With a single GPU  the command is  t5_mesh_transformer       model_dir    MODEL_DIR        t5_tfds_data_dir    DATA_DIR        gin_file  dataset.gin       gin_param  utils.run.mesh_shape    model 1 batch 1        gin_param  utils.run.mesh_devices     gpu 0         gin_param  MIXTURE_NAME    glue_mrpc_v002        gin_file  gs   t5 data pretrained_models small operative_config.gin  Reproducing our experiments We provide operative configs for all of the experiments in the paper in gs   t5 data experiments. The experiments folder has different subdirectories corresponding to the different sections in our paper. For example  gs   t5 data experiments objectives contains the experiments from Section 3.3   Unsupervised objectives  . Each subdirectory of the objectives folder contains operative configs for some particular experiment  where loosely speaking an  experiment  is one of the rows in one of the tables in our paper . Let s say you want to reproduce the results for the  Prefix language modeling  objective  the first row in Table 4 . The operative configs for that experiment live in gs   t5 data experiments objectives obj prefix_lm. In the base directory  there is an operative config for pre training the model  gs   t5 data experiments objectives obj prefix_lm operative_config.gin . Then  there are subdirectories for each of the downstream fine tuning mixtures we consider  each of which has its own operative config  for example  gs   t5 data experiments objectives obj prefix_lm cnn_dailymail_v002 operative_config.gin . To run this experiment  first pre train a model with the pre training operative config  export PRETRAIN_MODEL_DIR    BUCKET  obj prefix_lm  t5_mesh_transformer       tpu    TPU_NAME        gcp_project    PROJECT        tpu_zone    ZONE        model_dir    PRETRAIN_MODEL_DIR        gin_file  gs   t5 data experiments objectives obj prefix_lm operative_config.gin       gin_param  utils.tpu_mesh_shape.model_parallelism   1       gin_param  utils.tpu_mesh_shape.tpu_topology      TPU_SIZE    Then  you can fine tune the pre trained model on CNN Daily Mail like so  export FINETUNE_MODEL_DIR    BUCKET  obj prefix_lm cnn_dailymail_v002  t5_mesh_transformer       tpu    TPU_NAME        gcp_project    PROJECT        tpu_zone    ZONE        model_dir    FINETUNE_MODEL_DIR        gin_file  gs   t5 data experiments objectives obj prefix_lm cnn_dailymail_v002 operative_config.gin       gin_param  init_checkpoint      PRETRAIN_MODEL_DIR  model.ckpt 524288        gin_param  utils.tpu_mesh_shape.model_parallelism   1       gin_param  utils.tpu_mesh_shape.tpu_topology      TPU_SIZE    Useful Options Some training variants need multiple flags to be set at the same time. For each of the below variants  add the group of flags to . third_party py t5 google scripts run_finetune.sh. Deterministic training     train_gin_param  mesh_train_dataset_fn.seed   SEED        train_gin_param  utils.run.skip_seen_data   True   Language model     objective  lm       train_gin_param  utils.run.model_type    lm    Released Model Checkpoints We have released the following checkpoints for pre trained models described in our paper   T5 Small  60 million parameters   gs   t5 data pretrained_models small T5 Base  220 million parameters   gs   t5 data pretrained_models base T5 Large  770 million parameters   gs   t5 data pretrained_models large T5 3B  3 billion parameters   gs   t5 data pretrained_models 3B T5 11B  11 billion parameters   gs   t5 data pretrained_models 11B  See here for a list of additional experimental pre trained model checkpoints. How to Cite If you extend or use this work  please cite the paper where it was introduced  @article 2020t5    author     Colin Raffel and Noam Shazeer and Adam Roberts and Katherine Lee and Sharan Narang and Michael Matena and Yanqi Zhou and Wei Li and Peter J. Liu     title      Exploring the Limits of Transfer Learning with a Unified Text to Text Transformer     journal    Journal of Machine Learning Research     year       2020     volume     21     number     140     pages      1 67     url        http   jmlr.org papers v21 20 074.html     '"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 37
        }
      ],
      "source": [
        "#remove \\n, \\\\, : , (,)\n",
        "import re\n",
        "doc = re.sub(\"[\\n:(=<>)\\[\\]]\",' ',original)\n",
        "doc = re.sub(\"[-,/$~!{\\'\\\"}]\",' ',doc)\n",
        "doc = doc.replace(\"\\\\\",\"\")\n",
        "doc = doc.replace(\"--\",\"\")\n",
        "doc\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GwJgpfslvEwP",
        "outputId": "3b649715-4730-4b6e-d5aa-67e1e2fe6b5e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "' t5  text to text transfer transformer as of july 2022  we recommend using t5x  t5x is the new and improved implementation of t5  and more  in jax and flax. t5 on tensorflow with meshtf is no longer actively developed. if you are new to t5  we recommend starting with t5x.  the t5 library serves primarily as code for reproducing the experiments in exploring the limits of transfer learning with a unified text to text transformer. in the paper  we demonstrate how to achieve state of the art results on multiple nlp tasks using a text to text transformer pre trained on a large text corpus. the bulk of the code in this repository is used for loading  preprocessing  mixing  and evaluating datasets. it also provides a way to fine tune the pre trained models released alongside the publication. the t5 library can be used for future model development by providing useful modules for training and fine tuning  potentially huge  models on mixtures of text to text tasks. table of contents  library usage  dataset preparation  c4 installation setting up tpus on gcp training fine tuning eval decode export gpu usage reproducing our experiments useful options   released model checkpoints how to cite  library t5.data t5.data is a package for defining task objects that provide tf.data.datasets. each task is made up of   a data source text preprocessor function s  a sentencepiece model metric function s   additionally  you may optionally provide   token preprocessor function s  postprocess function s   the data source can be an arbitrary function that provides a tf.data.dataset  but we also provide simpler wrappers for datasets available in tensorflow datasets  tfds   a tfdstask  or stored as text files with one example per line  a textlinetask . the text preprocessor converts the examples in the source dataset into the appropriate format for a text to text model with fields for inputs and targets.  for example  the predefined t5.data.preprocessors.translate preprocessor converts inputs in the form   de    das ist gut.    en    that is good.   to the form   inputs    translate german to english  das ist gut.    targets    that is good.   in addition to text preprocessing  you can also use one or more token preprocessors to modify the inputs post tokenization. we implemented our unsupervised pre training objectives using these token preprocessors. we provide many predefined preprocessors in t5.data.preprocessors  but you may also define your own. the sentencepiece model is used to tokenize the input strings and decode the output tokens. you can create your own model with the google sentencepiece library  or use our default one at t5.data.default_spm_path. if you create your own  you must use the flags   pad_id 0   eos_id 1   unk_id 2   bos_id  1 with spm_train to be compatible with our model code. the metric function returns a score given the target and prediction from the model. you may also define a postprocess function to convert the target and prediction text to another format before calling the metric. we provide some predefined metrics in t5.evaluation.metrics. finally  t5.data contains a mixture class that can be instantiated to combine multiple task datasets for multi task training using various functions for specifying the mixture rates. t5.evaluation t5.evaluation contains two core components   metrics to be used during evaluation utilities for applying these metrics at evaluation time  t5.models t5.models contains shims for connecting t5 tasks and mixtures to a model implementation for training  evaluation  and inference. currently there are two shims available  one for the mesh tensorflow transformer that we used in our paper and another for the hugging face transformers library. the hugging face api is currently experimental and subject to change  but provides a simple and easy way to load  fine tune  and evaluate our pre trained models using pytorch on a single gpu. if you want to use our largest models on tpus and or reproduce the results in our paper  you should use the mtfmodel api and the t5_mesh_transformer binary. if you are interested fine tuning our models on a gpu in pytorch  you should try the hfpytorchmodel api. since the hfpytorchmodel is experimental  the remainder of this readme assumes usage of the mtfmodel and its associated binary. a usage example of hfpytorchmodel is available here. usage the easiest way to try out t5 is with a free tpu in our colab tutorial. below we provide examples for how to pre train  fine tune  evaluate  and decode from a model from the command line with our codebase. you can use these instructions to reproduce our results  fine tune one of our released checkpoints with your own data and or hyperparameters  or pre train a model from scratch. dataset preparation you may either use a new or pre existing task  or you may load examples from a preprocessed tsv file. using a task depending on your data source  see above   you will need to prepare your data appropriately. task if using a vanilla task  just make sure any file s  loaded by your dataset_fn are accessible to the tpu  i.e.  are in a gcs bucket   and you should be good to go  tfdstask most of our predefined tasks use tensorflow datasets  tfds  as their data source. when you run our training binary  see instructions below  with a tfdstask  the dataset will automatically be downloaded and prepared on its first use. after preparation is complete  the dataset is cached to your local storage to avoid this overhead in future runs.  if working in the cloud  we recommend you set the   t5_tfds_data_dir flag to point to a persistent storage location  such as a gcs bucket. this is a requirement when training on tpu. c4 the c4 dataset we created for unsupervised pre training is available in tensorflow datasets  but it requires a significant amount of bandwidth for downloading the raw common crawl scrapes   7 tb  and compute for its preparation   335 cpu days . we suggest you take advantage of the apache beam support in tfds  which enables distributed preprocessing of the dataset and can be run on google cloud dataflow. with 500 workers  the job should complete in  16 hours. after defining my_project and my_bucket appropriately  you can build the dataset in dataflow from gcp using the following commands  pip install tfds nightly c4  echo  tfds nightly c4      tmp beam_requirements.txt python  m tensorflow_datasets.scripts.download_and_prepare      datasets c4 en      data_dir gs    my_bucket tensorflow_datasets      beam_pipeline_options  project  my_project job_name c4 staging_location gs    my_bucket binaries temp_location gs    my_bucket temp runner dataflowrunner requirements_file  tmp beam_requirements.txt experiments shuffle_mode service region  my_region  read more in the tfds beam instructions. textlinetask a textlinetask is useful when your data source is a text file  or files  with one example per line. you can then use a text preprocessor to convert each line into a dictionary of inputs and targets. make sure your files are accessible to the tpu  i.e.  are in a gcs bucket   and you should be good to go  using a tsv file directly instead of defining a new task  you may use a tsv file  or files  directly as your dataset where each line is formatted as  input t target . however  there are a couple of caveats   there is no way to define a text processor  so the tsv will need to contain your data in a preprocessed format. there is also currently no way to set a token preprocessor  postprocess function  or metric function for evaluation when using a tsv file directly.  if you need any of these features  you must define a new task  tfdstask  or textlinetask. similar to the above cases  your tsv file s  must be accessible to the tpu  i.e.  are in a gcs bucket . installation to install the t5 package  simply run  pip install t5 gcp  setting up tpus on gcp you will first need to launch a virtual machine  vm  on google cloud. details about launching the vm can be found at the google cloud documentation. in order to run training or eval on cloud tpus  you must set up the following variables based on your project  zone and gcs bucket appropriately. please refer to the cloud tpu quickstart guide for more details. export project your_project_name export zone your_project_zone export bucket gs   yourbucket  export tpu_name t5 tpu export tpu_size v3 8 export data_dir    bucket  your_data_dir  export model_dir    bucket  your_model_dir  please use the following command to create a tpu device in the cloud vm. ctpu up   name  tpu_name   project  project   zone  zone   tpu size  tpu_size            tpu only   noconf training in the command below  we train a model on the glue benchmark mrpc task from scratch. you can change the mixture_name gin parameter to use any of the tasks or mixtures provided in our package. t5_mesh_transformer       tpu    tpu_name        gcp_project    project        tpu_zone    zone        model_dir    model_dir        t5_tfds_data_dir    data_dir        gin_file  dataset.gin       gin_file  models bi_v1.gin       gin_param  utils.tpu_mesh_shape.model_parallelism   1       gin_param  utils.tpu_mesh_shape.tpu_topology      tpu_size         gin_param  mixture_name    glue_mrpc_v002   the full list of tasks and mixtures can be obtained by running  python  c  import t5; print t5.data.mixtureregistry.names     you may also define additional tasks and mixtures in a new file and import it using the   module_import flag. alternatively  you could train with a tsv file where each line is formatted as  input t target   see above . fine tuning in order to fine tune one of our pre trained models  you need to pass the operative config of the pre trained model to the training script. the operative config should be passed in as a gin_file flag. it specifies the model architecture and other hyperparameters. in addition  you need to specify the mixture to fine tune on. for example  to fine tune the t5 small model on the glue_mrpc_v002 mixture  please run  t5_mesh_transformer       tpu    tpu_name        gcp_project    project        tpu_zone    zone        model_dir    model_dir        t5_tfds_data_dir    data_dir        gin_file  dataset.gin       gin_param  utils.tpu_mesh_shape.model_parallelism   1       gin_param  utils.tpu_mesh_shape.tpu_topology      tpu_size         gin_param  mixture_name    glue_mrpc_v002        gin_file  gs   t5 data pretrained_models small operative_config.gin  the correct pre trained checkpoint path is included in the operative config. you may also define additional tasks and mixtures in a new file and import it using the   module_import flag. alternatively  you could fine tune with a tsv file where each line is formatted as  input t target   see above . for example  you could try one of the paired translation datasets from wmt  19 news commentary 14 training set  e.g.  english french . when using a tsv file  you would replace the mixture_name flag with    gin_param  utils.run.train_dataset_fn   @t5.models.mesh_transformer.tsv_dataset_fn    gin_param  tsv_dataset_fn.filename    gs  path to tsv   to fine tune with the same hyperparameters we used in the paper  using a constant learning rate of 0.001   you can pass in this gin file which is included in the t5 package    gin_file  learning_rate_schedules constant_0_001.gin   the operative config for the pre trained models are set so that there is effectively no limit on the number of train steps. if you d like to train for a specific number of steps  you ll need to pass that in. since the pre trained model has already been trained for 1 000 000 steps  you should specify the total number of steps after pre training and fine tuning. for example  if you want to fine tune for an additional 10 000 steps  you should pass   gin_param  run.train_steps   1010000   you can also use a different batch size for fine tuning. we set the batch size according to the total number of tokens in a batch. by default  a batch uses a sequence length of 512. to set the number of tokens in a batch  you should set   gin_param    tokens_per_batch 1048576   eval in order to evaluate a model in the t5 framework  you need to use the eval.gin file  specify the model directory  decoding method  and which checkpoint step s  to evaluate. so  to evaluate on the glue mrpc task using beam search on all checkpoints  use the following command  t5_mesh_transformer      tpu    tpu_name        gcp_project    project        tpu_zone    zone        model_dir    model_dir        gin_file    model_dir  operative_config.gin       t5_tfds_data_dir   data_dir       gin_file  eval.gin       gin_file  beam_search.gin       gin_param  run.dataset_split    validation        gin_param  utils.tpu_mesh_shape.tpu_topology      tpu_size         gin_param  mixture_name    glue_mrpc_v002        gin_param  eval_checkpoint_step    all   to evaluate a specific checkpoint  simply set the eval_checkpoint_step parameter to appropriate checkpoint.   gin_param  eval_checkpoint_step   100000   you can also use greedy_decode.gin or sample_decode.gin instead of beam_search.gin in the command above. decode in order to produce predictions from a model in the t5 framework  you need to specify the model directory  decoding method  and which checkpoint step s  to use for decoding. assuming you have a text file of input sequences stored at  path to intputs.txt  an example command would be  t5_mesh_transformer      tpu    tpu_name        gcp_project    project        tpu_zone    zone        model_dir    model_dir        gin_file    model_dir  operative_config.gin       gin_file  infer.gin       gin_file  sample_decode.gin       gin_param  input_filename     path to inputs.txt       gin_param  output_filename     tmp outputs.txt       gin_param  utils.tpu_mesh_shape.tpu_topology      tpu_size        gin_param  infer_checkpoint_step    all   to predict with a specific checkpoint  simply set the infer_checkpoint_step parameter to appropriate checkpoint.   gin_param  infer_checkpoint_step   100000   you can also use beam_search.gin or greedy_decode.gin instead of sample_decode.gin in the command above. export you may also want to export a savedmodel  which is useful for serving your trained model   e.g.  when deploying with ml engine or in a docker image . t5_mesh_transformer      gcp_project    project        tpu_zone    zone        model_dir    model_dir        use_model_api      mode  export_predict       export_dir   path to export dir  the command above exports the latest checkpoint in the model directory. to export a particular checkpoint  add the following flags      checkpoint_mode  specific       checkpoint_steps 1000000 the t5 deploy notebook demonstrates exporting a savedmodel and packaging it in a docker image for serving. gpu usage if you would like to use gpu instead of tpus  you can modify the above commands by removing tpu specific flags    tpu    tpu_zone    gcp_project  and setting the gin params for mesh_shape and mesh_devices based on your desired setup. for example  if your machine has access to 6 gpus and you d like to do 3 way model parallelism and 2 way data parallelism  the fine tuning command above would become  t5_mesh_transformer       model_dir    model_dir        t5_tfds_data_dir    data_dir        gin_file  dataset.gin       gin_param  utils.run.mesh_shape    model 3 batch 2        gin_param  utils.run.mesh_devices     gpu 0   gpu 1   gpu 2   gpu 3   gpu 4   gpu 5         gin_param  mixture_name    glue_mrpc_v002        gin_file  gs   t5 data pretrained_models small operative_config.gin  with a single gpu  the command is  t5_mesh_transformer       model_dir    model_dir        t5_tfds_data_dir    data_dir        gin_file  dataset.gin       gin_param  utils.run.mesh_shape    model 1 batch 1        gin_param  utils.run.mesh_devices     gpu 0         gin_param  mixture_name    glue_mrpc_v002        gin_file  gs   t5 data pretrained_models small operative_config.gin  reproducing our experiments we provide operative configs for all of the experiments in the paper in gs   t5 data experiments. the experiments folder has different subdirectories corresponding to the different sections in our paper. for example  gs   t5 data experiments objectives contains the experiments from section 3.3   unsupervised objectives  . each subdirectory of the objectives folder contains operative configs for some particular experiment  where loosely speaking an  experiment  is one of the rows in one of the tables in our paper . let s say you want to reproduce the results for the  prefix language modeling  objective  the first row in table 4 . the operative configs for that experiment live in gs   t5 data experiments objectives obj prefix_lm. in the base directory  there is an operative config for pre training the model  gs   t5 data experiments objectives obj prefix_lm operative_config.gin . then  there are subdirectories for each of the downstream fine tuning mixtures we consider  each of which has its own operative config  for example  gs   t5 data experiments objectives obj prefix_lm cnn_dailymail_v002 operative_config.gin . to run this experiment  first pre train a model with the pre training operative config  export pretrain_model_dir    bucket  obj prefix_lm  t5_mesh_transformer       tpu    tpu_name        gcp_project    project        tpu_zone    zone        model_dir    pretrain_model_dir        gin_file  gs   t5 data experiments objectives obj prefix_lm operative_config.gin       gin_param  utils.tpu_mesh_shape.model_parallelism   1       gin_param  utils.tpu_mesh_shape.tpu_topology      tpu_size    then  you can fine tune the pre trained model on cnn daily mail like so  export finetune_model_dir    bucket  obj prefix_lm cnn_dailymail_v002  t5_mesh_transformer       tpu    tpu_name        gcp_project    project        tpu_zone    zone        model_dir    finetune_model_dir        gin_file  gs   t5 data experiments objectives obj prefix_lm cnn_dailymail_v002 operative_config.gin       gin_param  init_checkpoint      pretrain_model_dir  model.ckpt 524288        gin_param  utils.tpu_mesh_shape.model_parallelism   1       gin_param  utils.tpu_mesh_shape.tpu_topology      tpu_size    useful options some training variants need multiple flags to be set at the same time. for each of the below variants  add the group of flags to . third_party py t5 google scripts run_finetune.sh. deterministic training     train_gin_param  mesh_train_dataset_fn.seed   seed        train_gin_param  utils.run.skip_seen_data   true   language model     objective  lm       train_gin_param  utils.run.model_type    lm    released model checkpoints we have released the following checkpoints for pre trained models described in our paper   t5 small  60 million parameters   gs   t5 data pretrained_models small t5 base  220 million parameters   gs   t5 data pretrained_models base t5 large  770 million parameters   gs   t5 data pretrained_models large t5 3b  3 billion parameters   gs   t5 data pretrained_models 3b t5 11b  11 billion parameters   gs   t5 data pretrained_models 11b  see here for a list of additional experimental pre trained model checkpoints. how to cite if you extend or use this work  please cite the paper where it was introduced  @article 2020t5    author     colin raffel and noam shazeer and adam roberts and katherine lee and sharan narang and michael matena and yanqi zhou and wei li and peter j. liu     title      exploring the limits of transfer learning with a unified text to text transformer     journal    journal of machine learning research     year       2020     volume     21     number     140     pages      1 67     url        http   jmlr.org papers v21 20 074.html     '"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 38
        }
      ],
      "source": [
        "doc = doc.lower()\n",
        "doc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-CQ6Vl_LvEwP",
        "outputId": "3c748bcb-a1af-4dd3-f588-d6e33022067f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2618"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "#calculate total words in corpus\n",
        "total_words = doc.split()\n",
        "len_total_words = len(total_words)\n",
        "len_total_words"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b7-wXZ-3vEwQ"
      },
      "outputs": [],
      "source": [
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "stop_words = set(stopwords.words('english'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3iO4r6-uvEwQ",
        "outputId": "422e426b-cb66-44aa-c264-3aa8ba82355e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "47"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "sentences = tokenize.sent_tokenize(doc)\n",
        "len_sentences = len(sentences)\n",
        "len_sentences"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "4XDPB6Ji7_cy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cp5hTz_dvEwQ",
        "outputId": "e6e750c3-ce64-4f70-f498-a8fb31f32cc1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['t5 text to text transfer transformeras of july 2022  we recommend using t5xt5x is the new and improved implementation of t5 and more in jax and flax.t5 on tensorflow with meshtf is no longer actively developed.',\n",
              " 'if you are newto t5  we recommend starting with t5x.the t5 library serves primarily as code for reproducing the experiments in exploring the limits of transfer learning with a unified text to text transformer.',\n",
              " 'in the paper  we demonstrate how to achieve state of the art results on multiple nlp tasks using a text to text transformer pre trained on a large text corpus.the bulk of the code in this repository is used for loading  preprocessing  mixing  and evaluating datasets.it also provides a way to fine tune the pre trained models released alongside the publication.the t5 library can be used for future model development by providing useful modules for training and fine tuning potentially huge models on mixtures of text to text tasks.table of contentslibraryusagedataset preparationc4installationsetting up tpus on gcptrainingfine tuningevaldecodeexportgpu usagereproducing our experimentsuseful optionsreleased model checkpointshow to citelibraryt5.datat5.data is a package for defining task objects that provide tf.data.datasets.each task is made up ofa data sourcetext preprocessor functionsa sentencepiece modelmetric functionsadditionally  you may optionally providetoken preprocessor functionspostprocess functionsthe data source can be an arbitrary function that provides a tf.data.dataset  but we also provide simpler wrappers for datasets available in tensorflow datasets tfds a tfdstask or stored as text files with one example per line a textlinetask.the text preprocessor converts the examples in the source dataset into the appropriate format for a text to text model with fields for inputs and targets.',\n",
              " 'for example  the predefined t5.data.preprocessors.translate preprocessor converts inputs in the form  de   das ist gut.',\n",
              " 'en   that is good.',\n",
              " 'to the form  inputs   translate german to english das ist gut.',\n",
              " 'targets   that is good.',\n",
              " 'in addition to text preprocessing  you can also use one or more token preprocessors to modify the inputs post tokenization.',\n",
              " 'we implemented our unsupervised pre training objectives using these token preprocessors.we provide many predefined preprocessors in t5.data.preprocessors  but you may also define your own.the sentencepiece model is used to tokenize the input strings and decode the output tokens.',\n",
              " 'you can create your own model with the google sentencepiece library  or use our default one at t5.data.default_spm_path.',\n",
              " 'if you create your own  you must use the flags   pad_id0   eos_id1   unk_id2   bos_id 1 with spm_train to be compatible with our model code.the metric function returns a score given the target and prediction from the model.',\n",
              " 'you may also define a postprocess function to convert the target and prediction text to another format before calling the metric.',\n",
              " 'we provide some predefined metrics in t5.evaluation.metrics.finally  t5.data contains a mixture class that can be instantiated to combine multiple task datasets for multi task training using various functions for specifying the mixture rates.t5.evaluationt5.evaluation contains two core componentsmetrics to be used during evaluationutilities for applying these metrics at evaluation timet5.modelst5.models contains shims for connecting t5 tasks and mixtures to a model implementation for training  evaluation  and inference.currently there are two shims available one for the mesh tensorflow transformer that we used in our paper and another for the hugging face transformers library.the hugging face api is currently experimental and subject to change  but provides a simple and easy way to load  fine tune  and evaluate our pre trained models using pytorch on a single gpu.if you want to use our largest models on tpus and or reproduce the results in our paper  you should use the mtfmodel api and the t5_mesh_transformer binary.if you are interested fine tuning our models on a gpu in pytorch  you should try the hfpytorchmodel api.since the hfpytorchmodel is experimental  the remainder of this readme assumes usage of the mtfmodel and its associated binary.a usage example of hfpytorchmodel is available here.usagethe easiest way to try out t5 is with a free tpu in our colab tutorial.below we provide examples for how to pre train  fine tune  evaluate  and decode from a model from the command line with our codebase.',\n",
              " 'you can use these instructions to reproduce our results  fine tune one of our released checkpoints with your own data and or hyperparameters  or pre train a model from scratch.dataset preparationyou may either use a new or pre existing task  or you may load examples from a preprocessed tsv file.using a taskdepending on your data source see above  you will need to prepare your data appropriately.taskif using a vanilla task  just make sure any files loaded by your dataset_fn are accessible to the tpu i.e.',\n",
              " 'are in a gcs bucket  and you should be good to go tfdstaskmost of our predefined tasks use tensorflow datasets tfds as their data source.',\n",
              " 'when you run our training binary see instructions below with a tfdstask  the dataset will automatically be downloaded and prepared on its first use.',\n",
              " 'after preparation is complete  the dataset is cached to your local storage to avoid this overhead in future runs.',\n",
              " 'if working in the cloud  we recommend you set the   t5_tfds_data_dir flag to point to a persistent storage location  such as a gcs bucket.',\n",
              " 'this is a requirement when training on tpu.c4the c4 dataset we created for unsupervised pre training is available in tensorflow datasets  but it requires a significant amount of bandwidth for downloading the raw common crawl scrapes  7 tb and compute for its preparation  335 cpu days.',\n",
              " 'we suggest you take advantage of the apache beam support in tfds  which enables distributed preprocessing of the dataset and can be run on google cloud dataflow.',\n",
              " 'with 500 workers  the job should complete in  16 hours.after defining my_project and my_bucket appropriately  you can build the dataset in dataflow from gcp using the following commandspip install tfds nightlyc4echo  tfds nightlyc4    tmp beam_requirements.txtpython  m tensorflow_datasets.scripts.download_and_prepare     datasetsc4 en     data_dirgs   my_bucket tensorflow_datasets     beam_pipeline_options project my_project job_namec4 staging_locationgs   my_bucket binaries temp_locationgs   my_bucket temp runnerdataflowrunner requirements_file tmp beam_requirements.txt experimentsshuffle_modeservice region my_region read more in the tfds beam instructions.textlinetaska textlinetask is useful when your data source is a text file or files with one example per line.',\n",
              " 'you can then use a text preprocessor to convert each line into a dictionary of inputs and targets.make sure your files are accessible to the tpu i.e.',\n",
              " 'are in a gcs bucket  and you should be good to go using a tsv file directlyinstead of defining a new task  you may use a tsv file or files directly as your dataset where each line is formatted as inputttarget.however  there are a couple of caveatsthere is no way to define a text processor  so the tsv will need to contain your data in a preprocessed format.there is also currently no way to set a token preprocessor  postprocess function  or metric function for evaluation when using a tsv file directly.if you need any of these features  you must define a new task  tfdstask  or textlinetask.similar to the above cases  your tsv files must be accessible to the tpu i.e.',\n",
              " 'are in a gcs bucket.installationto install the t5 package  simply runpip install t5gcpsetting up tpus on gcpyou will first need to launch a virtual machine vm on google cloud.',\n",
              " 'details about launching the vm can be found at the google cloud documentation.in order to run training or eval on cloud tpus  you must set up the following variables based on your project  zone and gcs bucket appropriately.',\n",
              " 'please refer to the cloud tpu quickstart guide for more details.export projectyour_project_nameexport zoneyour_project_zoneexport bucketgs  yourbucket export tpu_namet5 tpuexport tpu_sizev3 8export data_dir   bucket  your_data_dir export model_dir   bucket  your_model_dir please use the following command to create a tpu device in the cloud vm.ctpu up   name tpu_name   project project   zone zone   tpu size tpu_size           tpu only   noconftrainingin the command below  we train a model on the glue benchmark mrpc task from scratch.',\n",
              " 'you can change the mixture_name gin parameter to use any of the tasks or mixtures provided in our package.t5_mesh_transformer      tpu   tpu_name       gcp_project   project       tpu_zone   zone       model_dir   model_dir       t5_tfds_data_dir   data_dir       gin_file dataset.gin      gin_file models bi_v1.gin      gin_param utils.tpu_mesh_shape.model_parallelism  1      gin_param utils.tpu_mesh_shape.tpu_topology     tpu_size        gin_param mixture_name   glue_mrpc_v002  the full list of tasks and mixtures can be obtained by runningpython  c  import t5; printt5.data.mixtureregistry.names you may also define additional tasks and mixtures in a new file and import it using the   module_import flag.alternatively  you could train with a tsv file where each line is formatted as inputttarget see above.fine tuningin order to fine tune one of our pre trained models  you need to pass the operative config of the pre trained model to the training script.',\n",
              " 'the operative config should be passed in as a gin_file flag.',\n",
              " 'it specifies the model architecture and other hyperparameters.',\n",
              " 'in addition  you need to specify the mixture to fine tune on.',\n",
              " 'for example  to fine tune the t5 small model on the glue_mrpc_v002 mixture  please runt5_mesh_transformer      tpu   tpu_name       gcp_project   project       tpu_zone   zone       model_dir   model_dir       t5_tfds_data_dir   data_dir       gin_file dataset.gin      gin_param utils.tpu_mesh_shape.model_parallelism  1      gin_param utils.tpu_mesh_shape.tpu_topology     tpu_size        gin_param mixture_name   glue_mrpc_v002       gin_file gs  t5 data pretrained_models small operative_config.gin the correct pre trained checkpoint path is included in the operative config.you may also define additional tasks and mixtures in a new file and import it using the   module_import flag.alternatively  you could fine tune with a tsv file where each line is formatted as inputttarget see above.',\n",
              " 'for example  you could try one of the paired translation datasets from wmt  19 news commentary 14 training sete.g.',\n",
              " 'english french.',\n",
              " 'when using a tsv file  you would replace the mixture_name flag with  gin_param utils.run.train_dataset_fn  @t5.models.mesh_transformer.tsv_dataset_fn   gin_param tsv_dataset_fn.filename   gs path to tsv  to fine tune with the same hyperparameters we used in the paper using a constant learning rate of 0.001  you can pass in this gin file which is included in the t5 package  gin_file learning_rate_schedules constant_0_001.gin the operative config for the pre trained models are set so that there is effectively no limit on the number of train steps.',\n",
              " 'if you d like to train for a specific number of steps  you ll need to pass that in.',\n",
              " 'since the pre trained model has already been trained for 1 000 000 steps  you should specify the total number of steps after pre training and fine tuning.',\n",
              " 'for example  if you want to fine tune for an additional 10 000 steps  you should pass  gin_param run.train_steps  1010000 you can also use a different batch size for fine tuning.',\n",
              " 'we set the batch size according to the total number of tokens in a batch.',\n",
              " 'by default  a batch uses a sequence length of 512. to set the number of tokens in a batch  you should set  gin_param   tokens_per_batch1048576 evalin order to evaluate a model in the t5 framework  you need to use the eval.gin file  specify the model directory  decoding method  and which checkpoint steps to evaluate.',\n",
              " 'so  to evaluate on the glue mrpc task using beam search on all checkpoints  use the following commandt5_mesh_transformer     tpu   tpu_name       gcp_project   project       tpu_zone   zone       model_dir   model_dir       gin_file   model_dir  operative_config.gin      t5_tfds_data_dir  data_dir      gin_file eval.gin      gin_file beam_search.gin      gin_param run.dataset_split   validation       gin_param utils.tpu_mesh_shape.tpu_topology     tpu_size        gin_param mixture_name   glue_mrpc_v002       gin_param eval_checkpoint_step   all  to evaluate a specific checkpoint  simply set the eval_checkpoint_step parameter to appropriate checkpoint.',\n",
              " 'gin_param eval_checkpoint_step  100000 you can also use greedy_decode.gin or sample_decode.gin instead of beam_search.gin in the command above.decodein order to produce predictions from a model in the t5 framework  you need to specify the model directory  decoding method  and which checkpoint steps to use for decoding.',\n",
              " 'assuming you have a text file of input sequences stored at  path to intputs.txt  an example command would bet5_mesh_transformer     tpu   tpu_name       gcp_project   project       tpu_zone   zone       model_dir   model_dir       gin_file   model_dir  operative_config.gin      gin_file infer.gin      gin_file sample_decode.gin      gin_param input_filename    path to inputs.txt      gin_param output_filename    tmp outputs.txt      gin_param utils.tpu_mesh_shape.tpu_topology     tpu_size       gin_param infer_checkpoint_step   all  to predict with a specific checkpoint  simply set the infer_checkpoint_step parameter to appropriate checkpoint.',\n",
              " 'gin_param infer_checkpoint_step  100000 you can also use beam_search.gin or greedy_decode.gin instead of sample_decode.gin in the command above.exportyou may also want to export a savedmodel  which is useful for serving your trained model  e.g.',\n",
              " 'when deploying with ml engine or in a docker image.t5_mesh_transformer     gcp_project   project       tpu_zone   zone       model_dir   model_dir       use_model_api     mode export_predict      export_dir  path to export dir the command above exports the latest checkpoint in the model directory.',\n",
              " 'to export a particular checkpoint  add the following flags    checkpoint_mode specific      checkpoint_steps1000000the t5 deploy notebook demonstrates exporting a savedmodel and packaging it in a docker image for serving.gpu usageif you would like to use gpu instead of tpus  you can modify the above commands by removing tpu specific flags   tpu    tpu_zone    gcp_project and setting the gin params for mesh_shape and mesh_devices based on your desired setup.for example  if your machine has access to 6 gpus and you d like to do 3 way model parallelism and 2 way data parallelism  the fine tuning command above would becomet5_mesh_transformer      model_dir   model_dir       t5_tfds_data_dir   data_dir       gin_file dataset.gin      gin_param utils.run.mesh_shape   model3 batch2       gin_param utils.run.mesh_devices   gpu0   gpu1   gpu2   gpu3   gpu4   gpu5       gin_param mixture_name   glue_mrpc_v002       gin_file gs  t5 data pretrained_models small operative_config.gin with a single gpu  the command ist5_mesh_transformer      model_dir   model_dir       t5_tfds_data_dir   data_dir       gin_file dataset.gin      gin_param utils.run.mesh_shape   model1 batch1       gin_param utils.run.mesh_devices   gpu0       gin_param mixture_name   glue_mrpc_v002       gin_file gs  t5 data pretrained_models small operative_config.gin reproducing our experimentswe provide operative configs for all of the experiments in the paper in gs  t5 data experiments.the experiments folder has different subdirectories corresponding to the different sections in our paper.for example  gs  t5 data experiments objectives contains the experiments from section 3.3  unsupervised objectives .each subdirectory of the objectives folder contains operative configs for some particular experiment where loosely speaking an  experiment  is one of the rows in one of the tables in our paper.let s say you want to reproduce the results for the  prefix language modeling  objective the first row in table 4.the operative configs for that experiment live in gs  t5 data experiments objectives obj prefix_lm.in the base directory  there is an operative config for pre training the model gs  t5 data experiments objectives obj prefix_lm operative_config.gin.then  there are subdirectories for each of the downstream fine tuning mixtures we consider  each of which has its own operative config for example  gs  t5 data experiments objectives obj prefix_lm cnn_dailymail_v002 operative_config.gin.to run this experiment  first pre train a model with the pre training operative configexport pretrain_model_dir   bucket  obj prefix_lm t5_mesh_transformer      tpu   tpu_name       gcp_project   project       tpu_zone   zone       model_dir   pretrain_model_dir       gin_file gs  t5 data experiments objectives obj prefix_lm operative_config.gin      gin_param utils.tpu_mesh_shape.model_parallelism  1      gin_param utils.tpu_mesh_shape.tpu_topology     tpu_size   then  you can fine tune the pre trained model on cnn daily mail like soexport finetune_model_dir   bucket  obj prefix_lm cnn_dailymail_v002 t5_mesh_transformer      tpu   tpu_name       gcp_project   project       tpu_zone   zone       model_dir   finetune_model_dir       gin_file gs  t5 data experiments objectives obj prefix_lm cnn_dailymail_v002 operative_config.gin      gin_param init_checkpoint     pretrain_model_dir  model.ckpt 524288       gin_param utils.tpu_mesh_shape.model_parallelism  1      gin_param utils.tpu_mesh_shape.tpu_topology     tpu_size   useful optionssome training variants need multiple flags to be set at the same time.',\n",
              " 'for eachof the below variants  add the group of flags to.',\n",
              " 'third_party py t5 google scripts run_finetune.sh.deterministic training    train_gin_param mesh_train_dataset_fn.seed  seed       train_gin_param utils.run.skip_seen_data  true  language model    objective lm      train_gin_param utils.run.model_type   lm   released model checkpointswe have released the following checkpoints for pre trained models described in our papert5 small 60 million parameters gs  t5 data pretrained_models smallt5 base 220 million parameters gs  t5 data pretrained_models baset5 large 770 million parameters gs  t5 data pretrained_models larget5 3b 3 billion parameters gs  t5 data pretrained_models 3bt5 11b 11 billion parameters gs  t5 data pretrained_models 11bsee here for a list of additional experimental pre trained model checkpoints.how to citeif you extend or use this work  please cite the paper where it was introduced@article 2020t5   author    colin raffel and noam shazeer and adam roberts and katherine lee and sharan narang and michael matena and yanqi zhou and wei li and peter j. liu    title     exploring the limits of transfer learning with a unified text to text transformer    journal   journal of machine learning research    year      2020    volume    21    number    140    pages     1 67    url       http  jmlr.org papers v21 20 074.html']"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "sentences"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NiIHDegQvEwR"
      },
      "outputs": [],
      "source": [
        "from collections import defaultdict\n",
        "tf_score = defaultdict(int)\n",
        "for word in total_words:\n",
        "    word = word.replace('.','')\n",
        "    if word not in stop_words:\n",
        "        tf_score[word] += 1\n",
        "\n",
        "tf_score.update((x,y/int(len_total_words)) for x,y in tf_score.items())\n",
        "# tf_score\n",
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oJSqTsGrvEwR"
      },
      "outputs": [],
      "source": [
        "\n",
        "def check_sent(word,sentences):\n",
        "    final = [all([w in x for w in word]) for x in sentences]\n",
        "    sent_len = [sentences[i] for i in range(0,len(final)) if final[i]]\n",
        "    return int(len(sent_len))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6HJKDJEIvEwR",
        "outputId": "1ea67000-5570-4009-e57e-10ae2c21f52a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "defaultdict(int,\n",
              "            {'t5': 0.7591051483517427,\n",
              "             'text': 0.6720937713621129,\n",
              "             'transfer': 0.06595796779179737,\n",
              "             'transformeras': 3.8501476017100584,\n",
              "             'july': 3.8501476017100584,\n",
              "             '2022': 3.8501476017100584,\n",
              "             'recommend': 0.1365755350057507,\n",
              "             'using': 0.1365755350057507,\n",
              "             't5xt5x': 3.8501476017100584,\n",
              "             'new': 0.3536400402435784,\n",
              "             'improved': 3.8501476017100584,\n",
              "             'implementation': 0.16126814759612232,\n",
              "             'jax': 3.8501476017100584,\n",
              "             'flaxt5': 3.8501476017100584,\n",
              "             'tensorflow': 0.3536400402435784,\n",
              "             'meshtf': 3.8501476017100584,\n",
              "             'longer': 3.8501476017100584,\n",
              "             'actively': 3.8501476017100584,\n",
              "             'developed': 3.8501476017100584,\n",
              "             'newto': 3.8501476017100584,\n",
              "             'starting': 3.8501476017100584,\n",
              "             't5xthe': 3.8501476017100584,\n",
              "             'library': 0.3536400402435784,\n",
              "             'serves': 3.8501476017100584,\n",
              "             'primarily': 3.8501476017100584,\n",
              "             'code': 0.08894748601649612,\n",
              "             'reproducing': 0.1865859555804121,\n",
              "             'experiments': 0.6720937713621129,\n",
              "             'exploring': 0.714653385780909,\n",
              "             'limits': 0.1365755350057507,\n",
              "             'learning': 0.1365755350057507,\n",
              "             'unified': 0.06595796779179737,\n",
              "             'transformer': 0.1124779834266903,\n",
              "             'paper': 0.08894748601649612,\n",
              "             'demonstrate': 3.8501476017100584,\n",
              "             'achieve': 3.8501476017100584,\n",
              "             'state': 3.8501476017100584,\n",
              "             'art': 3.8501476017100584,\n",
              "             'results': 0.08894748601649612,\n",
              "             'multiple': 0.16126814759612232,\n",
              "             'nlp': 3.8501476017100584,\n",
              "             'tasks': 0.4828517717235845,\n",
              "             'pre': 0.08894748601649612,\n",
              "             'trained': 0.06595796779179737,\n",
              "             'large': 0.1365755350057507,\n",
              "             'corpusthe': 3.8501476017100584,\n",
              "             'bulk': 3.8501476017100584,\n",
              "             'repository': 3.8501476017100584,\n",
              "             'used': 0.06595796779179737,\n",
              "             'loading': 3.8501476017100584,\n",
              "             'preprocessing': 0.1865859555804121,\n",
              "             'mixing': 3.8501476017100584,\n",
              "             'evaluating': 3.8501476017100584,\n",
              "             'datasetsit': 3.8501476017100584,\n",
              "             'also': 0.08894748601649612,\n",
              "             'provides': 0.4161603972249123,\n",
              "             'way': 0.4161603972249123,\n",
              "             'fine': 0.04348511193973889,\n",
              "             'tune': 0.06595796779179737,\n",
              "             'models': 0.1365755350057507,\n",
              "             'released': 0.08894748601649612,\n",
              "             'alongside': 3.8501476017100584,\n",
              "             'publicationthe': 3.8501476017100584,\n",
              "             'future': 0.06595796779179737,\n",
              "             'model': 0.1365755350057507,\n",
              "             'development': 3.8501476017100584,\n",
              "             'providing': 3.8501476017100584,\n",
              "             'useful': 0.08894748601649612,\n",
              "             'modules': 3.8501476017100584,\n",
              "             'training': 0.1365755350057507,\n",
              "             'tuning': 0.1365755350057507,\n",
              "             'potentially': 3.8501476017100584,\n",
              "             'huge': 3.8501476017100584,\n",
              "             'mixtures': 0.6720937713621129,\n",
              "             'taskstable': 3.8501476017100584,\n",
              "             'contentslibraryusagedataset': 3.8501476017100584,\n",
              "             'preparationc4installationsetting': 3.8501476017100584,\n",
              "             'tpus': 0.08894748601649612,\n",
              "             'gcptrainingfine': 3.8501476017100584,\n",
              "             'tuningevaldecodeexportgpu': 3.8501476017100584,\n",
              "             'usagereproducing': 3.8501476017100584,\n",
              "             'experimentsuseful': 3.8501476017100584,\n",
              "             'optionsreleased': 3.8501476017100584,\n",
              "             'checkpointshow': 0.6312717768418578,\n",
              "             'citelibraryt5datat5data': 3.8501476017100584,\n",
              "             'package': 0.5543107357057295,\n",
              "             'defining': 0.1365755350057507,\n",
              "             'task': 0.4828517717235845,\n",
              "             'objects': 3.8501476017100584,\n",
              "             'provide': 0.4161603972249123,\n",
              "             'tfdatadatasetseach': 3.8501476017100584,\n",
              "             'made': 3.8501476017100584,\n",
              "             'ofa': 3.8501476017100584,\n",
              "             'data': 0.021506205220963682,\n",
              "             'sourcetext': 3.8501476017100584,\n",
              "             'preprocessor': 0.1124779834266903,\n",
              "             'functionsa': 3.8501476017100584,\n",
              "             'sentencepiece': 0.1124779834266903,\n",
              "             'modelmetric': 3.8501476017100584,\n",
              "             'functionsadditionally': 3.8501476017100584,\n",
              "             'may': 0.1865859555804121,\n",
              "             'optionally': 3.8501476017100584,\n",
              "             'providetoken': 3.8501476017100584,\n",
              "             'functionspostprocess': 3.8501476017100584,\n",
              "             'functionsthe': 3.8501476017100584,\n",
              "             'source': 0.08894748601649612,\n",
              "             'arbitrary': 3.8501476017100584,\n",
              "             'function': 0.08894748601649612,\n",
              "             'tfdatadataset': 3.8501476017100584,\n",
              "             'simpler': 3.8501476017100584,\n",
              "             'wrappers': 3.8501476017100584,\n",
              "             'datasets': 0.021506205220963682,\n",
              "             'available': 0.5179430915348546,\n",
              "             'tfds': 0.06595796779179737,\n",
              "             'tfdstask': 0.4828517717235845,\n",
              "             'stored': 0.04348511193973889,\n",
              "             'files': 0.06595796779179737,\n",
              "             'one': 0.04348511193973889,\n",
              "             'example': 0.714653385780909,\n",
              "             'per': 0.08894748601649612,\n",
              "             'line': 0.06595796779179737,\n",
              "             'textlinetaskthe': 3.8501476017100584,\n",
              "             'converts': 0.4161603972249123,\n",
              "             'examples': 0.714653385780909,\n",
              "             'dataset': 0.021506205220963682,\n",
              "             'appropriate': 0.08894748601649612,\n",
              "             'format': 0.1124779834266903,\n",
              "             'fields': 3.8501476017100584,\n",
              "             'inputs': 0.08894748601649612,\n",
              "             'targets': 0.1124779834266903,\n",
              "             'predefined': 0.08894748601649612,\n",
              "             't5datapreprocessorstranslate': 3.8501476017100584,\n",
              "             'form': 0.1124779834266903,\n",
              "             'de': 3.8501476017100584,\n",
              "             'das': 0.021506205220963682,\n",
              "             'ist': 0.021506205220963682,\n",
              "             'gut': 0.1365755350057507,\n",
              "             'en': 0.021506205220963682,\n",
              "             'good': 0.08894748601649612,\n",
              "             'translate': 3.8501476017100584,\n",
              "             'german': 3.8501476017100584,\n",
              "             'english': 0.1124779834266903,\n",
              "             'addition': 0.04348511193973889,\n",
              "             'use': 0.06595796779179737,\n",
              "             'token': 0.4828517717235845,\n",
              "             'preprocessors': 0.1124779834266903,\n",
              "             'modify': 0.1865859555804121,\n",
              "             'post': 3.8501476017100584,\n",
              "             'tokenization': 3.8501476017100584,\n",
              "             'implemented': 3.8501476017100584,\n",
              "             'unsupervised': 0.4161603972249123,\n",
              "             'objectives': 1.2110902720948,\n",
              "             'preprocessorswe': 3.8501476017100584,\n",
              "             'many': 3.8501476017100584,\n",
              "             't5datapreprocessors': 3.8501476017100584,\n",
              "             'define': 0.06595796779179737,\n",
              "             'ownthe': 3.8501476017100584,\n",
              "             'tokenize': 3.8501476017100584,\n",
              "             'input': 0.08894748601649612,\n",
              "             'strings': 3.8501476017100584,\n",
              "             'decode': 0.08894748601649612,\n",
              "             'output': 3.8501476017100584,\n",
              "             'tokens': 0.4828517717235845,\n",
              "             'create': 0.08894748601649612,\n",
              "             'google': 0.1365755350057507,\n",
              "             'default': 0.08894748601649612,\n",
              "             't5datadefault_spm_path': 3.8501476017100584,\n",
              "             'must': 0.1124779834266903,\n",
              "             'flags': 0.1365755350057507,\n",
              "             'pad_id0': 3.8501476017100584,\n",
              "             'eos_id1': 3.8501476017100584,\n",
              "             'unk_id2': 3.8501476017100584,\n",
              "             'bos_id': 3.8501476017100584,\n",
              "             '1': 1.285198244248522,\n",
              "             'spm_train': 3.8501476017100584,\n",
              "             'compatible': 3.8501476017100584,\n",
              "             'codethe': 3.8501476017100584,\n",
              "             'metric': 0.1365755350057507,\n",
              "             'returns': 3.8501476017100584,\n",
              "             'score': 3.8501476017100584,\n",
              "             'given': 3.8501476017100584,\n",
              "             'target': 0.1124779834266903,\n",
              "             'prediction': 0.1124779834266903,\n",
              "             'postprocess': 0.1124779834266903,\n",
              "             'convert': 0.4161603972249123,\n",
              "             'another': 0.06595796779179737,\n",
              "             'calling': 3.8501476017100584,\n",
              "             'metrics': 0.1365755350057507,\n",
              "             't5evaluationmetricsfinally': 3.8501476017100584,\n",
              "             't5data': 3.8501476017100584,\n",
              "             'contains': 0.08894748601649612,\n",
              "             'mixture': 0.6720937713621129,\n",
              "             'class': 3.8501476017100584,\n",
              "             'instantiated': 3.8501476017100584,\n",
              "             'combine': 3.8501476017100584,\n",
              "             'multi': 3.8501476017100584,\n",
              "             'various': 3.8501476017100584,\n",
              "             'functions': 3.8501476017100584,\n",
              "             'specifying': 3.8501476017100584,\n",
              "             'ratest5evaluationt5evaluation': 3.8501476017100584,\n",
              "             'two': 0.3536400402435784,\n",
              "             'core': 3.8501476017100584,\n",
              "             'componentsmetrics': 3.8501476017100584,\n",
              "             'evaluationutilities': 3.8501476017100584,\n",
              "             'applying': 3.8501476017100584,\n",
              "             'evaluation': 0.4161603972249123,\n",
              "             'timet5modelst5models': 3.8501476017100584,\n",
              "             'shims': 0.1124779834266903,\n",
              "             'connecting': 3.8501476017100584,\n",
              "             'inferencecurrently': 3.8501476017100584,\n",
              "             'mesh': 3.8501476017100584,\n",
              "             'hugging': 0.1365755350057507,\n",
              "             'face': 0.08894748601649612,\n",
              "             'transformers': 3.8501476017100584,\n",
              "             'librarythe': 3.8501476017100584,\n",
              "             'api': 0.08894748601649612,\n",
              "             'currently': 0.21256144198367288,\n",
              "             'experimental': 0.714653385780909,\n",
              "             'subject': 3.8501476017100584,\n",
              "             'change': 0.16126814759612232,\n",
              "             'simple': 3.8501476017100584,\n",
              "             'easy': 3.8501476017100584,\n",
              "             'load': 0.08894748601649612,\n",
              "             'evaluate': 0.4161603972249123,\n",
              "             'pytorch': 0.1865859555804121,\n",
              "             'single': 0.1124779834266903,\n",
              "             'gpuif': 3.8501476017100584,\n",
              "             'want': 0.3536400402435784,\n",
              "             'largest': 3.8501476017100584,\n",
              "             'reproduce': 0.1124779834266903,\n",
              "             'mtfmodel': 0.1365755350057507,\n",
              "             't5_mesh_transformer': 1.1420974006078486,\n",
              "             'binaryif': 3.8501476017100584,\n",
              "             'interested': 3.8501476017100584,\n",
              "             'gpu': 0.16126814759612232,\n",
              "             'try': 0.1865859555804121,\n",
              "             'hfpytorchmodel': 0.21256144198367288,\n",
              "             'apisince': 3.8501476017100584,\n",
              "             'remainder': 3.8501476017100584,\n",
              "             'readme': 3.8501476017100584,\n",
              "             'assumes': 3.8501476017100584,\n",
              "             'usage': 0.1365755350057507,\n",
              "             'associated': 3.8501476017100584,\n",
              "             'binarya': 3.8501476017100584,\n",
              "             'hereusagethe': 3.8501476017100584,\n",
              "             'easiest': 3.8501476017100584,\n",
              "             'free': 3.8501476017100584,\n",
              "             'tpu': 0.08894748601649612,\n",
              "             'colab': 3.8501476017100584,\n",
              "             'tutorialbelow': 3.8501476017100584,\n",
              "             'train': 0.06595796779179737,\n",
              "             'command': 0.1365755350057507,\n",
              "             'codebase': 3.8501476017100584,\n",
              "             'instructions': 0.08894748601649612,\n",
              "             'checkpoints': 0.5179430915348546,\n",
              "             'hyperparameters': 0.1865859555804121,\n",
              "             'scratchdataset': 3.8501476017100584,\n",
              "             'preparationyou': 3.8501476017100584,\n",
              "             'either': 3.8501476017100584,\n",
              "             'existing': 3.8501476017100584,\n",
              "             'preprocessed': 0.1124779834266903,\n",
              "             'tsv': 0.4161603972249123,\n",
              "             'fileusing': 3.8501476017100584,\n",
              "             'taskdepending': 3.8501476017100584,\n",
              "             'see': 0.0,\n",
              "             'need': 0.04348511193973889,\n",
              "             'prepare': 3.8501476017100584,\n",
              "             'appropriatelytaskif': 3.8501476017100584,\n",
              "             'vanilla': 3.8501476017100584,\n",
              "             'make': 3.8501476017100584,\n",
              "             'sure': 0.06595796779179737,\n",
              "             'loaded': 3.8501476017100584,\n",
              "             'dataset_fn': 3.8501476017100584,\n",
              "             'accessible': 0.26662866325394863,\n",
              "             'ie': 0.0,\n",
              "             'gcs': 0.1365755350057507,\n",
              "             'bucket': 0.5179430915348546,\n",
              "             'go': 0.08894748601649612,\n",
              "             'tfdstaskmost': 3.8501476017100584,\n",
              "             'run': 0.06595796779179737,\n",
              "             'binary': 3.8501476017100584,\n",
              "             'automatically': 3.8501476017100584,\n",
              "             'downloaded': 3.8501476017100584,\n",
              "             'prepared': 3.8501476017100584,\n",
              "             'first': 0.06595796779179737,\n",
              "             'preparation': 0.08894748601649612,\n",
              "             'complete': 0.1865859555804121,\n",
              "             'cached': 3.8501476017100584,\n",
              "             'local': 3.8501476017100584,\n",
              "             'storage': 0.1124779834266903,\n",
              "             'avoid': 3.8501476017100584,\n",
              "             'overhead': 3.8501476017100584,\n",
              "             'runs': 3.8501476017100584,\n",
              "             'working': 3.8501476017100584,\n",
              "             'cloud': 0.1124779834266903,\n",
              "             'set': 0.021506205220963682,\n",
              "             't5_tfds_data_dir': 1.1420974006078486,\n",
              "             'flag': 0.1365755350057507,\n",
              "             'point': 3.8501476017100584,\n",
              "             'persistent': 3.8501476017100584,\n",
              "             'location': 3.8501476017100584,\n",
              "             'requirement': 3.8501476017100584,\n",
              "             'tpuc4the': 3.8501476017100584,\n",
              "             'c4': 3.8501476017100584,\n",
              "             'created': 3.8501476017100584,\n",
              "             'requires': 3.8501476017100584,\n",
              "             'significant': 3.8501476017100584,\n",
              "             'amount': 3.8501476017100584,\n",
              "             'bandwidth': 3.8501476017100584,\n",
              "             'downloading': 3.8501476017100584,\n",
              "             'raw': 3.8501476017100584,\n",
              "             'common': 3.8501476017100584,\n",
              "             'crawl': 3.8501476017100584,\n",
              "             'scrapes': 3.8501476017100584,\n",
              "             '7': 3.8501476017100584,\n",
              "             'tb': 3.8501476017100584,\n",
              "             'compute': 3.8501476017100584,\n",
              "             '335': 3.8501476017100584,\n",
              "             'cpu': 3.8501476017100584,\n",
              "             'days': 3.8501476017100584,\n",
              "             'suggest': 3.8501476017100584,\n",
              "             'take': 3.8501476017100584,\n",
              "             'advantage': 3.8501476017100584,\n",
              "             'apache': 3.8501476017100584,\n",
              "             'beam': 0.3237870770938972,\n",
              "             'support': 3.8501476017100584,\n",
              "             'enables': 3.8501476017100584,\n",
              "             'distributed': 3.8501476017100584,\n",
              "             'dataflow': 0.3536400402435784,\n",
              "             '500': 3.8501476017100584,\n",
              "             'workers': 3.8501476017100584,\n",
              "             'job': 3.8501476017100584,\n",
              "             '16': 3.8501476017100584,\n",
              "             'hoursafter': 3.8501476017100584,\n",
              "             'my_project': 1.452252328911688,\n",
              "             'my_bucket': 1.0169342576538425,\n",
              "             'appropriately': 0.21256144198367288,\n",
              "             'build': 3.8501476017100584,\n",
              "             'gcp': 3.8501476017100584,\n",
              "             'following': 0.3536400402435784,\n",
              "             'commandspip': 3.8501476017100584,\n",
              "             'install': 0.08894748601649612,\n",
              "             'nightlyc4echo': 3.8501476017100584,\n",
              "             'nightlyc4': 3.8501476017100584,\n",
              "             'tmp': 0.1365755350057507,\n",
              "             'beam_requirementstxtpython': 3.8501476017100584,\n",
              "             'tensorflow_datasetsscriptsdownload_and_prepare': 3.8501476017100584,\n",
              "             'datasetsc4': 3.8501476017100584,\n",
              "             'data_dirgs': 3.8501476017100584,\n",
              "             'tensorflow_datasets': 3.8501476017100584,\n",
              "             'beam_pipeline_options': 3.8501476017100584,\n",
              "             'project': 1.1420974006078486,\n",
              "             'job_namec4': 3.8501476017100584,\n",
              "             'staging_locationgs': 3.8501476017100584,\n",
              "             'binaries': 3.8501476017100584,\n",
              "             'temp_locationgs': 3.8501476017100584,\n",
              "             'temp': 3.8501476017100584,\n",
              "             'runnerdataflowrunner': 3.8501476017100584,\n",
              "             'requirements_file': 3.8501476017100584,\n",
              "             'beam_requirementstxt': 3.8501476017100584,\n",
              "             'experimentsshuffle_modeservice': 3.8501476017100584,\n",
              "             'region': 3.8501476017100584,\n",
              "             'my_region': 3.8501476017100584,\n",
              "             'read': 3.8501476017100584,\n",
              "             'instructionstextlinetaska': 3.8501476017100584,\n",
              "             'textlinetask': 3.8501476017100584,\n",
              "             'file': 0.06595796779179737,\n",
              "             'dictionary': 3.8501476017100584,\n",
              "             'targetsmake': 3.8501476017100584,\n",
              "             'directlyinstead': 3.8501476017100584,\n",
              "             'directly': 3.8501476017100584,\n",
              "             'formatted': 0.1124779834266903,\n",
              "             'inputttargethowever': 3.8501476017100584,\n",
              "             'couple': 3.8501476017100584,\n",
              "             'caveatsthere': 3.8501476017100584,\n",
              "             'processor': 3.8501476017100584,\n",
              "             'contain': 3.8501476017100584,\n",
              "             'formatthere': 3.8501476017100584,\n",
              "             'directlyif': 3.8501476017100584,\n",
              "             'features': 3.8501476017100584,\n",
              "             'textlinetasksimilar': 3.8501476017100584,\n",
              "             'cases': 3.8501476017100584,\n",
              "             'bucketinstallationto': 3.8501476017100584,\n",
              "             'simply': 0.21256144198367288,\n",
              "             'runpip': 3.8501476017100584,\n",
              "             't5gcpsetting': 3.8501476017100584,\n",
              "             'gcpyou': 3.8501476017100584,\n",
              "             'launch': 3.8501476017100584,\n",
              "             'virtual': 3.8501476017100584,\n",
              "             'machine': 0.1365755350057507,\n",
              "             'vm': 0.4828517717235845,\n",
              "             'details': 3.8501476017100584,\n",
              "             'launching': 3.8501476017100584,\n",
              "             'found': 3.8501476017100584,\n",
              "             'documentationin': 3.8501476017100584,\n",
              "             'order': 0.04348511193973889,\n",
              "             'eval': 3.8501476017100584,\n",
              "             'variables': 3.8501476017100584,\n",
              "             'based': 0.26662866325394863,\n",
              "             'zone': 1.285198244248522,\n",
              "             'please': 0.1124779834266903,\n",
              "             'refer': 3.8501476017100584,\n",
              "             'quickstart': 3.8501476017100584,\n",
              "             'guide': 3.8501476017100584,\n",
              "             'detailsexport': 3.8501476017100584,\n",
              "             'projectyour_project_nameexport': 3.8501476017100584,\n",
              "             'zoneyour_project_zoneexport': 3.8501476017100584,\n",
              "             'bucketgs': 3.8501476017100584,\n",
              "             'yourbucket': 3.8501476017100584,\n",
              "             'export': 0.6720937713621129,\n",
              "             'tpu_namet5': 3.8501476017100584,\n",
              "             'tpuexport': 3.8501476017100584,\n",
              "             'tpu_sizev3': 3.8501476017100584,\n",
              "             '8export': 3.8501476017100584,\n",
              "             'data_dir': 0.8544153281560676,\n",
              "             'your_data_dir': 3.8501476017100584,\n",
              "             'model_dir': 0.9057086225436182,\n",
              "             'your_model_dir': 3.8501476017100584,\n",
              "             'device': 3.8501476017100584,\n",
              "             'vmctpu': 3.8501476017100584,\n",
              "             'name': 3.8501476017100584,\n",
              "             'tpu_name': 0.9057086225436182,\n",
              "             'size': 1.285198244248522,\n",
              "             'tpu_size': 1.6529230243738393,\n",
              "             'noconftrainingin': 3.8501476017100584,\n",
              "             'glue': 0.1365755350057507,\n",
              "             'benchmark': 3.8501476017100584,\n",
              "             'mrpc': 0.16126814759612232,\n",
              "             'scratch': 3.8501476017100584,\n",
              "             'mixture_name': 1.2110902720948,\n",
              "             'gin': 0.08894748601649612,\n",
              "             'parameter': 0.1365755350057507,\n",
              "             'provided': 3.8501476017100584,\n",
              "             'packaget5_mesh_transformer': 3.8501476017100584,\n",
              "             'gcp_project': 1.452252328911688,\n",
              "             'tpu_zone': 1.6529230243738393,\n",
              "             'gin_file': 0.8544153281560676,\n",
              "             'datasetgin': 0.1124779834266903,\n",
              "             'bi_v1gin': 3.8501476017100584,\n",
              "             'gin_param': 0.9057086225436182,\n",
              "             'utilstpu_mesh_shapemodel_parallelism': 0.9057086225436182,\n",
              "             'utilstpu_mesh_shapetpu_topology': 0.9057086225436182,\n",
              "             'glue_mrpc_v002': 1.9042374526547452,\n",
              "             'full': 3.8501476017100584,\n",
              "             'list': 0.08894748601649612,\n",
              "             'obtained': 3.8501476017100584,\n",
              "             'runningpython': 3.8501476017100584,\n",
              "             'c': 3.8501476017100584,\n",
              "             'import': 0.1365755350057507,\n",
              "             't5;': 3.8501476017100584,\n",
              "             'printt5datamixtureregistrynames': 3.8501476017100584,\n",
              "             'additional': 0.08894748601649612,\n",
              "             'module_import': 0.9057086225436182,\n",
              "             'flagalternatively': 0.5179430915348546,\n",
              "             'could': 0.1124779834266903,\n",
              "             'inputttarget': 0.16126814759612232,\n",
              "             'abovefine': 3.8501476017100584,\n",
              "             'tuningin': 3.8501476017100584,\n",
              "             'pass': 0.08894748601649612,\n",
              "             'operative': 0.4161603972249123,\n",
              "             'config': 0.16126814759612232,\n",
              "             'script': 3.8501476017100584,\n",
              "             'passed': 3.8501476017100584,\n",
              "             'specifies': 3.8501476017100584,\n",
              "             'architecture': 3.8501476017100584,\n",
              "             'specify': 0.1865859555804121,\n",
              "             'small': 0.1365755350057507,\n",
              "             'runt5_mesh_transformer': 3.8501476017100584,\n",
              "             'gs': 0.06595796779179737,\n",
              "             'pretrained_models': 0.9057086225436182,\n",
              "             'operative_configgin': 1.0169342576538425,\n",
              "             'correct': 3.8501476017100584,\n",
              "             'checkpoint': 0.5179430915348546,\n",
              "             'path': 0.08894748601649612,\n",
              "             'included': 0.1124779834266903,\n",
              "             'configyou': 3.8501476017100584,\n",
              "             'paired': 3.8501476017100584,\n",
              "             'translation': 3.8501476017100584,\n",
              "             'wmt': 3.8501476017100584,\n",
              "             '19': 3.8501476017100584,\n",
              "             'news': 3.8501476017100584,\n",
              "             'commentary': 3.8501476017100584,\n",
              "             '14': 3.8501476017100584,\n",
              "             'seteg': 3.8501476017100584,\n",
              "             'french': 3.8501476017100584,\n",
              "             'would': 0.3536400402435784,\n",
              "             'replace': 3.8501476017100584,\n",
              "             'utilsruntrain_dataset_fn': 3.8501476017100584,\n",
              "             '@t5modelsmesh_transformertsv_dataset_fn': 3.8501476017100584,\n",
              "             'tsv_dataset_fnfilename': 3.8501476017100584,\n",
              "             'constant': 3.8501476017100584,\n",
              "             'rate': 3.8501476017100584,\n",
              "             '0001': 3.8501476017100584,\n",
              "             'learning_rate_schedules': 3.8501476017100584,\n",
              "             'constant_0_001gin': 3.8501476017100584,\n",
              "             'effectively': 3.8501476017100584,\n",
              "             'limit': 3.8501476017100584,\n",
              "             'number': 0.3237870770938972,\n",
              "             'steps': 0.08894748601649612,\n",
              "             'like': 0.4828517717235845,\n",
              "             'specific': 0.1124779834266903,\n",
              "             'since': 3.8501476017100584,\n",
              "             'already': 3.8501476017100584,\n",
              "             '000': 1.2110902720948,\n",
              "             'total': 0.08894748601649612,\n",
              "             '10': 3.8501476017100584,\n",
              "             'runtrain_steps': 3.8501476017100584,\n",
              "             '1010000': 3.8501476017100584,\n",
              "             'different': 0.06595796779179737,\n",
              "             'batch': 0.26662866325394863,\n",
              "             'according': 3.8501476017100584,\n",
              "             'uses': 3.8501476017100584,\n",
              "             'sequence': 3.8501476017100584,\n",
              "             'length': 3.8501476017100584,\n",
              "             '512': 3.8501476017100584,\n",
              "             'tokens_per_batch1048576': 3.8501476017100584,\n",
              "             'evalin': 3.8501476017100584,\n",
              "             'framework': 0.5920510636885765,\n",
              "             'evalgin': 0.4161603972249123,\n",
              "             'directory': 0.1865859555804121,\n",
              "             'decoding': 0.16126814759612232,\n",
              "             'method': 0.1124779834266903,\n",
              "             'search': 3.8501476017100584,\n",
              "             'commandt5_mesh_transformer': 3.8501476017100584,\n",
              "             'beam_searchgin': 0.9057086225436182,\n",
              "             'rundataset_split': 3.8501476017100584,\n",
              "             'validation': 3.8501476017100584,\n",
              "             'eval_checkpoint_step': 1.0775588794702773,\n",
              "             '100000': 1.3652409519220583,\n",
              "             'greedy_decodegin': 0.9057086225436182,\n",
              "             'sample_decodegin': 0.9057086225436182,\n",
              "             'instead': 0.04348511193973889,\n",
              "             'abovedecodein': 3.8501476017100584,\n",
              "             'produce': 3.8501476017100584,\n",
              "             'predictions': 3.8501476017100584,\n",
              "             'assuming': 3.8501476017100584,\n",
              "             'sequences': 3.8501476017100584,\n",
              "             'intputstxt': 3.8501476017100584,\n",
              "             'bet5_mesh_transformer': 3.8501476017100584,\n",
              "             'infergin': 3.8501476017100584,\n",
              "             'input_filename': 3.8501476017100584,\n",
              "             'inputstxt': 3.8501476017100584,\n",
              "             'output_filename': 3.8501476017100584,\n",
              "             'outputstxt': 3.8501476017100584,\n",
              "             'infer_checkpoint_step': 1.0169342576538425,\n",
              "             'predict': 3.8501476017100584,\n",
              "             'aboveexportyou': 3.8501476017100584,\n",
              "             'savedmodel': 0.4828517717235845,\n",
              "             'serving': 3.8501476017100584,\n",
              "             'eg': 3.8501476017100584,\n",
              "             'deploying': 3.8501476017100584,\n",
              "             'ml': 3.8501476017100584,\n",
              "             'engine': 3.8501476017100584,\n",
              "             'docker': 0.4828517717235845,\n",
              "             'imaget5_mesh_transformer': 3.8501476017100584,\n",
              "             'use_model_api': 3.8501476017100584,\n",
              "             'mode': 3.8501476017100584,\n",
              "             'export_predict': 3.8501476017100584,\n",
              "             'export_dir': 3.8501476017100584,\n",
              "             'dir': 3.8501476017100584,\n",
              "             'exports': 3.8501476017100584,\n",
              "             'latest': 3.8501476017100584,\n",
              "             'particular': 0.1365755350057507,\n",
              "             'add': 0.021506205220963682,\n",
              "             'checkpoint_mode': 3.8501476017100584,\n",
              "             'checkpoint_steps1000000the': 3.8501476017100584,\n",
              "             'deploy': 3.8501476017100584,\n",
              "             'notebook': 3.8501476017100584,\n",
              "             'demonstrates': 3.8501476017100584,\n",
              "             'exporting': 3.8501476017100584,\n",
              "             'packaging': 3.8501476017100584,\n",
              "             'image': 3.8501476017100584,\n",
              "             'servinggpu': 3.8501476017100584,\n",
              "             'usageif': 3.8501476017100584,\n",
              "             'commands': 3.8501476017100584,\n",
              "             'removing': 3.8501476017100584,\n",
              "             'setting': 3.8501476017100584,\n",
              "             'params': 3.8501476017100584,\n",
              "             'mesh_shape': 3.8501476017100584,\n",
              "             'mesh_devices': 3.8501476017100584,\n",
              "             'desired': 3.8501476017100584,\n",
              "             'setupfor': 3.8501476017100584,\n",
              "             'access': 3.8501476017100584,\n",
              "             '6': 3.8501476017100584,\n",
              "             'gpus': 3.8501476017100584,\n",
              "             '3': 2.463853240590168,\n",
              "             'parallelism': 0.16126814759612232,\n",
              "             '2': 3.8501476017100584,\n",
              "             'becomet5_mesh_transformer': 3.8501476017100584,\n",
              "             'utilsrunmesh_shape': 0.9057086225436182,\n",
              "             'model3': 3.8501476017100584,\n",
              "             'batch2': 3.8501476017100584,\n",
              "             'utilsrunmesh_devices': 1.0775588794702773,\n",
              "             'gpu0': 1.2110902720948,\n",
              "             'gpu1': 3.8501476017100584,\n",
              "             'gpu2': 3.8501476017100584,\n",
              "             'gpu3': 3.8501476017100584,\n",
              "             'gpu4': 3.8501476017100584,\n",
              "             'gpu5': 3.8501476017100584,\n",
              "             'ist5_mesh_transformer': 3.8501476017100584,\n",
              "             'model1': 3.8501476017100584,\n",
              "             'batch1': 3.8501476017100584,\n",
              "             'experimentswe': 3.8501476017100584,\n",
              "             'configs': 0.16126814759612232,\n",
              "             'experimentsthe': 3.8501476017100584,\n",
              "             'folder': 0.08894748601649612,\n",
              "             'subdirectories': 0.26662866325394863,\n",
              "             'corresponding': 3.8501476017100584,\n",
              "             'sections': 3.8501476017100584,\n",
              "             'paperfor': 3.8501476017100584,\n",
              "             'section': 3.8501476017100584,\n",
              "             '33': 3.8501476017100584,\n",
              "             'subdirectory': 3.8501476017100584,\n",
              "             'experiment': 0.6720937713621129,\n",
              "             'loosely': 3.8501476017100584,\n",
              "             'speaking': 3.8501476017100584,\n",
              "             'rows': 3.8501476017100584,\n",
              "             'tables': 3.8501476017100584,\n",
              "             'paperlet': 3.8501476017100584,\n",
              "             'say': 3.8501476017100584,\n",
              "             'prefix': 3.8501476017100584,\n",
              "             'language': 0.1365755350057507,\n",
              "             'modeling': 3.8501476017100584,\n",
              "             'objective': 1.2110902720948,\n",
              "             'row': 3.8501476017100584,\n",
              "             'table': 3.8501476017100584,\n",
              "             '4the': 3.8501476017100584,\n",
              "             'live': 3.8501476017100584,\n",
              "             'obj': 1.2110902720948,\n",
              "             'prefix_lmin': 3.8501476017100584,\n",
              "             'base': 0.26662866325394863,\n",
              "             'prefix_lm': 1.2110902720948,\n",
              "             'operative_configginthen': 3.8501476017100584,\n",
              "             'downstream': 3.8501476017100584,\n",
              "             'consider': 3.8501476017100584,\n",
              "             'cnn_dailymail_v002': 1.9042374526547452,\n",
              "             'operative_configginto': 3.8501476017100584,\n",
              "             'configexport': 3.8501476017100584,\n",
              "             'pretrain_model_dir': 0.9057086225436182,\n",
              "             'cnn': 3.8501476017100584,\n",
              "             'daily': 3.8501476017100584,\n",
              "             'mail': 3.8501476017100584,\n",
              "             'soexport': 3.8501476017100584,\n",
              "             'finetune_model_dir': 0.9057086225436182,\n",
              "             'init_checkpoint': 3.8501476017100584,\n",
              "             'modelckpt': 3.8501476017100584,\n",
              "             '524288': 3.8501476017100584,\n",
              "             'optionssome': 3.8501476017100584,\n",
              "             'variants': 0.4161603972249123,\n",
              "             'time': 3.8501476017100584,\n",
              "             'eachof': 3.8501476017100584,\n",
              "             'group': 3.8501476017100584,\n",
              "             'third_party': 3.8501476017100584,\n",
              "             'py': 3.8501476017100584,\n",
              "             'scripts': 3.8501476017100584,\n",
              "             'run_finetuneshdeterministic': 3.8501476017100584,\n",
              "             'train_gin_param': 0.9057086225436182,\n",
              "             'mesh_train_dataset_fnseed': 3.8501476017100584,\n",
              "             'seed': 3.8501476017100584,\n",
              "             'utilsrunskip_seen_data': 3.8501476017100584,\n",
              "             'true': 3.8501476017100584,\n",
              "             'lm': 0.1365755350057507,\n",
              "             'utilsrunmodel_type': 3.8501476017100584,\n",
              "             'checkpointswe': 3.8501476017100584,\n",
              "             'described': 3.8501476017100584,\n",
              "             'papert5': 3.8501476017100584,\n",
              "             '60': 3.8501476017100584,\n",
              "             'million': 0.1365755350057507,\n",
              "             'parameters': 0.1365755350057507,\n",
              "             'smallt5': 3.8501476017100584,\n",
              "             '220': 3.8501476017100584,\n",
              "             'baset5': 3.8501476017100584,\n",
              "             '770': 3.8501476017100584,\n",
              "             'larget5': 3.8501476017100584,\n",
              "             '3b': 3.8501476017100584,\n",
              "             'billion': 0.26662866325394863,\n",
              "             '3bt5': 3.8501476017100584,\n",
              "             '11b': 3.8501476017100584,\n",
              "             '11': 3.8501476017100584,\n",
              "             '11bsee': 3.8501476017100584,\n",
              "             'citeif': 3.8501476017100584,\n",
              "             'extend': 3.8501476017100584,\n",
              "             'work': 3.8501476017100584,\n",
              "             'cite': 3.8501476017100584,\n",
              "             'introduced@article': 3.8501476017100584,\n",
              "             '2020t5': 3.8501476017100584,\n",
              "             'author': 3.8501476017100584,\n",
              "             'colin': 3.8501476017100584,\n",
              "             'raffel': 3.8501476017100584,\n",
              "             'noam': 3.8501476017100584,\n",
              "             'shazeer': 3.8501476017100584,\n",
              "             'adam': 3.8501476017100584,\n",
              "             'roberts': 3.8501476017100584,\n",
              "             'katherine': 3.8501476017100584,\n",
              "             'lee': 3.8501476017100584,\n",
              "             'sharan': 3.8501476017100584,\n",
              "             'narang': 3.8501476017100584,\n",
              "             'michael': 3.8501476017100584,\n",
              "             'matena': 3.8501476017100584,\n",
              "             'yanqi': 3.8501476017100584,\n",
              "             'zhou': 3.8501476017100584,\n",
              "             'wei': 3.8501476017100584,\n",
              "             'li': 3.8501476017100584,\n",
              "             'peter': 3.8501476017100584,\n",
              "             'j': 3.8501476017100584,\n",
              "             'liu': 3.8501476017100584,\n",
              "             'title': 3.8501476017100584,\n",
              "             'journal': 1.1420974006078486,\n",
              "             'research': 3.8501476017100584,\n",
              "             'year': 3.8501476017100584,\n",
              "             '2020': 3.8501476017100584,\n",
              "             'volume': 3.8501476017100584,\n",
              "             '21': 3.8501476017100584,\n",
              "             '140': 3.8501476017100584,\n",
              "             'pages': 3.8501476017100584,\n",
              "             '67': 3.8501476017100584,\n",
              "             'url': 3.8501476017100584,\n",
              "             'http': 3.8501476017100584,\n",
              "             'jmlrorg': 3.8501476017100584,\n",
              "             'papers': 3.8501476017100584,\n",
              "             'v21': 3.8501476017100584,\n",
              "             '20': 3.8501476017100584,\n",
              "             '074html': 3.8501476017100584})"
            ]
          },
          "execution_count": 188,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "idf_score = defaultdict(int)\n",
        "for word in total_words:\n",
        "    word = word.replace('.','')\n",
        "    if word not in stop_words:\n",
        "        if word in idf_score:\n",
        "            idf_score[word] = check_sent(word,sentences)\n",
        "        else:\n",
        "            idf_score[word] = 1\n",
        "\n",
        "idf_score.update((x,math.log(int(len_sentences)/y)) for x,y in idf_score.items())\n",
        "idf_score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Wb7I37O5vEwS",
        "outputId": "c81f4769-3e18-40da-f1cc-954b2598189d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'t5': 0.008408727770130076,\n",
              " 'text': 0.005391126508252243,\n",
              " 'transfer': 7.558208685079913e-05,\n",
              " 'transformeras': 0.0014706446148625128,\n",
              " 'july': 0.0014706446148625128,\n",
              " '2022': 0.0014706446148625128,\n",
              " 'recommend': 0.00015650366883775864,\n",
              " 'using': 0.0007303504545762069,\n",
              " 't5xt5x': 0.0014706446148625128,\n",
              " 'new': 0.0008104813756537321,\n",
              " 'improved': 0.0014706446148625128,\n",
              " 'implementation': 0.00012319950160131574,\n",
              " 'jax': 0.0014706446148625128,\n",
              " 'flaxt5': 0.0014706446148625128,\n",
              " 'tensorflow': 0.0006754011463781101,\n",
              " 'meshtf': 0.0014706446148625128,\n",
              " 'longer': 0.0014706446148625128,\n",
              " 'actively': 0.0014706446148625128,\n",
              " 'developed': 0.0014706446148625128,\n",
              " 'newto': 0.0014706446148625128,\n",
              " 'starting': 0.0014706446148625128,\n",
              " 't5xthe': 0.0014706446148625128,\n",
              " 'library': 0.00040524068782686606,\n",
              " 'serves': 0.0014706446148625128,\n",
              " 'primarily': 0.0014706446148625128,\n",
              " 'code': 6.79507150622583e-05,\n",
              " 'reproducing': 0.0001425408369598259,\n",
              " 'experiments': 0.0025672030991677345,\n",
              " 'exploring': 0.000545953694255851,\n",
              " 'limits': 0.00010433577922517242,\n",
              " 'learning': 0.00020867155845034484,\n",
              " 'unified': 5.038805790053275e-05,\n",
              " 'transformer': 0.00017185329782534804,\n",
              " 'paper': 0.00020385214518677493,\n",
              " 'demonstrate': 0.0014706446148625128,\n",
              " 'achieve': 0.0014706446148625128,\n",
              " 'state': 0.0014706446148625128,\n",
              " 'art': 0.0014706446148625128,\n",
              " 'results': 0.0001359014301245166,\n",
              " 'multiple': 0.00018479925240197365,\n",
              " 'nlp': 0.0014706446148625128,\n",
              " 'tasks': 0.0012910475179774986,\n",
              " 'pre': 0.0006795071506225831,\n",
              " 'trained': 0.0003275223763534629,\n",
              " 'large': 0.00010433577922517242,\n",
              " 'corpusthe': 0.0014706446148625128,\n",
              " 'bulk': 0.0014706446148625128,\n",
              " 'repository': 0.0014706446148625128,\n",
              " 'used': 0.00015116417370159826,\n",
              " 'loading': 0.0014706446148625128,\n",
              " 'preprocessing': 0.00021381125543973886,\n",
              " 'mixing': 0.0014706446148625128,\n",
              " 'evaluating': 0.0014706446148625128,\n",
              " 'datasetsit': 0.0014706446148625128,\n",
              " 'also': 0.00040770429037354986,\n",
              " 'provides': 0.00047688357206827236,\n",
              " 'way': 0.0011127283348259687,\n",
              " 'fine': 0.00028237085675155126,\n",
              " 'tune': 0.0002771343184529301,\n",
              " 'models': 0.0004695110065132759,\n",
              " 'released': 0.0001359014301245166,\n",
              " 'alongside': 0.0014706446148625128,\n",
              " 'publicationthe': 0.0014706446148625128,\n",
              " 'future': 5.038805790053275e-05,\n",
              " 'model': 0.0014607009091524138,\n",
              " 'development': 0.0014706446148625128,\n",
              " 'providing': 0.0014706446148625128,\n",
              " 'useful': 0.0001359014301245166,\n",
              " 'modules': 0.0014706446148625128,\n",
              " 'training': 0.0007825183441887932,\n",
              " 'tuning': 0.0003130073376755173,\n",
              " 'potentially': 0.0014706446148625128,\n",
              " 'huge': 0.0014706446148625128,\n",
              " 'mixtures': 0.0017970421694174141,\n",
              " 'taskstable': 0.0014706446148625128,\n",
              " 'contentslibraryusagedataset': 0.0014706446148625128,\n",
              " 'preparationc4installationsetting': 0.0014706446148625128,\n",
              " 'tpus': 0.00016987678765564577,\n",
              " 'gcptrainingfine': 0.0014706446148625128,\n",
              " 'tuningevaldecodeexportgpu': 0.0014706446148625128,\n",
              " 'usagereproducing': 0.0014706446148625128,\n",
              " 'experimentsuseful': 0.0014706446148625128,\n",
              " 'optionsreleased': 0.0014706446148625128,\n",
              " 'checkpointshow': 0.0004822549861282336,\n",
              " 'citelibraryt5datat5data': 0.0014706446148625128,\n",
              " 'package': 0.0006351918285397971,\n",
              " 'defining': 0.00015650366883775864,\n",
              " 'task': 0.0018443535971107124,\n",
              " 'objects': 0.0014706446148625128,\n",
              " 'provide': 0.0009537671441365447,\n",
              " 'tfdatadatasetseach': 0.0014706446148625128,\n",
              " 'made': 0.0014706446148625128,\n",
              " 'ofa': 0.0014706446148625128,\n",
              " 'data': 0.0001971539057689566,\n",
              " 'sourcetext': 0.0014706446148625128,\n",
              " 'preprocessor': 0.0002577799467380221,\n",
              " 'functionsa': 0.0014706446148625128,\n",
              " 'sentencepiece': 0.00012888997336901105,\n",
              " 'modelmetric': 0.0014706446148625128,\n",
              " 'functionsadditionally': 0.0014706446148625128,\n",
              " 'may': 0.0006414337663192166,\n",
              " 'optionally': 0.0014706446148625128,\n",
              " 'providetoken': 0.0014706446148625128,\n",
              " 'functionspostprocess': 0.0014706446148625128,\n",
              " 'functionsthe': 0.0014706446148625128,\n",
              " 'source': 0.00016987678765564577,\n",
              " 'arbitrary': 0.0014706446148625128,\n",
              " 'function': 0.00016987678765564577,\n",
              " 'tfdatadataset': 0.0014706446148625128,\n",
              " 'simpler': 0.0014706446148625128,\n",
              " 'wrappers': 0.0014706446148625128,\n",
              " 'datasets': 4.928847644223915e-05,\n",
              " 'available': 0.0007913569007408015,\n",
              " 'tfds': 0.00015116417370159826,\n",
              " 'tfdstask': 0.0005533060791332138,\n",
              " 'stored': 3.322010079430014e-05,\n",
              " 'files': 0.00015116417370159826,\n",
              " 'one': 0.00016610050397150073,\n",
              " 'example': 0.0030027453184071806,\n",
              " 'per': 6.79507150622583e-05,\n",
              " 'line': 0.0001763582026518646,\n",
              " 'textlinetaskthe': 0.0014706446148625128,\n",
              " 'converts': 0.0003179223813788482,\n",
              " 'examples': 0.0008189305413837766,\n",
              " 'dataset': 5.750322251594567e-05,\n",
              " 'appropriate': 0.00010192607259338746,\n",
              " 'format': 8.592664891267402e-05,\n",
              " 'fields': 0.0014706446148625128,\n",
              " 'inputs': 0.00016987678765564577,\n",
              " 'targets': 8.592664891267402e-05,\n",
              " 'predefined': 0.0001359014301245166,\n",
              " 't5datapreprocessorstranslate': 0.0014706446148625128,\n",
              " 'form': 8.592664891267402e-05,\n",
              " 'de': 0.0014706446148625128,\n",
              " 'das': 1.6429492147413048e-05,\n",
              " 'ist': 1.6429492147413048e-05,\n",
              " 'gut': 0.00010433577922517242,\n",
              " 'en': 1.6429492147413048e-05,\n",
              " 'good': 0.0001359014301245166,\n",
              " 'translate': 0.0014706446148625128,\n",
              " 'german': 0.0014706446148625128,\n",
              " 'english': 8.592664891267402e-05,\n",
              " 'addition': 3.322010079430014e-05,\n",
              " 'use': 0.0005290746079555939,\n",
              " 'token': 0.0005533060791332138,\n",
              " 'preprocessors': 8.592664891267402e-05,\n",
              " 'modify': 0.0001425408369598259,\n",
              " 'post': 0.0014706446148625128,\n",
              " 'tokenization': 0.0014706446148625128,\n",
              " 'implemented': 0.0014706446148625128,\n",
              " 'unsupervised': 0.00047688357206827236,\n",
              " 'objectives': 0.004163411936154775,\n",
              " 'preprocessorswe': 0.0014706446148625128,\n",
              " 'many': 0.0014706446148625128,\n",
              " 't5datapreprocessors': 0.0014706446148625128,\n",
              " 'define': 0.00015116417370159826,\n",
              " 'ownthe': 0.0014706446148625128,\n",
              " 'tokenize': 0.0014706446148625128,\n",
              " 'input': 6.79507150622583e-05,\n",
              " 'strings': 0.0014706446148625128,\n",
              " 'decode': 6.79507150622583e-05,\n",
              " 'output': 0.0014706446148625128,\n",
              " 'tokens': 0.0005533060791332138,\n",
              " 'create': 0.00010192607259338746,\n",
              " 'google': 0.00026083944806293106,\n",
              " 'default': 6.79507150622583e-05,\n",
              " 't5datadefault_spm_path': 0.0014706446148625128,\n",
              " 'must': 0.00017185329782534804,\n",
              " 'flags': 0.00026083944806293106,\n",
              " 'pad_id0': 0.0014706446148625128,\n",
              " 'eos_id1': 0.0014706446148625128,\n",
              " 'unk_id2': 0.0014706446148625128,\n",
              " 'bos_id': 0.0014706446148625128,\n",
              " '1': 0.0034363589418409677,\n",
              " 'spm_train': 0.0014706446148625128,\n",
              " 'compatible': 0.0014706446148625128,\n",
              " 'codethe': 0.0014706446148625128,\n",
              " 'metric': 0.00015650366883775864,\n",
              " 'returns': 0.0014706446148625128,\n",
              " 'score': 0.0014706446148625128,\n",
              " 'given': 0.0014706446148625128,\n",
              " 'target': 8.592664891267402e-05,\n",
              " 'prediction': 8.592664891267402e-05,\n",
              " 'postprocess': 8.592664891267402e-05,\n",
              " 'convert': 0.0003179223813788482,\n",
              " 'another': 5.038805790053275e-05,\n",
              " 'calling': 0.0014706446148625128,\n",
              " 'metrics': 0.00010433577922517242,\n",
              " 't5evaluationmetricsfinally': 0.0014706446148625128,\n",
              " 't5data': 0.0014706446148625128,\n",
              " 'contains': 0.00016987678765564577,\n",
              " 'mixture': 0.0010268812396670938,\n",
              " 'class': 0.0014706446148625128,\n",
              " 'instantiated': 0.0014706446148625128,\n",
              " 'combine': 0.0014706446148625128,\n",
              " 'multi': 0.0014706446148625128,\n",
              " 'various': 0.0014706446148625128,\n",
              " 'functions': 0.0014706446148625128,\n",
              " 'specifying': 0.0014706446148625128,\n",
              " 'ratest5evaluationt5evaluation': 0.0014706446148625128,\n",
              " 'two': 0.00027016045855124404,\n",
              " 'core': 0.0014706446148625128,\n",
              " 'componentsmetrics': 0.0014706446148625128,\n",
              " 'evaluationutilities': 0.0014706446148625128,\n",
              " 'applying': 0.0014706446148625128,\n",
              " 'evaluation': 0.00047688357206827236,\n",
              " 'timet5modelst5models': 0.0014706446148625128,\n",
              " 'shims': 8.592664891267402e-05,\n",
              " 'connecting': 0.0014706446148625128,\n",
              " 'inferencecurrently': 0.0014706446148625128,\n",
              " 'mesh': 0.0014706446148625128,\n",
              " 'hugging': 0.00010433577922517242,\n",
              " 'face': 6.79507150622583e-05,\n",
              " 'transformers': 0.0014706446148625128,\n",
              " 'librarythe': 0.0014706446148625128,\n",
              " 'api': 6.79507150622583e-05,\n",
              " 'currently': 0.00016238460044589218,\n",
              " 'experimental': 0.0008189305413837766,\n",
              " 'subject': 0.0014706446148625128,\n",
              " 'change': 0.00012319950160131574,\n",
              " 'simple': 0.0014706446148625128,\n",
              " 'easy': 0.0014706446148625128,\n",
              " 'load': 6.79507150622583e-05,\n",
              " 'evaluate': 0.0009537671441365447,\n",
              " 'pytorch': 0.0001425408369598259,\n",
              " 'single': 8.592664891267402e-05,\n",
              " 'gpuif': 0.0014706446148625128,\n",
              " 'want': 0.0005403209171024881,\n",
              " 'largest': 0.0014706446148625128,\n",
              " 'reproduce': 0.00012888997336901105,\n",
              " 'mtfmodel': 0.00010433577922517242,\n",
              " 't5_mesh_transformer': 0.0013087441565406974,\n",
              " 'binaryif': 0.0014706446148625128,\n",
              " 'interested': 0.0014706446148625128,\n",
              " 'gpu': 0.00018479925240197365,\n",
              " 'try': 0.00021381125543973886,\n",
              " 'hfpytorchmodel': 0.0002435769006688383,\n",
              " 'apisince': 0.0014706446148625128,\n",
              " 'remainder': 0.0014706446148625128,\n",
              " 'readme': 0.0014706446148625128,\n",
              " 'assumes': 0.0014706446148625128,\n",
              " 'usage': 0.00010433577922517242,\n",
              " 'associated': 0.0014706446148625128,\n",
              " 'binarya': 0.0014706446148625128,\n",
              " 'hereusagethe': 0.0014706446148625128,\n",
              " 'easiest': 0.0014706446148625128,\n",
              " 'free': 0.0014706446148625128,\n",
              " 'tpu': 0.0005436057204980664,\n",
              " 'colab': 0.0014706446148625128,\n",
              " 'tutorialbelow': 0.0014706446148625128,\n",
              " 'train': 0.0001763582026518646,\n",
              " 'command': 0.0004695110065132759,\n",
              " 'codebase': 0.0014706446148625128,\n",
              " 'instructions': 6.79507150622583e-05,\n",
              " 'checkpoints': 0.0005935176755556013,\n",
              " 'hyperparameters': 0.00021381125543973886,\n",
              " 'scratchdataset': 0.0014706446148625128,\n",
              " 'preparationyou': 0.0014706446148625128,\n",
              " 'either': 0.0014706446148625128,\n",
              " 'existing': 0.0014706446148625128,\n",
              " 'preprocessed': 8.592664891267402e-05,\n",
              " 'tsv': 0.0015896119068942412,\n",
              " 'fileusing': 0.0014706446148625128,\n",
              " 'taskdepending': 0.0014706446148625128,\n",
              " 'see': 0.0,\n",
              " 'need': 0.00016610050397150073,\n",
              " 'prepare': 0.0014706446148625128,\n",
              " 'appropriatelytaskif': 0.0014706446148625128,\n",
              " 'vanilla': 0.0014706446148625128,\n",
              " 'make': 0.0014706446148625128,\n",
              " 'sure': 5.038805790053275e-05,\n",
              " 'loaded': 0.0014706446148625128,\n",
              " 'dataset_fn': 0.0014706446148625128,\n",
              " 'accessible': 0.0003055332275637303,\n",
              " 'ie': 0.0,\n",
              " 'gcs': 0.00026083944806293106,\n",
              " 'bucket': 0.001582713801481603,\n",
              " 'go': 6.79507150622583e-05,\n",
              " 'tfdstaskmost': 0.0014706446148625128,\n",
              " 'run': 0.0001007761158010655,\n",
              " 'binary': 0.0014706446148625128,\n",
              " 'automatically': 0.0014706446148625128,\n",
              " 'downloaded': 0.0014706446148625128,\n",
              " 'prepared': 0.0014706446148625128,\n",
              " 'first': 0.0001007761158010655,\n",
              " 'preparation': 6.79507150622583e-05,\n",
              " 'complete': 0.0001425408369598259,\n",
              " 'cached': 0.0014706446148625128,\n",
              " 'local': 0.0014706446148625128,\n",
              " 'storage': 8.592664891267402e-05,\n",
              " 'avoid': 0.0014706446148625128,\n",
              " 'overhead': 0.0014706446148625128,\n",
              " 'runs': 0.0014706446148625128,\n",
              " 'working': 0.0014706446148625128,\n",
              " 'cloud': 0.0003007432711943591,\n",
              " 'set': 8.214746073706525e-05,\n",
              " 't5_tfds_data_dir': 0.002617488313081395,\n",
              " 'flag': 0.00015650366883775864,\n",
              " 'point': 0.0014706446148625128,\n",
              " 'persistent': 0.0014706446148625128,\n",
              " 'location': 0.0014706446148625128,\n",
              " 'requirement': 0.0014706446148625128,\n",
              " 'tpuc4the': 0.0014706446148625128,\n",
              " 'c4': 0.0014706446148625128,\n",
              " 'created': 0.0014706446148625128,\n",
              " 'requires': 0.0014706446148625128,\n",
              " 'significant': 0.0014706446148625128,\n",
              " 'amount': 0.0014706446148625128,\n",
              " 'bandwidth': 0.0014706446148625128,\n",
              " 'downloading': 0.0014706446148625128,\n",
              " 'raw': 0.0014706446148625128,\n",
              " 'common': 0.0014706446148625128,\n",
              " 'crawl': 0.0014706446148625128,\n",
              " 'scrapes': 0.0014706446148625128,\n",
              " '7': 0.0014706446148625128,\n",
              " 'tb': 0.0014706446148625128,\n",
              " 'compute': 0.0014706446148625128,\n",
              " '335': 0.0014706446148625128,\n",
              " 'cpu': 0.0014706446148625128,\n",
              " 'days': 0.0014706446148625128,\n",
              " 'suggest': 0.0014706446148625128,\n",
              " 'take': 0.0014706446148625128,\n",
              " 'advantage': 0.0014706446148625128,\n",
              " 'apache': 0.0014706446148625128,\n",
              " 'beam': 0.0003710317919334193,\n",
              " 'support': 0.0014706446148625128,\n",
              " 'enables': 0.0014706446148625128,\n",
              " 'distributed': 0.0014706446148625128,\n",
              " 'dataflow': 0.00027016045855124404,\n",
              " '500': 0.0014706446148625128,\n",
              " 'workers': 0.0014706446148625128,\n",
              " 'job': 0.0014706446148625128,\n",
              " '16': 0.0014706446148625128,\n",
              " 'hoursafter': 0.0014706446148625128,\n",
              " 'my_project': 0.0011094364621174087,\n",
              " 'my_bucket': 0.0015537574601281016,\n",
              " 'appropriately': 0.00016238460044589218,\n",
              " 'build': 0.0014706446148625128,\n",
              " 'gcp': 0.0014706446148625128,\n",
              " 'following': 0.0008104813756537321,\n",
              " 'commandspip': 0.0014706446148625128,\n",
              " 'install': 0.00010192607259338746,\n",
              " 'nightlyc4echo': 0.0014706446148625128,\n",
              " 'nightlyc4': 0.0014706446148625128,\n",
              " 'tmp': 0.00015650366883775864,\n",
              " 'beam_requirementstxtpython': 0.0014706446148625128,\n",
              " 'tensorflow_datasetsscriptsdownload_and_prepare': 0.0014706446148625128,\n",
              " 'datasetsc4': 0.0014706446148625128,\n",
              " 'data_dirgs': 0.0014706446148625128,\n",
              " 'tensorflow_datasets': 0.0014706446148625128,\n",
              " 'beam_pipeline_options': 0.0014706446148625128,\n",
              " 'project': 0.004798728573982557,\n",
              " 'job_namec4': 0.0014706446148625128,\n",
              " 'staging_locationgs': 0.0014706446148625128,\n",
              " 'binaries': 0.0014706446148625128,\n",
              " 'temp_locationgs': 0.0014706446148625128,\n",
              " 'temp': 0.0014706446148625128,\n",
              " 'runnerdataflowrunner': 0.0014706446148625128,\n",
              " 'requirements_file': 0.0014706446148625128,\n",
              " 'beam_requirementstxt': 0.0014706446148625128,\n",
              " 'experimentsshuffle_modeservice': 0.0014706446148625128,\n",
              " 'region': 0.0014706446148625128,\n",
              " 'my_region': 0.0014706446148625128,\n",
              " 'read': 0.0014706446148625128,\n",
              " 'instructionstextlinetaska': 0.0014706446148625128,\n",
              " 'textlinetask': 0.0014706446148625128,\n",
              " 'file': 0.0003023283474031965,\n",
              " 'dictionary': 0.0014706446148625128,\n",
              " 'targetsmake': 0.0014706446148625128,\n",
              " 'directlyinstead': 0.0014706446148625128,\n",
              " 'directly': 0.0014706446148625128,\n",
              " 'formatted': 0.00012888997336901105,\n",
              " 'inputttargethowever': 0.0014706446148625128,\n",
              " 'couple': 0.0014706446148625128,\n",
              " 'caveatsthere': 0.0014706446148625128,\n",
              " 'processor': 0.0014706446148625128,\n",
              " 'contain': 0.0014706446148625128,\n",
              " 'formatthere': 0.0014706446148625128,\n",
              " 'directlyif': 0.0014706446148625128,\n",
              " 'features': 0.0014706446148625128,\n",
              " 'textlinetasksimilar': 0.0014706446148625128,\n",
              " 'cases': 0.0014706446148625128,\n",
              " 'bucketinstallationto': 0.0014706446148625128,\n",
              " 'simply': 0.0002435769006688383,\n",
              " 'runpip': 0.0014706446148625128,\n",
              " 't5gcpsetting': 0.0014706446148625128,\n",
              " 'gcpyou': 0.0014706446148625128,\n",
              " 'launch': 0.0014706446148625128,\n",
              " 'virtual': 0.0014706446148625128,\n",
              " 'machine': 0.00015650366883775864,\n",
              " 'vm': 0.0003688707194221425,\n",
              " 'details': 0.0014706446148625128,\n",
              " 'launching': 0.0014706446148625128,\n",
              " 'found': 0.0014706446148625128,\n",
              " 'documentationin': 0.0014706446148625128,\n",
              " 'order': 6.644020158860029e-05,\n",
              " 'eval': 0.0014706446148625128,\n",
              " 'variables': 0.0014706446148625128,\n",
              " 'based': 0.00020368881837582017,\n",
              " 'zone': 0.004909084202629954,\n",
              " 'please': 0.00017185329782534804,\n",
              " 'refer': 0.0014706446148625128,\n",
              " 'quickstart': 0.0014706446148625128,\n",
              " 'guide': 0.0014706446148625128,\n",
              " 'detailsexport': 0.0014706446148625128,\n",
              " 'projectyour_project_nameexport': 0.0014706446148625128,\n",
              " 'zoneyour_project_zoneexport': 0.0014706446148625128,\n",
              " 'bucketgs': 0.0014706446148625128,\n",
              " 'yourbucket': 0.0014706446148625128,\n",
              " 'export': 0.0012836015495838672,\n",
              " 'tpu_namet5': 0.0014706446148625128,\n",
              " 'tpuexport': 0.0014706446148625128,\n",
              " 'tpu_sizev3': 0.0014706446148625128,\n",
              " '8export': 0.0014706446148625128,\n",
              " 'data_dir': 0.001958171111129261,\n",
              " 'your_data_dir': 0.0014706446148625128,\n",
              " 'model_dir': 0.006573133624266136,\n",
              " 'your_model_dir': 0.0014706446148625128,\n",
              " 'device': 0.0014706446148625128,\n",
              " 'vmctpu': 0.0014706446148625128,\n",
              " 'name': 0.0014706446148625128,\n",
              " 'tpu_name': 0.0024216808089401556,\n",
              " 'size': 0.0014727252607889864,\n",
              " 'tpu_size': 0.0044195802790744365,\n",
              " 'noconftrainingin': 0.0014706446148625128,\n",
              " 'glue': 0.00010433577922517242,\n",
              " 'benchmark': 0.0014706446148625128,\n",
              " 'mrpc': 0.00012319950160131574,\n",
              " 'scratch': 0.0014706446148625128,\n",
              " 'mixture_name': 0.0032382092836759357,\n",
              " 'gin': 0.00010192607259338746,\n",
              " 'parameter': 0.00015650366883775864,\n",
              " 'provided': 0.0014706446148625128,\n",
              " 'packaget5_mesh_transformer': 0.0014706446148625128,\n",
              " 'gcp_project': 0.004437745848469635,\n",
              " 'tpu_zone': 0.0050509488903707845,\n",
              " 'gin_file': 0.005874513333387783,\n",
              " 'datasetgin': 0.00017185329782534804,\n",
              " 'bi_v1gin': 0.0014706446148625128,\n",
              " 'gin_param': 0.010724586439592117,\n",
              " 'utilstpu_mesh_shapemodel_parallelism': 0.0013838176051086603,\n",
              " 'utilstpu_mesh_shapetpu_topology': 0.0020757264076629906,\n",
              " 'glue_mrpc_v002': 0.00436418056376183,\n",
              " 'full': 0.0014706446148625128,\n",
              " 'list': 6.79507150622583e-05,\n",
              " 'obtained': 0.0014706446148625128,\n",
              " 'runningpython': 0.0014706446148625128,\n",
              " 'c': 0.0014706446148625128,\n",
              " 'import': 0.00015650366883775864,\n",
              " 't5;': 0.0014706446148625128,\n",
              " 'printt5datamixtureregistrynames': 0.0014706446148625128,\n",
              " 'additional': 0.0001359014301245166,\n",
              " 'module_import': 0.0006919088025543302,\n",
              " 'flagalternatively': 0.00039567845037040075,\n",
              " 'could': 0.00012888997336901105,\n",
              " 'inputttarget': 0.00012319950160131574,\n",
              " 'abovefine': 0.0014706446148625128,\n",
              " 'tuningin': 0.0014706446148625128,\n",
              " 'pass': 0.0001359014301245166,\n",
              " 'operative': 0.0015896119068942412,\n",
              " 'config': 0.0003079987540032894,\n",
              " 'script': 0.0014706446148625128,\n",
              " 'passed': 0.0014706446148625128,\n",
              " 'specifies': 0.0014706446148625128,\n",
              " 'architecture': 0.0014706446148625128,\n",
              " 'specify': 0.0002850816739196518,\n",
              " 'small': 0.00026083944806293106,\n",
              " 'runt5_mesh_transformer': 0.0014706446148625128,\n",
              " 'gs': 0.000403104463204262,\n",
              " 'pretrained_models': 0.0027676352102173206,\n",
              " 'operative_configgin': 0.0027190755552241774,\n",
              " 'correct': 0.0014706446148625128,\n",
              " 'checkpoint': 0.0017805530266668036,\n",
              " 'path': 0.00016987678765564577,\n",
              " 'included': 8.592664891267402e-05,\n",
              " 'configyou': 0.0014706446148625128,\n",
              " 'paired': 0.0014706446148625128,\n",
              " 'translation': 0.0014706446148625128,\n",
              " 'wmt': 0.0014706446148625128,\n",
              " '19': 0.0014706446148625128,\n",
              " 'news': 0.0014706446148625128,\n",
              " 'commentary': 0.0014706446148625128,\n",
              " '14': 0.0014706446148625128,\n",
              " 'seteg': 0.0014706446148625128,\n",
              " 'french': 0.0014706446148625128,\n",
              " 'would': 0.0005403209171024881,\n",
              " 'replace': 0.0014706446148625128,\n",
              " 'utilsruntrain_dataset_fn': 0.0014706446148625128,\n",
              " '@t5modelsmesh_transformertsv_dataset_fn': 0.0014706446148625128,\n",
              " 'tsv_dataset_fnfilename': 0.0014706446148625128,\n",
              " 'constant': 0.0014706446148625128,\n",
              " 'rate': 0.0014706446148625128,\n",
              " '0001': 0.0014706446148625128,\n",
              " 'learning_rate_schedules': 0.0014706446148625128,\n",
              " 'constant_0_001gin': 0.0014706446148625128,\n",
              " 'effectively': 0.0014706446148625128,\n",
              " 'limit': 0.0014706446148625128,\n",
              " 'number': 0.0007420635838668386,\n",
              " 'steps': 0.00023782750271790403,\n",
              " 'like': 0.000737741438844285,\n",
              " 'specific': 0.00021481662228168508,\n",
              " 'since': 0.0014706446148625128,\n",
              " 'already': 0.0014706446148625128,\n",
              " '000': 0.0013878039787182583,\n",
              " 'total': 6.79507150622583e-05,\n",
              " '10': 0.0014706446148625128,\n",
              " 'runtrain_steps': 0.0014706446148625128,\n",
              " '1010000': 0.0014706446148625128,\n",
              " 'different': 7.558208685079913e-05,\n",
              " 'batch': 0.0005092220459395505,\n",
              " 'according': 0.0014706446148625128,\n",
              " 'uses': 0.0014706446148625128,\n",
              " 'sequence': 0.0014706446148625128,\n",
              " 'length': 0.0014706446148625128,\n",
              " '512': 0.0014706446148625128,\n",
              " 'tokens_per_batch1048576': 0.0014706446148625128,\n",
              " 'evalin': 0.0014706446148625128,\n",
              " 'framework': 0.00045229263841755274,\n",
              " 'evalgin': 0.0003179223813788482,\n",
              " 'directory': 0.0002850816739196518,\n",
              " 'decoding': 0.00018479925240197365,\n",
              " 'method': 8.592664891267402e-05,\n",
              " 'search': 0.0014706446148625128,\n",
              " 'commandt5_mesh_transformer': 0.0014706446148625128,\n",
              " 'beam_searchgin': 0.0010378632038314953,\n",
              " 'rundataset_split': 0.0014706446148625128,\n",
              " 'validation': 0.0014706446148625128,\n",
              " 'eval_checkpoint_step': 0.0012347886319369107,\n",
              " '100000': 0.001042964821941985,\n",
              " 'greedy_decodegin': 0.0006919088025543302,\n",
              " 'sample_decodegin': 0.0010378632038314953,\n",
              " 'instead': 4.9830151191450224e-05,\n",
              " 'abovedecodein': 0.0014706446148625128,\n",
              " 'produce': 0.0014706446148625128,\n",
              " 'predictions': 0.0014706446148625128,\n",
              " 'assuming': 0.0014706446148625128,\n",
              " 'sequences': 0.0014706446148625128,\n",
              " 'intputstxt': 0.0014706446148625128,\n",
              " 'bet5_mesh_transformer': 0.0014706446148625128,\n",
              " 'infergin': 0.0014706446148625128,\n",
              " 'input_filename': 0.0014706446148625128,\n",
              " 'inputstxt': 0.0014706446148625128,\n",
              " 'output_filename': 0.0014706446148625128,\n",
              " 'outputstxt': 0.0014706446148625128,\n",
              " 'infer_checkpoint_step': 0.0011653180950960762,\n",
              " 'predict': 0.0014706446148625128,\n",
              " 'aboveexportyou': 0.0014706446148625128,\n",
              " 'savedmodel': 0.0003688707194221425,\n",
              " 'serving': 0.0014706446148625128,\n",
              " 'eg': 0.0014706446148625128,\n",
              " 'deploying': 0.0014706446148625128,\n",
              " 'ml': 0.0014706446148625128,\n",
              " 'engine': 0.0014706446148625128,\n",
              " 'docker': 0.0003688707194221425,\n",
              " 'imaget5_mesh_transformer': 0.0014706446148625128,\n",
              " 'use_model_api': 0.0014706446148625128,\n",
              " 'mode': 0.0014706446148625128,\n",
              " 'export_predict': 0.0014706446148625128,\n",
              " 'export_dir': 0.0014706446148625128,\n",
              " 'dir': 0.0014706446148625128,\n",
              " 'exports': 0.0014706446148625128,\n",
              " 'latest': 0.0014706446148625128,\n",
              " 'particular': 0.00010433577922517242,\n",
              " 'add': 1.6429492147413048e-05,\n",
              " 'checkpoint_mode': 0.0014706446148625128,\n",
              " 'checkpoint_steps1000000the': 0.0014706446148625128,\n",
              " 'deploy': 0.0014706446148625128,\n",
              " 'notebook': 0.0014706446148625128,\n",
              " 'demonstrates': 0.0014706446148625128,\n",
              " 'exporting': 0.0014706446148625128,\n",
              " 'packaging': 0.0014706446148625128,\n",
              " 'image': 0.0014706446148625128,\n",
              " 'servinggpu': 0.0014706446148625128,\n",
              " 'usageif': 0.0014706446148625128,\n",
              " 'commands': 0.0014706446148625128,\n",
              " 'removing': 0.0014706446148625128,\n",
              " 'setting': 0.0014706446148625128,\n",
              " 'params': 0.0014706446148625128,\n",
              " 'mesh_shape': 0.0014706446148625128,\n",
              " 'mesh_devices': 0.0014706446148625128,\n",
              " 'desired': 0.0014706446148625128,\n",
              " 'setupfor': 0.0014706446148625128,\n",
              " 'access': 0.0014706446148625128,\n",
              " '6': 0.0014706446148625128,\n",
              " 'gpus': 0.0014706446148625128,\n",
              " '3': 0.0018822408255081498,\n",
              " 'parallelism': 0.00012319950160131574,\n",
              " '2': 0.0014706446148625128,\n",
              " 'becomet5_mesh_transformer': 0.0014706446148625128,\n",
              " 'utilsrunmesh_shape': 0.0006919088025543302,\n",
              " 'model3': 0.0014706446148625128,\n",
              " 'batch2': 0.0014706446148625128,\n",
              " 'utilsrunmesh_devices': 0.0008231924212912737,\n",
              " 'gpu0': 0.0009252026524788388,\n",
              " 'gpu1': 0.0014706446148625128,\n",
              " 'gpu2': 0.0014706446148625128,\n",
              " 'gpu3': 0.0014706446148625128,\n",
              " 'gpu4': 0.0014706446148625128,\n",
              " 'gpu5': 0.0014706446148625128,\n",
              " 'ist5_mesh_transformer': 0.0014706446148625128,\n",
              " 'model1': 0.0014706446148625128,\n",
              " 'batch1': 0.0014706446148625128,\n",
              " 'experimentswe': 0.0014706446148625128,\n",
              " 'configs': 0.00018479925240197365,\n",
              " 'experimentsthe': 0.0014706446148625128,\n",
              " 'folder': 6.79507150622583e-05,\n",
              " 'subdirectories': 0.00020368881837582017,\n",
              " 'corresponding': 0.0014706446148625128,\n",
              " 'sections': 0.0014706446148625128,\n",
              " 'paperfor': 0.0014706446148625128,\n",
              " 'section': 0.0014706446148625128,\n",
              " '33': 0.0014706446148625128,\n",
              " 'subdirectory': 0.0014706446148625128,\n",
              " 'experiment': 0.0010268812396670938,\n",
              " 'loosely': 0.0014706446148625128,\n",
              " 'speaking': 0.0014706446148625128,\n",
              " 'rows': 0.0014706446148625128,\n",
              " 'tables': 0.0014706446148625128,\n",
              " 'paperlet': 0.0014706446148625128,\n",
              " 'say': 0.0014706446148625128,\n",
              " 'prefix': 0.0014706446148625128,\n",
              " 'language': 0.00010433577922517242,\n",
              " 'modeling': 0.0014706446148625128,\n",
              " 'objective': 0.0009252026524788388,\n",
              " 'row': 0.0014706446148625128,\n",
              " 'table': 0.0014706446148625128,\n",
              " '4the': 0.0014706446148625128,\n",
              " 'live': 0.0014706446148625128,\n",
              " 'obj': 0.0032382092836759357,\n",
              " 'prefix_lmin': 0.0014706446148625128,\n",
              " 'base': 0.00020368881837582017,\n",
              " 'prefix_lm': 0.0027756079574365166,\n",
              " 'operative_configginthen': 0.0014706446148625128,\n",
              " 'downstream': 0.0014706446148625128,\n",
              " 'consider': 0.0014706446148625128,\n",
              " 'cnn_dailymail_v002': 0.002182090281880915,\n",
              " 'operative_configginto': 0.0014706446148625128,\n",
              " 'configexport': 0.0014706446148625128,\n",
              " 'pretrain_model_dir': 0.0010378632038314953,\n",
              " 'cnn': 0.0014706446148625128,\n",
              " 'daily': 0.0014706446148625128,\n",
              " 'mail': 0.0014706446148625128,\n",
              " 'soexport': 0.0014706446148625128,\n",
              " 'finetune_model_dir': 0.0006919088025543302,\n",
              " 'init_checkpoint': 0.0014706446148625128,\n",
              " 'modelckpt': 0.0014706446148625128,\n",
              " '524288': 0.0014706446148625128,\n",
              " 'optionssome': 0.0014706446148625128,\n",
              " 'variants': 0.0003179223813788482,\n",
              " 'time': 0.0014706446148625128,\n",
              " 'eachof': 0.0014706446148625128,\n",
              " 'group': 0.0014706446148625128,\n",
              " 'third_party': 0.0014706446148625128,\n",
              " 'py': 0.0014706446148625128,\n",
              " 'scripts': 0.0014706446148625128,\n",
              " 'run_finetuneshdeterministic': 0.0014706446148625128,\n",
              " 'train_gin_param': 0.0010378632038314953,\n",
              " 'mesh_train_dataset_fnseed': 0.0014706446148625128,\n",
              " 'seed': 0.0014706446148625128,\n",
              " 'utilsrunskip_seen_data': 0.0014706446148625128,\n",
              " 'true': 0.0014706446148625128,\n",
              " 'lm': 0.00010433577922517242,\n",
              " 'utilsrunmodel_type': 0.0014706446148625128,\n",
              " 'checkpointswe': 0.0014706446148625128,\n",
              " 'described': 0.0014706446148625128,\n",
              " 'papert5': 0.0014706446148625128,\n",
              " '60': 0.0014706446148625128,\n",
              " 'million': 0.00015650366883775864,\n",
              " 'parameters': 0.00026083944806293106,\n",
              " 'smallt5': 0.0014706446148625128,\n",
              " '220': 0.0014706446148625128,\n",
              " 'baset5': 0.0014706446148625128,\n",
              " '770': 0.0014706446148625128,\n",
              " 'larget5': 0.0014706446148625128,\n",
              " '3b': 0.0014706446148625128,\n",
              " 'billion': 0.00020368881837582017,\n",
              " '3bt5': 0.0014706446148625128,\n",
              " '11b': 0.0014706446148625128,\n",
              " '11': 0.0014706446148625128,\n",
              " '11bsee': 0.0014706446148625128,\n",
              " 'citeif': 0.0014706446148625128,\n",
              " 'extend': 0.0014706446148625128,\n",
              " 'work': 0.0014706446148625128,\n",
              " 'cite': 0.0014706446148625128,\n",
              " 'introduced@article': 0.0014706446148625128,\n",
              " '2020t5': 0.0014706446148625128,\n",
              " 'author': 0.0014706446148625128,\n",
              " 'colin': 0.0014706446148625128,\n",
              " 'raffel': 0.0014706446148625128,\n",
              " 'noam': 0.0014706446148625128,\n",
              " 'shazeer': 0.0014706446148625128,\n",
              " 'adam': 0.0014706446148625128,\n",
              " 'roberts': 0.0014706446148625128,\n",
              " 'katherine': 0.0014706446148625128,\n",
              " 'lee': 0.0014706446148625128,\n",
              " 'sharan': 0.0014706446148625128,\n",
              " 'narang': 0.0014706446148625128,\n",
              " 'michael': 0.0014706446148625128,\n",
              " 'matena': 0.0014706446148625128,\n",
              " 'yanqi': 0.0014706446148625128,\n",
              " 'zhou': 0.0014706446148625128,\n",
              " 'wei': 0.0014706446148625128,\n",
              " 'li': 0.0014706446148625128,\n",
              " 'peter': 0.0014706446148625128,\n",
              " 'j': 0.0014706446148625128,\n",
              " 'liu': 0.0014706446148625128,\n",
              " 'title': 0.0014706446148625128,\n",
              " 'journal': 0.0008724961043604649,\n",
              " 'research': 0.0014706446148625128,\n",
              " 'year': 0.0014706446148625128,\n",
              " '2020': 0.0014706446148625128,\n",
              " 'volume': 0.0014706446148625128,\n",
              " '21': 0.0014706446148625128,\n",
              " '140': 0.0014706446148625128,\n",
              " 'pages': 0.0014706446148625128,\n",
              " '67': 0.0014706446148625128,\n",
              " 'url': 0.0014706446148625128,\n",
              " 'http': 0.0014706446148625128,\n",
              " 'jmlrorg': 0.0014706446148625128,\n",
              " 'papers': 0.0014706446148625128,\n",
              " 'v21': 0.0014706446148625128,\n",
              " '20': 0.0014706446148625128,\n",
              " '074html': 0.0014706446148625128}"
            ]
          },
          "execution_count": 189,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tf_idf_score = {key: tf_score[key] * idf_score.get(key,0) for key in tf_score.keys()}\n",
        "\n",
        "tf_idf_score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ec79PLbgvEwS",
        "outputId": "6ff18a19-1c86-4e78-c018-15db265b7d4b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'gin_param': 0.010724586439592117,\n",
              " 't5': 0.008408727770130076,\n",
              " 'model_dir': 0.006573133624266136,\n",
              " 'gin_file': 0.005874513333387783,\n",
              " 'text': 0.005391126508252243,\n",
              " 'tpu_zone': 0.0050509488903707845,\n",
              " 'zone': 0.004909084202629954,\n",
              " 'project': 0.004798728573982557,\n",
              " 'gcp_project': 0.004437745848469635,\n",
              " 'tpu_size': 0.0044195802790744365,\n",
              " 'glue_mrpc_v002': 0.00436418056376183,\n",
              " 'objectives': 0.004163411936154775,\n",
              " '1': 0.0034363589418409677,\n",
              " 'mixture_name': 0.0032382092836759357,\n",
              " 'obj': 0.0032382092836759357,\n",
              " 'example': 0.0030027453184071806,\n",
              " 'prefix_lm': 0.0027756079574365166,\n",
              " 'pretrained_models': 0.0027676352102173206,\n",
              " 'operative_configgin': 0.0027190755552241774,\n",
              " 't5_tfds_data_dir': 0.002617488313081395,\n",
              " 'experiments': 0.0025672030991677345,\n",
              " 'tpu_name': 0.0024216808089401556,\n",
              " 'cnn_dailymail_v002': 0.002182090281880915,\n",
              " 'utilstpu_mesh_shapetpu_topology': 0.0020757264076629906,\n",
              " 'data_dir': 0.001958171111129261,\n",
              " '3': 0.0018822408255081498,\n",
              " 'task': 0.0018443535971107124,\n",
              " 'mixtures': 0.0017970421694174141,\n",
              " 'checkpoint': 0.0017805530266668036,\n",
              " 'tsv': 0.0015896119068942412}"
            ]
          },
          "execution_count": 190,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "def get_top_n(dictionary, n):\n",
        "    result = dict(sorted(dictionary.items(), key=itemgetter(1), reverse=True)[:n])\n",
        "    return result\n",
        "\n",
        "get_top_n(tf_idf_score,30)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X2gVcouBvEwS"
      },
      "source": [
        "# Method 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ianCtXQOvEwS"
      },
      "outputs": [],
      "source": [
        "import nltk.tokenize as nt\n",
        "import nltk"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zeQkfqgwvEwS",
        "outputId": "6361473d-4db4-4365-9b61-7bec036807e7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[' T5  Text To Text Transfer Transformer As of July 2022  we recommend using T5X  T5X is the new and improved implementation of T5  and more  in JAX and Flax.',\n",
              " 'T5 on Tensorflow with MeshTF is no longer actively developed.',\n",
              " 'If you are new to T5  we recommend starting with T5X.',\n",
              " 'The t5 library serves primarily as code for reproducing the experiments in Exploring the Limits of Transfer Learning with a Unified Text to Text Transformer.',\n",
              " 'In the paper  we demonstrate how to achieve state of the art results on multiple NLP tasks using a text to text transformer pre trained on a large text corpus.',\n",
              " 'The bulk of the code in this repository is used for loading  preprocessing  mixing  and evaluating datasets.',\n",
              " 'It also provides a way to fine tune the pre trained models released alongside the publication.',\n",
              " 'The t5 library can be used for future model development by providing useful modules for training and fine tuning  potentially huge  models on mixtures of text to text tasks.',\n",
              " 'Table of Contents  Library Usage  Dataset Preparation  C4 Installation Setting up TPUs on GCP Training Fine Tuning Eval Decode Export GPU Usage Reproducing our experiments Useful Options   Released Model Checkpoints How to Cite  Library t5.data t5.data is a package for defining Task objects that provide tf.data.Datasets.',\n",
              " 'Each Task is made up of   a data source text preprocessor function s  a SentencePiece model metric function s   Additionally  you may optionally provide   token preprocessor function s  postprocess function s   The data source can be an arbitrary function that provides a tf.data.Dataset  but we also provide simpler wrappers for datasets available in TensorFlow Datasets  TFDS   a TfdsTask  or stored as text files with one example per line  a TextLineTask .',\n",
              " 'The text preprocessor converts the examples in the source dataset into the appropriate format for a text to text model with fields for inputs and targets.',\n",
              " 'For example  the predefined t5.data.preprocessors.translate preprocessor converts inputs in the form   de    Das ist gut.',\n",
              " '    en    That is good.  ',\n",
              " 'to the form   inputs    translate German to English  Das ist gut.',\n",
              " '    targets    That is good.  ',\n",
              " 'In addition to text preprocessing  you can also use one or more token preprocessors to modify the inputs post tokenization.',\n",
              " 'We implemented our unsupervised pre training objectives using these token preprocessors.',\n",
              " 'We provide many predefined preprocessors in t5.data.preprocessors  but you may also define your own.',\n",
              " 'The SentencePiece model is used to tokenize the input strings and decode the output tokens.',\n",
              " 'You can create your own model with the google sentencepiece library  or use our default one at t5.data.DEFAULT_SPM_PATH.',\n",
              " 'If you create your own  you must use the flags   pad_id 0   eos_id 1   unk_id 2   bos_id  1 with spm_train to be compatible with our model code.',\n",
              " 'The metric function returns a score given the target and prediction from the model.',\n",
              " 'You may also define a postprocess function to convert the target and prediction text to another format before calling the metric.',\n",
              " 'We provide some predefined metrics in t5.evaluation.metrics.',\n",
              " 'Finally  t5.data contains a Mixture class that can be instantiated to combine multiple Task datasets for multi task training using various functions for specifying the mixture rates.',\n",
              " 't5.evaluation t5.evaluation contains two core components   metrics to be used during evaluation utilities for applying these metrics at evaluation time  t5.models t5.models contains shims for connecting T5 Tasks and Mixtures to a model implementation for training  evaluation  and inference.',\n",
              " 'Currently there are two shims available  One for the Mesh TensorFlow Transformer that we used in our paper and another for the Hugging Face Transformers library.',\n",
              " 'The Hugging Face API is currently experimental and subject to change  but provides a simple and easy way to load  fine tune  and evaluate our pre trained models using PyTorch on a single GPU.',\n",
              " 'If you want to use our largest models on TPUs and or reproduce the results in our paper  you should use the MtfModel API and the t5_mesh_transformer binary.',\n",
              " 'If you are interested fine tuning our models on a GPU in PyTorch  you should try the HfPyTorchModel API.',\n",
              " 'Since the HfPyTorchModel is experimental  the remainder of this README assumes usage of the MtfModel and its associated binary.',\n",
              " 'A usage example of HfPyTorchModel is available here.',\n",
              " 'Usage The easiest way to try out T5 is with a free TPU in our Colab Tutorial.',\n",
              " 'Below we provide examples for how to pre train  fine tune  evaluate  and decode from a model from the command line with our codebase.',\n",
              " 'You can use these instructions to reproduce our results  fine tune one of our released checkpoints with your own data and or hyperparameters  or pre train a model from scratch.',\n",
              " 'Dataset Preparation You may either use a new or pre existing Task  or you may load examples from a preprocessed TSV file.',\n",
              " 'Using a Task Depending on your data source  see above   you will need to prepare your data appropriately.',\n",
              " 'Task If using a vanilla task  just make sure any file s  loaded by your dataset_fn are accessible to the TPU  i.e.  are in a GCS bucket   and you should be good to go ',\n",
              " 'TfdsTask Most of our predefined Tasks use TensorFlow Datasets  TFDS  as their data source.',\n",
              " 'When you run our training binary  see instructions below  with a TfdsTask  the dataset will automatically be downloaded and prepared on its first use.',\n",
              " 'After preparation is complete  the dataset is cached to your local storage to avoid this overhead in future runs.',\n",
              " 'If working in the cloud  we recommend you set the   t5_tfds_data_dir flag to point to a persistent storage location  such as a GCS bucket.',\n",
              " 'This is a requirement when training on TPU.',\n",
              " 'C4 The C4 dataset we created for unsupervised pre training is available in TensorFlow Datasets  but it requires a significant amount of bandwidth for downloading the raw Common Crawl scrapes   7 TB  and compute for its preparation   335 CPU days .',\n",
              " 'We suggest you take advantage of the Apache Beam support in TFDS  which enables distributed preprocessing of the dataset and can be run on Google Cloud Dataflow.',\n",
              " 'With 500 workers  the job should complete in  16 hours.',\n",
              " 'After defining MY_PROJECT and MY_BUCKET appropriately  you can build the dataset in DataFlow from GCP using the following commands  pip install tfds nightly c4  echo  tfds nightly c4      tmp beam_requirements.txt python  m tensorflow_datasets.scripts.download_and_prepare      datasets c4 en      data_dir gs    MY_BUCKET tensorflow_datasets      beam_pipeline_options  project  MY_PROJECT job_name c4 staging_location gs    MY_BUCKET binaries temp_location gs    MY_BUCKET temp runner DataflowRunner requirements_file  tmp beam_requirements.txt experiments shuffle_mode service region  MY_REGION  Read more in the TFDS Beam instructions.',\n",
              " 'TextLineTask A TextLineTask is useful when your data source is a text file  or files  with one example per line.',\n",
              " 'You can then use a text preprocessor to convert each line into a dictionary of inputs and targets.',\n",
              " 'Make sure your files are accessible to the TPU  i.e.  are in a GCS bucket   and you should be good to go ',\n",
              " 'Using a TSV File Directly Instead of defining a new Task  you may use a TSV file  or files  directly as your dataset where each line is formatted as  input t target .',\n",
              " 'However  there are a couple of caveats   There is no way to define a text processor  so the TSV will need to contain your data in a preprocessed format.',\n",
              " 'There is also currently no way to set a token preprocessor  postprocess function  or metric function for evaluation when using a TSV file directly.',\n",
              " 'If you need any of these features  you must define a new Task  TfdsTask  or TextLineTask.',\n",
              " 'Similar to the above cases  your TSV file s  must be accessible to the TPU  i.e.  are in a GCS bucket .',\n",
              " 'Installation To install the T5 package  simply run  pip install t5 gcp  Setting up TPUs on GCP You will first need to launch a Virtual Machine  VM  on Google Cloud.',\n",
              " 'Details about launching the VM can be found at the Google Cloud Documentation.',\n",
              " 'In order to run training or eval on Cloud TPUs  you must set up the following variables based on your project  zone and GCS bucket appropriately.',\n",
              " 'Please refer to the Cloud TPU Quickstart guide for more details.',\n",
              " 'export PROJECT your_project_name export ZONE your_project_zone export BUCKET gs   yourbucket  export TPU_NAME t5 tpu export TPU_SIZE v3 8 export DATA_DIR    BUCKET  your_data_dir  export MODEL_DIR    BUCKET  your_model_dir  Please use the following command to create a TPU device in the Cloud VM.',\n",
              " 'ctpu up   name  TPU_NAME   project  PROJECT   zone  ZONE   tpu size  TPU_SIZE            tpu only   noconf Training In the command below  we train a model on the GLUE Benchmark MRPC task from scratch.',\n",
              " 'You can change the MIXTURE_NAME gin parameter to use any of the tasks or mixtures provided in our package.',\n",
              " 't5_mesh_transformer       tpu    TPU_NAME        gcp_project    PROJECT        tpu_zone    ZONE        model_dir    MODEL_DIR        t5_tfds_data_dir    DATA_DIR        gin_file  dataset.gin       gin_file  models bi_v1.gin       gin_param  utils.tpu_mesh_shape.model_parallelism   1       gin_param  utils.tpu_mesh_shape.tpu_topology      TPU_SIZE         gin_param  MIXTURE_NAME    glue_mrpc_v002   The full list of tasks and mixtures can be obtained by running  python  c  import t5; print t5.data.MixtureRegistry.names     You may also define additional tasks and mixtures in a new file and import it using the   module_import flag.',\n",
              " 'Alternatively  you could train with a TSV file where each line is formatted as  input t target   see above .',\n",
              " 'Fine tuning In order to fine tune one of our pre trained models  you need to pass the operative config of the pre trained model to the training script.',\n",
              " 'The operative config should be passed in as a gin_file flag.',\n",
              " 'It specifies the model architecture and other hyperparameters.',\n",
              " 'In addition  you need to specify the mixture to fine tune on.',\n",
              " 'For example  to fine tune the T5 small model on the glue_mrpc_v002 mixture  please run  t5_mesh_transformer       tpu    TPU_NAME        gcp_project    PROJECT        tpu_zone    ZONE        model_dir    MODEL_DIR        t5_tfds_data_dir    DATA_DIR        gin_file  dataset.gin       gin_param  utils.tpu_mesh_shape.model_parallelism   1       gin_param  utils.tpu_mesh_shape.tpu_topology      TPU_SIZE         gin_param  MIXTURE_NAME    glue_mrpc_v002        gin_file  gs   t5 data pretrained_models small operative_config.gin  The correct pre trained checkpoint path is included in the operative config.',\n",
              " 'You may also define additional tasks and mixtures in a new file and import it using the   module_import flag.',\n",
              " 'Alternatively  you could fine tune with a TSV file where each line is formatted as  input t target   see above .',\n",
              " 'For example  you could try one of the paired translation datasets from WMT  19 News Commentary 14 training set  e.g.  English French .',\n",
              " 'When using a TSV file  you would replace the MIXTURE_NAME flag with    gin_param  utils.run.train_dataset_fn   @t5.models.mesh_transformer.tsv_dataset_fn    gin_param  tsv_dataset_fn.filename    gs  path to tsv   To fine tune with the same hyperparameters we used in the paper  using a constant learning rate of 0.001   you can pass in this gin file which is included in the T5 package    gin_file  learning_rate_schedules constant_0_001.gin   The operative config for the pre trained models are set so that there is effectively no limit on the number of train steps.',\n",
              " 'If you d like to train for a specific number of steps  you ll need to pass that in.',\n",
              " 'Since the pre trained model has already been trained for 1 000 000 steps  you should specify the total number of steps after pre training and fine tuning.',\n",
              " 'For example  if you want to fine tune for an additional 10 000 steps  you should pass   gin_param  run.train_steps   1010000   You can also use a different batch size for fine tuning.',\n",
              " 'We set the batch size according to the total number of tokens in a batch.',\n",
              " 'By default  a batch uses a sequence length of 512.',\n",
              " 'To set the number of tokens in a batch  you should set   gin_param    tokens_per_batch 1048576   Eval In order to evaluate a model in the T5 framework  you need to use the eval.gin file  specify the model directory  decoding method  and which checkpoint step s  to evaluate.',\n",
              " 'So  to evaluate on the GLUE MRPC task using beam search on all checkpoints  use the following command  t5_mesh_transformer      tpu    TPU_NAME        gcp_project    PROJECT        tpu_zone    ZONE        model_dir    MODEL_DIR        gin_file    MODEL_DIR  operative_config.gin       t5_tfds_data_dir   DATA_DIR       gin_file  eval.gin       gin_file  beam_search.gin       gin_param  run.dataset_split    validation        gin_param  utils.tpu_mesh_shape.tpu_topology      TPU_SIZE         gin_param  MIXTURE_NAME    glue_mrpc_v002        gin_param  eval_checkpoint_step    all   To evaluate a specific checkpoint  simply set the eval_checkpoint_step parameter to appropriate checkpoint.',\n",
              " '  gin_param  eval_checkpoint_step   100000   You can also use greedy_decode.gin or sample_decode.gin instead of beam_search.gin in the command above.',\n",
              " 'Decode In order to produce predictions from a model in the T5 framework  you need to specify the model directory  decoding method  and which checkpoint step s  to use for decoding.',\n",
              " 'Assuming you have a text file of input sequences stored at  path to intputs.txt  an example command would be  t5_mesh_transformer      tpu    TPU_NAME        gcp_project    PROJECT        tpu_zone    ZONE        model_dir    MODEL_DIR        gin_file    MODEL_DIR  operative_config.gin       gin_file  infer.gin       gin_file  sample_decode.gin       gin_param  input_filename     path to inputs.txt       gin_param  output_filename     tmp outputs.txt       gin_param  utils.tpu_mesh_shape.tpu_topology      TPU_SIZE        gin_param  infer_checkpoint_step    all   To predict with a specific checkpoint  simply set the infer_checkpoint_step parameter to appropriate checkpoint.',\n",
              " '  gin_param  infer_checkpoint_step   100000   You can also use beam_search.gin or greedy_decode.gin instead of sample_decode.gin in the command above.',\n",
              " 'Export You may also want to export a SavedModel  which is useful for serving your trained model   e.g.  when deploying with ML Engine or in a Docker image .',\n",
              " 't5_mesh_transformer      gcp_project    PROJECT        tpu_zone    ZONE        model_dir    MODEL_DIR        use_model_api      mode  export_predict       export_dir   path to export dir  The command above exports the latest checkpoint in the model directory.',\n",
              " 'To export a particular checkpoint  add the following flags      checkpoint_mode  specific       checkpoint_steps 1000000 The t5 deploy notebook demonstrates exporting a SavedModel and packaging it in a Docker image for serving.',\n",
              " 'GPU Usage If you would like to use GPU instead of TPUs  you can modify the above commands by removing TPU specific flags    tpu    tpu_zone    gcp_project  and setting the gin params for mesh_shape and mesh_devices based on your desired setup.',\n",
              " 'For example  if your machine has access to 6 GPUs and you d like to do 3 way model parallelism and 2 way data parallelism  the fine tuning command above would become  t5_mesh_transformer       model_dir    MODEL_DIR        t5_tfds_data_dir    DATA_DIR        gin_file  dataset.gin       gin_param  utils.run.mesh_shape    model 3 batch 2        gin_param  utils.run.mesh_devices     gpu 0   gpu 1   gpu 2   gpu 3   gpu 4   gpu 5         gin_param  MIXTURE_NAME    glue_mrpc_v002        gin_file  gs   t5 data pretrained_models small operative_config.gin  With a single GPU  the command is  t5_mesh_transformer       model_dir    MODEL_DIR        t5_tfds_data_dir    DATA_DIR        gin_file  dataset.gin       gin_param  utils.run.mesh_shape    model 1 batch 1        gin_param  utils.run.mesh_devices     gpu 0         gin_param  MIXTURE_NAME    glue_mrpc_v002        gin_file  gs   t5 data pretrained_models small operative_config.gin  Reproducing our experiments We provide operative configs for all of the experiments in the paper in gs   t5 data experiments.',\n",
              " 'The experiments folder has different subdirectories corresponding to the different sections in our paper.',\n",
              " 'For example  gs   t5 data experiments objectives contains the experiments from Section 3.3   Unsupervised objectives  .',\n",
              " 'Each subdirectory of the objectives folder contains operative configs for some particular experiment  where loosely speaking an  experiment  is one of the rows in one of the tables in our paper .',\n",
              " 'Let s say you want to reproduce the results for the  Prefix language modeling  objective  the first row in Table 4 .',\n",
              " 'The operative configs for that experiment live in gs   t5 data experiments objectives obj prefix_lm.',\n",
              " 'In the base directory  there is an operative config for pre training the model  gs   t5 data experiments objectives obj prefix_lm operative_config.gin .',\n",
              " 'Then  there are subdirectories for each of the downstream fine tuning mixtures we consider  each of which has its own operative config  for example  gs   t5 data experiments objectives obj prefix_lm cnn_dailymail_v002 operative_config.gin .',\n",
              " 'To run this experiment  first pre train a model with the pre training operative config  export PRETRAIN_MODEL_DIR    BUCKET  obj prefix_lm  t5_mesh_transformer       tpu    TPU_NAME        gcp_project    PROJECT        tpu_zone    ZONE        model_dir    PRETRAIN_MODEL_DIR        gin_file  gs   t5 data experiments objectives obj prefix_lm operative_config.gin       gin_param  utils.tpu_mesh_shape.model_parallelism   1       gin_param  utils.tpu_mesh_shape.tpu_topology      TPU_SIZE    Then  you can fine tune the pre trained model on CNN Daily Mail like so  export FINETUNE_MODEL_DIR    BUCKET  obj prefix_lm cnn_dailymail_v002  t5_mesh_transformer       tpu    TPU_NAME        gcp_project    PROJECT        tpu_zone    ZONE        model_dir    FINETUNE_MODEL_DIR        gin_file  gs   t5 data experiments objectives obj prefix_lm cnn_dailymail_v002 operative_config.gin       gin_param  init_checkpoint      PRETRAIN_MODEL_DIR  model.ckpt 524288        gin_param  utils.tpu_mesh_shape.model_parallelism   1       gin_param  utils.tpu_mesh_shape.tpu_topology      TPU_SIZE    Useful Options Some training variants need multiple flags to be set at the same time.',\n",
              " 'For each of the below variants  add the group of flags to . third_party py t5 google scripts run_finetune.sh.',\n",
              " 'Deterministic training     train_gin_param  mesh_train_dataset_fn.seed   SEED        train_gin_param  utils.run.skip_seen_data   True   Language model     objective  lm       train_gin_param  utils.run.model_type    lm    Released Model Checkpoints We have released the following checkpoints for pre trained models described in our paper   T5 Small  60 million parameters   gs   t5 data pretrained_models small T5 Base  220 million parameters   gs   t5 data pretrained_models base T5 Large  770 million parameters   gs   t5 data pretrained_models large T5 3B  3 billion parameters   gs   t5 data pretrained_models 3B T5 11B  11 billion parameters   gs   t5 data pretrained_models 11B  See here for a list of additional experimental pre trained model checkpoints.',\n",
              " 'How to Cite If you extend or use this work  please cite the paper where it was introduced  @article 2020t5    author     Colin Raffel and Noam Shazeer and Adam Roberts and Katherine Lee and Sharan Narang and Michael Matena and Yanqi Zhou and Wei Li and Peter J. Liu     title      Exploring the Limits of Transfer Learning with a Unified Text to Text Transformer     journal    Journal of Machine Learning Research     year       2020     volume     21     number     140     pages      1 67     url        http   jmlr.org papers v21 20 074.html   ']"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "sent = nt.sent_tokenize(original)\n",
        "sent = [ re.sub(\"[\\n:(=<>)\\[\\]]\",' ',s) for s in sent]\n",
        "sent = [re.sub(\"[-,/$~!{\\'\\\"}]\",' ',s) for s in sent]\n",
        "sent = [s.replace(\"\\\\\",\"\") for s in sent]\n",
        "sent = [s.replace(\"--\",\"\") for s in sent]\n",
        "sent"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OfiCcQ6wvEwT",
        "outputId": "4531ff3b-b4ab-4ab4-a686-25c7650a55d9"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[['T5',\n",
              "  'Text',\n",
              "  'To',\n",
              "  'Text',\n",
              "  'Transfer',\n",
              "  'Transformer',\n",
              "  'As',\n",
              "  'of',\n",
              "  'July',\n",
              "  '2022',\n",
              "  'we',\n",
              "  'recommend',\n",
              "  'using',\n",
              "  'T5X',\n",
              "  'T5X',\n",
              "  'is',\n",
              "  'the',\n",
              "  'new',\n",
              "  'and',\n",
              "  'improved',\n",
              "  'implementation',\n",
              "  'of',\n",
              "  'T5',\n",
              "  'and',\n",
              "  'more',\n",
              "  'in',\n",
              "  'JAX',\n",
              "  'and',\n",
              "  'Flax',\n",
              "  '.'],\n",
              " ['T5',\n",
              "  'on',\n",
              "  'Tensorflow',\n",
              "  'with',\n",
              "  'MeshTF',\n",
              "  'is',\n",
              "  'no',\n",
              "  'longer',\n",
              "  'actively',\n",
              "  'developed',\n",
              "  '.'],\n",
              " ['If',\n",
              "  'you',\n",
              "  'are',\n",
              "  'new',\n",
              "  'to',\n",
              "  'T5',\n",
              "  'we',\n",
              "  'recommend',\n",
              "  'starting',\n",
              "  'with',\n",
              "  'T5X',\n",
              "  '.'],\n",
              " ['The',\n",
              "  't5',\n",
              "  'library',\n",
              "  'serves',\n",
              "  'primarily',\n",
              "  'as',\n",
              "  'code',\n",
              "  'for',\n",
              "  'reproducing',\n",
              "  'the',\n",
              "  'experiments',\n",
              "  'in',\n",
              "  'Exploring',\n",
              "  'the',\n",
              "  'Limits',\n",
              "  'of',\n",
              "  'Transfer',\n",
              "  'Learning',\n",
              "  'with',\n",
              "  'a',\n",
              "  'Unified',\n",
              "  'Text',\n",
              "  'to',\n",
              "  'Text',\n",
              "  'Transformer',\n",
              "  '.'],\n",
              " ['In',\n",
              "  'the',\n",
              "  'paper',\n",
              "  'we',\n",
              "  'demonstrate',\n",
              "  'how',\n",
              "  'to',\n",
              "  'achieve',\n",
              "  'state',\n",
              "  'of',\n",
              "  'the',\n",
              "  'art',\n",
              "  'results',\n",
              "  'on',\n",
              "  'multiple',\n",
              "  'NLP',\n",
              "  'tasks',\n",
              "  'using',\n",
              "  'a',\n",
              "  'text',\n",
              "  'to',\n",
              "  'text',\n",
              "  'transformer',\n",
              "  'pre',\n",
              "  'trained',\n",
              "  'on',\n",
              "  'a',\n",
              "  'large',\n",
              "  'text',\n",
              "  'corpus',\n",
              "  '.'],\n",
              " ['The',\n",
              "  'bulk',\n",
              "  'of',\n",
              "  'the',\n",
              "  'code',\n",
              "  'in',\n",
              "  'this',\n",
              "  'repository',\n",
              "  'is',\n",
              "  'used',\n",
              "  'for',\n",
              "  'loading',\n",
              "  'preprocessing',\n",
              "  'mixing',\n",
              "  'and',\n",
              "  'evaluating',\n",
              "  'datasets',\n",
              "  '.'],\n",
              " ['It',\n",
              "  'also',\n",
              "  'provides',\n",
              "  'a',\n",
              "  'way',\n",
              "  'to',\n",
              "  'fine',\n",
              "  'tune',\n",
              "  'the',\n",
              "  'pre',\n",
              "  'trained',\n",
              "  'models',\n",
              "  'released',\n",
              "  'alongside',\n",
              "  'the',\n",
              "  'publication',\n",
              "  '.'],\n",
              " ['The',\n",
              "  't5',\n",
              "  'library',\n",
              "  'can',\n",
              "  'be',\n",
              "  'used',\n",
              "  'for',\n",
              "  'future',\n",
              "  'model',\n",
              "  'development',\n",
              "  'by',\n",
              "  'providing',\n",
              "  'useful',\n",
              "  'modules',\n",
              "  'for',\n",
              "  'training',\n",
              "  'and',\n",
              "  'fine',\n",
              "  'tuning',\n",
              "  'potentially',\n",
              "  'huge',\n",
              "  'models',\n",
              "  'on',\n",
              "  'mixtures',\n",
              "  'of',\n",
              "  'text',\n",
              "  'to',\n",
              "  'text',\n",
              "  'tasks',\n",
              "  '.'],\n",
              " ['Table',\n",
              "  'of',\n",
              "  'Contents',\n",
              "  'Library',\n",
              "  'Usage',\n",
              "  'Dataset',\n",
              "  'Preparation',\n",
              "  'C4',\n",
              "  'Installation',\n",
              "  'Setting',\n",
              "  'up',\n",
              "  'TPUs',\n",
              "  'on',\n",
              "  'GCP',\n",
              "  'Training',\n",
              "  'Fine',\n",
              "  'Tuning',\n",
              "  'Eval',\n",
              "  'Decode',\n",
              "  'Export',\n",
              "  'GPU',\n",
              "  'Usage',\n",
              "  'Reproducing',\n",
              "  'our',\n",
              "  'experiments',\n",
              "  'Useful',\n",
              "  'Options',\n",
              "  'Released',\n",
              "  'Model',\n",
              "  'Checkpoints',\n",
              "  'How',\n",
              "  'to',\n",
              "  'Cite',\n",
              "  'Library',\n",
              "  't5.data',\n",
              "  't5.data',\n",
              "  'is',\n",
              "  'a',\n",
              "  'package',\n",
              "  'for',\n",
              "  'defining',\n",
              "  'Task',\n",
              "  'objects',\n",
              "  'that',\n",
              "  'provide',\n",
              "  'tf.data.Datasets',\n",
              "  '.'],\n",
              " ['Each',\n",
              "  'Task',\n",
              "  'is',\n",
              "  'made',\n",
              "  'up',\n",
              "  'of',\n",
              "  'a',\n",
              "  'data',\n",
              "  'source',\n",
              "  'text',\n",
              "  'preprocessor',\n",
              "  'function',\n",
              "  's',\n",
              "  'a',\n",
              "  'SentencePiece',\n",
              "  'model',\n",
              "  'metric',\n",
              "  'function',\n",
              "  's',\n",
              "  'Additionally',\n",
              "  'you',\n",
              "  'may',\n",
              "  'optionally',\n",
              "  'provide',\n",
              "  'token',\n",
              "  'preprocessor',\n",
              "  'function',\n",
              "  's',\n",
              "  'postprocess',\n",
              "  'function',\n",
              "  's',\n",
              "  'The',\n",
              "  'data',\n",
              "  'source',\n",
              "  'can',\n",
              "  'be',\n",
              "  'an',\n",
              "  'arbitrary',\n",
              "  'function',\n",
              "  'that',\n",
              "  'provides',\n",
              "  'a',\n",
              "  'tf.data.Dataset',\n",
              "  'but',\n",
              "  'we',\n",
              "  'also',\n",
              "  'provide',\n",
              "  'simpler',\n",
              "  'wrappers',\n",
              "  'for',\n",
              "  'datasets',\n",
              "  'available',\n",
              "  'in',\n",
              "  'TensorFlow',\n",
              "  'Datasets',\n",
              "  'TFDS',\n",
              "  'a',\n",
              "  'TfdsTask',\n",
              "  'or',\n",
              "  'stored',\n",
              "  'as',\n",
              "  'text',\n",
              "  'files',\n",
              "  'with',\n",
              "  'one',\n",
              "  'example',\n",
              "  'per',\n",
              "  'line',\n",
              "  'a',\n",
              "  'TextLineTask',\n",
              "  '.'],\n",
              " ['The',\n",
              "  'text',\n",
              "  'preprocessor',\n",
              "  'converts',\n",
              "  'the',\n",
              "  'examples',\n",
              "  'in',\n",
              "  'the',\n",
              "  'source',\n",
              "  'dataset',\n",
              "  'into',\n",
              "  'the',\n",
              "  'appropriate',\n",
              "  'format',\n",
              "  'for',\n",
              "  'a',\n",
              "  'text',\n",
              "  'to',\n",
              "  'text',\n",
              "  'model',\n",
              "  'with',\n",
              "  'fields',\n",
              "  'for',\n",
              "  'inputs',\n",
              "  'and',\n",
              "  'targets',\n",
              "  '.'],\n",
              " ['For',\n",
              "  'example',\n",
              "  'the',\n",
              "  'predefined',\n",
              "  't5.data.preprocessors.translate',\n",
              "  'preprocessor',\n",
              "  'converts',\n",
              "  'inputs',\n",
              "  'in',\n",
              "  'the',\n",
              "  'form',\n",
              "  'de',\n",
              "  'Das',\n",
              "  'ist',\n",
              "  'gut',\n",
              "  '.'],\n",
              " ['en', 'That', 'is', 'good', '.'],\n",
              " ['to',\n",
              "  'the',\n",
              "  'form',\n",
              "  'inputs',\n",
              "  'translate',\n",
              "  'German',\n",
              "  'to',\n",
              "  'English',\n",
              "  'Das',\n",
              "  'ist',\n",
              "  'gut',\n",
              "  '.'],\n",
              " ['targets', 'That', 'is', 'good', '.'],\n",
              " ['In',\n",
              "  'addition',\n",
              "  'to',\n",
              "  'text',\n",
              "  'preprocessing',\n",
              "  'you',\n",
              "  'can',\n",
              "  'also',\n",
              "  'use',\n",
              "  'one',\n",
              "  'or',\n",
              "  'more',\n",
              "  'token',\n",
              "  'preprocessors',\n",
              "  'to',\n",
              "  'modify',\n",
              "  'the',\n",
              "  'inputs',\n",
              "  'post',\n",
              "  'tokenization',\n",
              "  '.'],\n",
              " ['We',\n",
              "  'implemented',\n",
              "  'our',\n",
              "  'unsupervised',\n",
              "  'pre',\n",
              "  'training',\n",
              "  'objectives',\n",
              "  'using',\n",
              "  'these',\n",
              "  'token',\n",
              "  'preprocessors',\n",
              "  '.'],\n",
              " ['We',\n",
              "  'provide',\n",
              "  'many',\n",
              "  'predefined',\n",
              "  'preprocessors',\n",
              "  'in',\n",
              "  't5.data.preprocessors',\n",
              "  'but',\n",
              "  'you',\n",
              "  'may',\n",
              "  'also',\n",
              "  'define',\n",
              "  'your',\n",
              "  'own',\n",
              "  '.'],\n",
              " ['The',\n",
              "  'SentencePiece',\n",
              "  'model',\n",
              "  'is',\n",
              "  'used',\n",
              "  'to',\n",
              "  'tokenize',\n",
              "  'the',\n",
              "  'input',\n",
              "  'strings',\n",
              "  'and',\n",
              "  'decode',\n",
              "  'the',\n",
              "  'output',\n",
              "  'tokens',\n",
              "  '.'],\n",
              " ['You',\n",
              "  'can',\n",
              "  'create',\n",
              "  'your',\n",
              "  'own',\n",
              "  'model',\n",
              "  'with',\n",
              "  'the',\n",
              "  'google',\n",
              "  'sentencepiece',\n",
              "  'library',\n",
              "  'or',\n",
              "  'use',\n",
              "  'our',\n",
              "  'default',\n",
              "  'one',\n",
              "  'at',\n",
              "  't5.data.DEFAULT_SPM_PATH',\n",
              "  '.'],\n",
              " ['If',\n",
              "  'you',\n",
              "  'create',\n",
              "  'your',\n",
              "  'own',\n",
              "  'you',\n",
              "  'must',\n",
              "  'use',\n",
              "  'the',\n",
              "  'flags',\n",
              "  'pad_id',\n",
              "  '0',\n",
              "  'eos_id',\n",
              "  '1',\n",
              "  'unk_id',\n",
              "  '2',\n",
              "  'bos_id',\n",
              "  '1',\n",
              "  'with',\n",
              "  'spm_train',\n",
              "  'to',\n",
              "  'be',\n",
              "  'compatible',\n",
              "  'with',\n",
              "  'our',\n",
              "  'model',\n",
              "  'code',\n",
              "  '.'],\n",
              " ['The',\n",
              "  'metric',\n",
              "  'function',\n",
              "  'returns',\n",
              "  'a',\n",
              "  'score',\n",
              "  'given',\n",
              "  'the',\n",
              "  'target',\n",
              "  'and',\n",
              "  'prediction',\n",
              "  'from',\n",
              "  'the',\n",
              "  'model',\n",
              "  '.'],\n",
              " ['You',\n",
              "  'may',\n",
              "  'also',\n",
              "  'define',\n",
              "  'a',\n",
              "  'postprocess',\n",
              "  'function',\n",
              "  'to',\n",
              "  'convert',\n",
              "  'the',\n",
              "  'target',\n",
              "  'and',\n",
              "  'prediction',\n",
              "  'text',\n",
              "  'to',\n",
              "  'another',\n",
              "  'format',\n",
              "  'before',\n",
              "  'calling',\n",
              "  'the',\n",
              "  'metric',\n",
              "  '.'],\n",
              " ['We',\n",
              "  'provide',\n",
              "  'some',\n",
              "  'predefined',\n",
              "  'metrics',\n",
              "  'in',\n",
              "  't5.evaluation.metrics',\n",
              "  '.'],\n",
              " ['Finally',\n",
              "  't5.data',\n",
              "  'contains',\n",
              "  'a',\n",
              "  'Mixture',\n",
              "  'class',\n",
              "  'that',\n",
              "  'can',\n",
              "  'be',\n",
              "  'instantiated',\n",
              "  'to',\n",
              "  'combine',\n",
              "  'multiple',\n",
              "  'Task',\n",
              "  'datasets',\n",
              "  'for',\n",
              "  'multi',\n",
              "  'task',\n",
              "  'training',\n",
              "  'using',\n",
              "  'various',\n",
              "  'functions',\n",
              "  'for',\n",
              "  'specifying',\n",
              "  'the',\n",
              "  'mixture',\n",
              "  'rates',\n",
              "  '.'],\n",
              " ['t5.evaluation',\n",
              "  't5.evaluation',\n",
              "  'contains',\n",
              "  'two',\n",
              "  'core',\n",
              "  'components',\n",
              "  'metrics',\n",
              "  'to',\n",
              "  'be',\n",
              "  'used',\n",
              "  'during',\n",
              "  'evaluation',\n",
              "  'utilities',\n",
              "  'for',\n",
              "  'applying',\n",
              "  'these',\n",
              "  'metrics',\n",
              "  'at',\n",
              "  'evaluation',\n",
              "  'time',\n",
              "  't5.models',\n",
              "  't5.models',\n",
              "  'contains',\n",
              "  'shims',\n",
              "  'for',\n",
              "  'connecting',\n",
              "  'T5',\n",
              "  'Tasks',\n",
              "  'and',\n",
              "  'Mixtures',\n",
              "  'to',\n",
              "  'a',\n",
              "  'model',\n",
              "  'implementation',\n",
              "  'for',\n",
              "  'training',\n",
              "  'evaluation',\n",
              "  'and',\n",
              "  'inference',\n",
              "  '.'],\n",
              " ['Currently',\n",
              "  'there',\n",
              "  'are',\n",
              "  'two',\n",
              "  'shims',\n",
              "  'available',\n",
              "  'One',\n",
              "  'for',\n",
              "  'the',\n",
              "  'Mesh',\n",
              "  'TensorFlow',\n",
              "  'Transformer',\n",
              "  'that',\n",
              "  'we',\n",
              "  'used',\n",
              "  'in',\n",
              "  'our',\n",
              "  'paper',\n",
              "  'and',\n",
              "  'another',\n",
              "  'for',\n",
              "  'the',\n",
              "  'Hugging',\n",
              "  'Face',\n",
              "  'Transformers',\n",
              "  'library',\n",
              "  '.'],\n",
              " ['The',\n",
              "  'Hugging',\n",
              "  'Face',\n",
              "  'API',\n",
              "  'is',\n",
              "  'currently',\n",
              "  'experimental',\n",
              "  'and',\n",
              "  'subject',\n",
              "  'to',\n",
              "  'change',\n",
              "  'but',\n",
              "  'provides',\n",
              "  'a',\n",
              "  'simple',\n",
              "  'and',\n",
              "  'easy',\n",
              "  'way',\n",
              "  'to',\n",
              "  'load',\n",
              "  'fine',\n",
              "  'tune',\n",
              "  'and',\n",
              "  'evaluate',\n",
              "  'our',\n",
              "  'pre',\n",
              "  'trained',\n",
              "  'models',\n",
              "  'using',\n",
              "  'PyTorch',\n",
              "  'on',\n",
              "  'a',\n",
              "  'single',\n",
              "  'GPU',\n",
              "  '.'],\n",
              " ['If',\n",
              "  'you',\n",
              "  'want',\n",
              "  'to',\n",
              "  'use',\n",
              "  'our',\n",
              "  'largest',\n",
              "  'models',\n",
              "  'on',\n",
              "  'TPUs',\n",
              "  'and',\n",
              "  'or',\n",
              "  'reproduce',\n",
              "  'the',\n",
              "  'results',\n",
              "  'in',\n",
              "  'our',\n",
              "  'paper',\n",
              "  'you',\n",
              "  'should',\n",
              "  'use',\n",
              "  'the',\n",
              "  'MtfModel',\n",
              "  'API',\n",
              "  'and',\n",
              "  'the',\n",
              "  't5_mesh_transformer',\n",
              "  'binary',\n",
              "  '.'],\n",
              " ['If',\n",
              "  'you',\n",
              "  'are',\n",
              "  'interested',\n",
              "  'fine',\n",
              "  'tuning',\n",
              "  'our',\n",
              "  'models',\n",
              "  'on',\n",
              "  'a',\n",
              "  'GPU',\n",
              "  'in',\n",
              "  'PyTorch',\n",
              "  'you',\n",
              "  'should',\n",
              "  'try',\n",
              "  'the',\n",
              "  'HfPyTorchModel',\n",
              "  'API',\n",
              "  '.'],\n",
              " ['Since',\n",
              "  'the',\n",
              "  'HfPyTorchModel',\n",
              "  'is',\n",
              "  'experimental',\n",
              "  'the',\n",
              "  'remainder',\n",
              "  'of',\n",
              "  'this',\n",
              "  'README',\n",
              "  'assumes',\n",
              "  'usage',\n",
              "  'of',\n",
              "  'the',\n",
              "  'MtfModel',\n",
              "  'and',\n",
              "  'its',\n",
              "  'associated',\n",
              "  'binary',\n",
              "  '.'],\n",
              " ['A',\n",
              "  'usage',\n",
              "  'example',\n",
              "  'of',\n",
              "  'HfPyTorchModel',\n",
              "  'is',\n",
              "  'available',\n",
              "  'here',\n",
              "  '.'],\n",
              " ['Usage',\n",
              "  'The',\n",
              "  'easiest',\n",
              "  'way',\n",
              "  'to',\n",
              "  'try',\n",
              "  'out',\n",
              "  'T5',\n",
              "  'is',\n",
              "  'with',\n",
              "  'a',\n",
              "  'free',\n",
              "  'TPU',\n",
              "  'in',\n",
              "  'our',\n",
              "  'Colab',\n",
              "  'Tutorial',\n",
              "  '.'],\n",
              " ['Below',\n",
              "  'we',\n",
              "  'provide',\n",
              "  'examples',\n",
              "  'for',\n",
              "  'how',\n",
              "  'to',\n",
              "  'pre',\n",
              "  'train',\n",
              "  'fine',\n",
              "  'tune',\n",
              "  'evaluate',\n",
              "  'and',\n",
              "  'decode',\n",
              "  'from',\n",
              "  'a',\n",
              "  'model',\n",
              "  'from',\n",
              "  'the',\n",
              "  'command',\n",
              "  'line',\n",
              "  'with',\n",
              "  'our',\n",
              "  'codebase',\n",
              "  '.'],\n",
              " ['You',\n",
              "  'can',\n",
              "  'use',\n",
              "  'these',\n",
              "  'instructions',\n",
              "  'to',\n",
              "  'reproduce',\n",
              "  'our',\n",
              "  'results',\n",
              "  'fine',\n",
              "  'tune',\n",
              "  'one',\n",
              "  'of',\n",
              "  'our',\n",
              "  'released',\n",
              "  'checkpoints',\n",
              "  'with',\n",
              "  'your',\n",
              "  'own',\n",
              "  'data',\n",
              "  'and',\n",
              "  'or',\n",
              "  'hyperparameters',\n",
              "  'or',\n",
              "  'pre',\n",
              "  'train',\n",
              "  'a',\n",
              "  'model',\n",
              "  'from',\n",
              "  'scratch',\n",
              "  '.'],\n",
              " ['Dataset',\n",
              "  'Preparation',\n",
              "  'You',\n",
              "  'may',\n",
              "  'either',\n",
              "  'use',\n",
              "  'a',\n",
              "  'new',\n",
              "  'or',\n",
              "  'pre',\n",
              "  'existing',\n",
              "  'Task',\n",
              "  'or',\n",
              "  'you',\n",
              "  'may',\n",
              "  'load',\n",
              "  'examples',\n",
              "  'from',\n",
              "  'a',\n",
              "  'preprocessed',\n",
              "  'TSV',\n",
              "  'file',\n",
              "  '.'],\n",
              " ['Using',\n",
              "  'a',\n",
              "  'Task',\n",
              "  'Depending',\n",
              "  'on',\n",
              "  'your',\n",
              "  'data',\n",
              "  'source',\n",
              "  'see',\n",
              "  'above',\n",
              "  'you',\n",
              "  'will',\n",
              "  'need',\n",
              "  'to',\n",
              "  'prepare',\n",
              "  'your',\n",
              "  'data',\n",
              "  'appropriately',\n",
              "  '.'],\n",
              " ['Task',\n",
              "  'If',\n",
              "  'using',\n",
              "  'a',\n",
              "  'vanilla',\n",
              "  'task',\n",
              "  'just',\n",
              "  'make',\n",
              "  'sure',\n",
              "  'any',\n",
              "  'file',\n",
              "  's',\n",
              "  'loaded',\n",
              "  'by',\n",
              "  'your',\n",
              "  'dataset_fn',\n",
              "  'are',\n",
              "  'accessible',\n",
              "  'to',\n",
              "  'the',\n",
              "  'TPU',\n",
              "  'i.e',\n",
              "  '.',\n",
              "  'are',\n",
              "  'in',\n",
              "  'a',\n",
              "  'GCS',\n",
              "  'bucket',\n",
              "  'and',\n",
              "  'you',\n",
              "  'should',\n",
              "  'be',\n",
              "  'good',\n",
              "  'to',\n",
              "  'go'],\n",
              " ['TfdsTask',\n",
              "  'Most',\n",
              "  'of',\n",
              "  'our',\n",
              "  'predefined',\n",
              "  'Tasks',\n",
              "  'use',\n",
              "  'TensorFlow',\n",
              "  'Datasets',\n",
              "  'TFDS',\n",
              "  'as',\n",
              "  'their',\n",
              "  'data',\n",
              "  'source',\n",
              "  '.'],\n",
              " ['When',\n",
              "  'you',\n",
              "  'run',\n",
              "  'our',\n",
              "  'training',\n",
              "  'binary',\n",
              "  'see',\n",
              "  'instructions',\n",
              "  'below',\n",
              "  'with',\n",
              "  'a',\n",
              "  'TfdsTask',\n",
              "  'the',\n",
              "  'dataset',\n",
              "  'will',\n",
              "  'automatically',\n",
              "  'be',\n",
              "  'downloaded',\n",
              "  'and',\n",
              "  'prepared',\n",
              "  'on',\n",
              "  'its',\n",
              "  'first',\n",
              "  'use',\n",
              "  '.'],\n",
              " ['After',\n",
              "  'preparation',\n",
              "  'is',\n",
              "  'complete',\n",
              "  'the',\n",
              "  'dataset',\n",
              "  'is',\n",
              "  'cached',\n",
              "  'to',\n",
              "  'your',\n",
              "  'local',\n",
              "  'storage',\n",
              "  'to',\n",
              "  'avoid',\n",
              "  'this',\n",
              "  'overhead',\n",
              "  'in',\n",
              "  'future',\n",
              "  'runs',\n",
              "  '.'],\n",
              " ['If',\n",
              "  'working',\n",
              "  'in',\n",
              "  'the',\n",
              "  'cloud',\n",
              "  'we',\n",
              "  'recommend',\n",
              "  'you',\n",
              "  'set',\n",
              "  'the',\n",
              "  't5_tfds_data_dir',\n",
              "  'flag',\n",
              "  'to',\n",
              "  'point',\n",
              "  'to',\n",
              "  'a',\n",
              "  'persistent',\n",
              "  'storage',\n",
              "  'location',\n",
              "  'such',\n",
              "  'as',\n",
              "  'a',\n",
              "  'GCS',\n",
              "  'bucket',\n",
              "  '.'],\n",
              " ['This', 'is', 'a', 'requirement', 'when', 'training', 'on', 'TPU', '.'],\n",
              " ['C4',\n",
              "  'The',\n",
              "  'C4',\n",
              "  'dataset',\n",
              "  'we',\n",
              "  'created',\n",
              "  'for',\n",
              "  'unsupervised',\n",
              "  'pre',\n",
              "  'training',\n",
              "  'is',\n",
              "  'available',\n",
              "  'in',\n",
              "  'TensorFlow',\n",
              "  'Datasets',\n",
              "  'but',\n",
              "  'it',\n",
              "  'requires',\n",
              "  'a',\n",
              "  'significant',\n",
              "  'amount',\n",
              "  'of',\n",
              "  'bandwidth',\n",
              "  'for',\n",
              "  'downloading',\n",
              "  'the',\n",
              "  'raw',\n",
              "  'Common',\n",
              "  'Crawl',\n",
              "  'scrapes',\n",
              "  '7',\n",
              "  'TB',\n",
              "  'and',\n",
              "  'compute',\n",
              "  'for',\n",
              "  'its',\n",
              "  'preparation',\n",
              "  '335',\n",
              "  'CPU',\n",
              "  'days',\n",
              "  '.'],\n",
              " ['We',\n",
              "  'suggest',\n",
              "  'you',\n",
              "  'take',\n",
              "  'advantage',\n",
              "  'of',\n",
              "  'the',\n",
              "  'Apache',\n",
              "  'Beam',\n",
              "  'support',\n",
              "  'in',\n",
              "  'TFDS',\n",
              "  'which',\n",
              "  'enables',\n",
              "  'distributed',\n",
              "  'preprocessing',\n",
              "  'of',\n",
              "  'the',\n",
              "  'dataset',\n",
              "  'and',\n",
              "  'can',\n",
              "  'be',\n",
              "  'run',\n",
              "  'on',\n",
              "  'Google',\n",
              "  'Cloud',\n",
              "  'Dataflow',\n",
              "  '.'],\n",
              " ['With',\n",
              "  '500',\n",
              "  'workers',\n",
              "  'the',\n",
              "  'job',\n",
              "  'should',\n",
              "  'complete',\n",
              "  'in',\n",
              "  '16',\n",
              "  'hours',\n",
              "  '.'],\n",
              " ['After',\n",
              "  'defining',\n",
              "  'MY_PROJECT',\n",
              "  'and',\n",
              "  'MY_BUCKET',\n",
              "  'appropriately',\n",
              "  'you',\n",
              "  'can',\n",
              "  'build',\n",
              "  'the',\n",
              "  'dataset',\n",
              "  'in',\n",
              "  'DataFlow',\n",
              "  'from',\n",
              "  'GCP',\n",
              "  'using',\n",
              "  'the',\n",
              "  'following',\n",
              "  'commands',\n",
              "  'pip',\n",
              "  'install',\n",
              "  'tfds',\n",
              "  'nightly',\n",
              "  'c4',\n",
              "  'echo',\n",
              "  'tfds',\n",
              "  'nightly',\n",
              "  'c4',\n",
              "  'tmp',\n",
              "  'beam_requirements.txt',\n",
              "  'python',\n",
              "  'm',\n",
              "  'tensorflow_datasets.scripts.download_and_prepare',\n",
              "  'datasets',\n",
              "  'c4',\n",
              "  'en',\n",
              "  'data_dir',\n",
              "  'gs',\n",
              "  'MY_BUCKET',\n",
              "  'tensorflow_datasets',\n",
              "  'beam_pipeline_options',\n",
              "  'project',\n",
              "  'MY_PROJECT',\n",
              "  'job_name',\n",
              "  'c4',\n",
              "  'staging_location',\n",
              "  'gs',\n",
              "  'MY_BUCKET',\n",
              "  'binaries',\n",
              "  'temp_location',\n",
              "  'gs',\n",
              "  'MY_BUCKET',\n",
              "  'temp',\n",
              "  'runner',\n",
              "  'DataflowRunner',\n",
              "  'requirements_file',\n",
              "  'tmp',\n",
              "  'beam_requirements.txt',\n",
              "  'experiments',\n",
              "  'shuffle_mode',\n",
              "  'service',\n",
              "  'region',\n",
              "  'MY_REGION',\n",
              "  'Read',\n",
              "  'more',\n",
              "  'in',\n",
              "  'the',\n",
              "  'TFDS',\n",
              "  'Beam',\n",
              "  'instructions',\n",
              "  '.'],\n",
              " ['TextLineTask',\n",
              "  'A',\n",
              "  'TextLineTask',\n",
              "  'is',\n",
              "  'useful',\n",
              "  'when',\n",
              "  'your',\n",
              "  'data',\n",
              "  'source',\n",
              "  'is',\n",
              "  'a',\n",
              "  'text',\n",
              "  'file',\n",
              "  'or',\n",
              "  'files',\n",
              "  'with',\n",
              "  'one',\n",
              "  'example',\n",
              "  'per',\n",
              "  'line',\n",
              "  '.'],\n",
              " ['You',\n",
              "  'can',\n",
              "  'then',\n",
              "  'use',\n",
              "  'a',\n",
              "  'text',\n",
              "  'preprocessor',\n",
              "  'to',\n",
              "  'convert',\n",
              "  'each',\n",
              "  'line',\n",
              "  'into',\n",
              "  'a',\n",
              "  'dictionary',\n",
              "  'of',\n",
              "  'inputs',\n",
              "  'and',\n",
              "  'targets',\n",
              "  '.'],\n",
              " ['Make',\n",
              "  'sure',\n",
              "  'your',\n",
              "  'files',\n",
              "  'are',\n",
              "  'accessible',\n",
              "  'to',\n",
              "  'the',\n",
              "  'TPU',\n",
              "  'i.e',\n",
              "  '.',\n",
              "  'are',\n",
              "  'in',\n",
              "  'a',\n",
              "  'GCS',\n",
              "  'bucket',\n",
              "  'and',\n",
              "  'you',\n",
              "  'should',\n",
              "  'be',\n",
              "  'good',\n",
              "  'to',\n",
              "  'go'],\n",
              " ['Using',\n",
              "  'a',\n",
              "  'TSV',\n",
              "  'File',\n",
              "  'Directly',\n",
              "  'Instead',\n",
              "  'of',\n",
              "  'defining',\n",
              "  'a',\n",
              "  'new',\n",
              "  'Task',\n",
              "  'you',\n",
              "  'may',\n",
              "  'use',\n",
              "  'a',\n",
              "  'TSV',\n",
              "  'file',\n",
              "  'or',\n",
              "  'files',\n",
              "  'directly',\n",
              "  'as',\n",
              "  'your',\n",
              "  'dataset',\n",
              "  'where',\n",
              "  'each',\n",
              "  'line',\n",
              "  'is',\n",
              "  'formatted',\n",
              "  'as',\n",
              "  'input',\n",
              "  't',\n",
              "  'target',\n",
              "  '.'],\n",
              " ['However',\n",
              "  'there',\n",
              "  'are',\n",
              "  'a',\n",
              "  'couple',\n",
              "  'of',\n",
              "  'caveats',\n",
              "  'There',\n",
              "  'is',\n",
              "  'no',\n",
              "  'way',\n",
              "  'to',\n",
              "  'define',\n",
              "  'a',\n",
              "  'text',\n",
              "  'processor',\n",
              "  'so',\n",
              "  'the',\n",
              "  'TSV',\n",
              "  'will',\n",
              "  'need',\n",
              "  'to',\n",
              "  'contain',\n",
              "  'your',\n",
              "  'data',\n",
              "  'in',\n",
              "  'a',\n",
              "  'preprocessed',\n",
              "  'format',\n",
              "  '.'],\n",
              " ['There',\n",
              "  'is',\n",
              "  'also',\n",
              "  'currently',\n",
              "  'no',\n",
              "  'way',\n",
              "  'to',\n",
              "  'set',\n",
              "  'a',\n",
              "  'token',\n",
              "  'preprocessor',\n",
              "  'postprocess',\n",
              "  'function',\n",
              "  'or',\n",
              "  'metric',\n",
              "  'function',\n",
              "  'for',\n",
              "  'evaluation',\n",
              "  'when',\n",
              "  'using',\n",
              "  'a',\n",
              "  'TSV',\n",
              "  'file',\n",
              "  'directly',\n",
              "  '.'],\n",
              " ['If',\n",
              "  'you',\n",
              "  'need',\n",
              "  'any',\n",
              "  'of',\n",
              "  'these',\n",
              "  'features',\n",
              "  'you',\n",
              "  'must',\n",
              "  'define',\n",
              "  'a',\n",
              "  'new',\n",
              "  'Task',\n",
              "  'TfdsTask',\n",
              "  'or',\n",
              "  'TextLineTask',\n",
              "  '.'],\n",
              " ['Similar',\n",
              "  'to',\n",
              "  'the',\n",
              "  'above',\n",
              "  'cases',\n",
              "  'your',\n",
              "  'TSV',\n",
              "  'file',\n",
              "  's',\n",
              "  'must',\n",
              "  'be',\n",
              "  'accessible',\n",
              "  'to',\n",
              "  'the',\n",
              "  'TPU',\n",
              "  'i.e',\n",
              "  '.',\n",
              "  'are',\n",
              "  'in',\n",
              "  'a',\n",
              "  'GCS',\n",
              "  'bucket',\n",
              "  '.'],\n",
              " ['Installation',\n",
              "  'To',\n",
              "  'install',\n",
              "  'the',\n",
              "  'T5',\n",
              "  'package',\n",
              "  'simply',\n",
              "  'run',\n",
              "  'pip',\n",
              "  'install',\n",
              "  't5',\n",
              "  'gcp',\n",
              "  'Setting',\n",
              "  'up',\n",
              "  'TPUs',\n",
              "  'on',\n",
              "  'GCP',\n",
              "  'You',\n",
              "  'will',\n",
              "  'first',\n",
              "  'need',\n",
              "  'to',\n",
              "  'launch',\n",
              "  'a',\n",
              "  'Virtual',\n",
              "  'Machine',\n",
              "  'VM',\n",
              "  'on',\n",
              "  'Google',\n",
              "  'Cloud',\n",
              "  '.'],\n",
              " ['Details',\n",
              "  'about',\n",
              "  'launching',\n",
              "  'the',\n",
              "  'VM',\n",
              "  'can',\n",
              "  'be',\n",
              "  'found',\n",
              "  'at',\n",
              "  'the',\n",
              "  'Google',\n",
              "  'Cloud',\n",
              "  'Documentation',\n",
              "  '.'],\n",
              " ['In',\n",
              "  'order',\n",
              "  'to',\n",
              "  'run',\n",
              "  'training',\n",
              "  'or',\n",
              "  'eval',\n",
              "  'on',\n",
              "  'Cloud',\n",
              "  'TPUs',\n",
              "  'you',\n",
              "  'must',\n",
              "  'set',\n",
              "  'up',\n",
              "  'the',\n",
              "  'following',\n",
              "  'variables',\n",
              "  'based',\n",
              "  'on',\n",
              "  'your',\n",
              "  'project',\n",
              "  'zone',\n",
              "  'and',\n",
              "  'GCS',\n",
              "  'bucket',\n",
              "  'appropriately',\n",
              "  '.'],\n",
              " ['Please',\n",
              "  'refer',\n",
              "  'to',\n",
              "  'the',\n",
              "  'Cloud',\n",
              "  'TPU',\n",
              "  'Quickstart',\n",
              "  'guide',\n",
              "  'for',\n",
              "  'more',\n",
              "  'details',\n",
              "  '.'],\n",
              " ['export',\n",
              "  'PROJECT',\n",
              "  'your_project_name',\n",
              "  'export',\n",
              "  'ZONE',\n",
              "  'your_project_zone',\n",
              "  'export',\n",
              "  'BUCKET',\n",
              "  'gs',\n",
              "  'yourbucket',\n",
              "  'export',\n",
              "  'TPU_NAME',\n",
              "  't5',\n",
              "  'tpu',\n",
              "  'export',\n",
              "  'TPU_SIZE',\n",
              "  'v3',\n",
              "  '8',\n",
              "  'export',\n",
              "  'DATA_DIR',\n",
              "  'BUCKET',\n",
              "  'your_data_dir',\n",
              "  'export',\n",
              "  'MODEL_DIR',\n",
              "  'BUCKET',\n",
              "  'your_model_dir',\n",
              "  'Please',\n",
              "  'use',\n",
              "  'the',\n",
              "  'following',\n",
              "  'command',\n",
              "  'to',\n",
              "  'create',\n",
              "  'a',\n",
              "  'TPU',\n",
              "  'device',\n",
              "  'in',\n",
              "  'the',\n",
              "  'Cloud',\n",
              "  'VM',\n",
              "  '.'],\n",
              " ['ctpu',\n",
              "  'up',\n",
              "  'name',\n",
              "  'TPU_NAME',\n",
              "  'project',\n",
              "  'PROJECT',\n",
              "  'zone',\n",
              "  'ZONE',\n",
              "  'tpu',\n",
              "  'size',\n",
              "  'TPU_SIZE',\n",
              "  'tpu',\n",
              "  'only',\n",
              "  'noconf',\n",
              "  'Training',\n",
              "  'In',\n",
              "  'the',\n",
              "  'command',\n",
              "  'below',\n",
              "  'we',\n",
              "  'train',\n",
              "  'a',\n",
              "  'model',\n",
              "  'on',\n",
              "  'the',\n",
              "  'GLUE',\n",
              "  'Benchmark',\n",
              "  'MRPC',\n",
              "  'task',\n",
              "  'from',\n",
              "  'scratch',\n",
              "  '.'],\n",
              " ['You',\n",
              "  'can',\n",
              "  'change',\n",
              "  'the',\n",
              "  'MIXTURE_NAME',\n",
              "  'gin',\n",
              "  'parameter',\n",
              "  'to',\n",
              "  'use',\n",
              "  'any',\n",
              "  'of',\n",
              "  'the',\n",
              "  'tasks',\n",
              "  'or',\n",
              "  'mixtures',\n",
              "  'provided',\n",
              "  'in',\n",
              "  'our',\n",
              "  'package',\n",
              "  '.'],\n",
              " ['t5_mesh_transformer',\n",
              "  'tpu',\n",
              "  'TPU_NAME',\n",
              "  'gcp_project',\n",
              "  'PROJECT',\n",
              "  'tpu_zone',\n",
              "  'ZONE',\n",
              "  'model_dir',\n",
              "  'MODEL_DIR',\n",
              "  't5_tfds_data_dir',\n",
              "  'DATA_DIR',\n",
              "  'gin_file',\n",
              "  'dataset.gin',\n",
              "  'gin_file',\n",
              "  'models',\n",
              "  'bi_v1.gin',\n",
              "  'gin_param',\n",
              "  'utils.tpu_mesh_shape.model_parallelism',\n",
              "  '1',\n",
              "  'gin_param',\n",
              "  'utils.tpu_mesh_shape.tpu_topology',\n",
              "  'TPU_SIZE',\n",
              "  'gin_param',\n",
              "  'MIXTURE_NAME',\n",
              "  'glue_mrpc_v002',\n",
              "  'The',\n",
              "  'full',\n",
              "  'list',\n",
              "  'of',\n",
              "  'tasks',\n",
              "  'and',\n",
              "  'mixtures',\n",
              "  'can',\n",
              "  'be',\n",
              "  'obtained',\n",
              "  'by',\n",
              "  'running',\n",
              "  'python',\n",
              "  'c',\n",
              "  'import',\n",
              "  't5',\n",
              "  ';',\n",
              "  'print',\n",
              "  't5.data.MixtureRegistry.names',\n",
              "  'You',\n",
              "  'may',\n",
              "  'also',\n",
              "  'define',\n",
              "  'additional',\n",
              "  'tasks',\n",
              "  'and',\n",
              "  'mixtures',\n",
              "  'in',\n",
              "  'a',\n",
              "  'new',\n",
              "  'file',\n",
              "  'and',\n",
              "  'import',\n",
              "  'it',\n",
              "  'using',\n",
              "  'the',\n",
              "  'module_import',\n",
              "  'flag',\n",
              "  '.'],\n",
              " ['Alternatively',\n",
              "  'you',\n",
              "  'could',\n",
              "  'train',\n",
              "  'with',\n",
              "  'a',\n",
              "  'TSV',\n",
              "  'file',\n",
              "  'where',\n",
              "  'each',\n",
              "  'line',\n",
              "  'is',\n",
              "  'formatted',\n",
              "  'as',\n",
              "  'input',\n",
              "  't',\n",
              "  'target',\n",
              "  'see',\n",
              "  'above',\n",
              "  '.'],\n",
              " ['Fine',\n",
              "  'tuning',\n",
              "  'In',\n",
              "  'order',\n",
              "  'to',\n",
              "  'fine',\n",
              "  'tune',\n",
              "  'one',\n",
              "  'of',\n",
              "  'our',\n",
              "  'pre',\n",
              "  'trained',\n",
              "  'models',\n",
              "  'you',\n",
              "  'need',\n",
              "  'to',\n",
              "  'pass',\n",
              "  'the',\n",
              "  'operative',\n",
              "  'config',\n",
              "  'of',\n",
              "  'the',\n",
              "  'pre',\n",
              "  'trained',\n",
              "  'model',\n",
              "  'to',\n",
              "  'the',\n",
              "  'training',\n",
              "  'script',\n",
              "  '.'],\n",
              " ['The',\n",
              "  'operative',\n",
              "  'config',\n",
              "  'should',\n",
              "  'be',\n",
              "  'passed',\n",
              "  'in',\n",
              "  'as',\n",
              "  'a',\n",
              "  'gin_file',\n",
              "  'flag',\n",
              "  '.'],\n",
              " ['It',\n",
              "  'specifies',\n",
              "  'the',\n",
              "  'model',\n",
              "  'architecture',\n",
              "  'and',\n",
              "  'other',\n",
              "  'hyperparameters',\n",
              "  '.'],\n",
              " ['In',\n",
              "  'addition',\n",
              "  'you',\n",
              "  'need',\n",
              "  'to',\n",
              "  'specify',\n",
              "  'the',\n",
              "  'mixture',\n",
              "  'to',\n",
              "  'fine',\n",
              "  'tune',\n",
              "  'on',\n",
              "  '.'],\n",
              " ['For',\n",
              "  'example',\n",
              "  'to',\n",
              "  'fine',\n",
              "  'tune',\n",
              "  'the',\n",
              "  'T5',\n",
              "  'small',\n",
              "  'model',\n",
              "  'on',\n",
              "  'the',\n",
              "  'glue_mrpc_v002',\n",
              "  'mixture',\n",
              "  'please',\n",
              "  'run',\n",
              "  't5_mesh_transformer',\n",
              "  'tpu',\n",
              "  'TPU_NAME',\n",
              "  'gcp_project',\n",
              "  'PROJECT',\n",
              "  'tpu_zone',\n",
              "  'ZONE',\n",
              "  'model_dir',\n",
              "  'MODEL_DIR',\n",
              "  't5_tfds_data_dir',\n",
              "  'DATA_DIR',\n",
              "  'gin_file',\n",
              "  'dataset.gin',\n",
              "  'gin_param',\n",
              "  'utils.tpu_mesh_shape.model_parallelism',\n",
              "  '1',\n",
              "  'gin_param',\n",
              "  'utils.tpu_mesh_shape.tpu_topology',\n",
              "  'TPU_SIZE',\n",
              "  'gin_param',\n",
              "  'MIXTURE_NAME',\n",
              "  'glue_mrpc_v002',\n",
              "  'gin_file',\n",
              "  'gs',\n",
              "  't5',\n",
              "  'data',\n",
              "  'pretrained_models',\n",
              "  'small',\n",
              "  'operative_config.gin',\n",
              "  'The',\n",
              "  'correct',\n",
              "  'pre',\n",
              "  'trained',\n",
              "  'checkpoint',\n",
              "  'path',\n",
              "  'is',\n",
              "  'included',\n",
              "  'in',\n",
              "  'the',\n",
              "  'operative',\n",
              "  'config',\n",
              "  '.'],\n",
              " ['You',\n",
              "  'may',\n",
              "  'also',\n",
              "  'define',\n",
              "  'additional',\n",
              "  'tasks',\n",
              "  'and',\n",
              "  'mixtures',\n",
              "  'in',\n",
              "  'a',\n",
              "  'new',\n",
              "  'file',\n",
              "  'and',\n",
              "  'import',\n",
              "  'it',\n",
              "  'using',\n",
              "  'the',\n",
              "  'module_import',\n",
              "  'flag',\n",
              "  '.'],\n",
              " ['Alternatively',\n",
              "  'you',\n",
              "  'could',\n",
              "  'fine',\n",
              "  'tune',\n",
              "  'with',\n",
              "  'a',\n",
              "  'TSV',\n",
              "  'file',\n",
              "  'where',\n",
              "  'each',\n",
              "  'line',\n",
              "  'is',\n",
              "  'formatted',\n",
              "  'as',\n",
              "  'input',\n",
              "  't',\n",
              "  'target',\n",
              "  'see',\n",
              "  'above',\n",
              "  '.'],\n",
              " ['For',\n",
              "  'example',\n",
              "  'you',\n",
              "  'could',\n",
              "  'try',\n",
              "  'one',\n",
              "  'of',\n",
              "  'the',\n",
              "  'paired',\n",
              "  'translation',\n",
              "  'datasets',\n",
              "  'from',\n",
              "  'WMT',\n",
              "  '19',\n",
              "  'News',\n",
              "  'Commentary',\n",
              "  '14',\n",
              "  'training',\n",
              "  'set',\n",
              "  'e.g',\n",
              "  '.',\n",
              "  'English',\n",
              "  'French',\n",
              "  '.'],\n",
              " ['When',\n",
              "  'using',\n",
              "  'a',\n",
              "  'TSV',\n",
              "  'file',\n",
              "  'you',\n",
              "  'would',\n",
              "  'replace',\n",
              "  'the',\n",
              "  'MIXTURE_NAME',\n",
              "  'flag',\n",
              "  'with',\n",
              "  'gin_param',\n",
              "  'utils.run.train_dataset_fn',\n",
              "  '@',\n",
              "  't5.models.mesh_transformer.tsv_dataset_fn',\n",
              "  'gin_param',\n",
              "  'tsv_dataset_fn.filename',\n",
              "  'gs',\n",
              "  'path',\n",
              "  'to',\n",
              "  'tsv',\n",
              "  'To',\n",
              "  'fine',\n",
              "  'tune',\n",
              "  'with',\n",
              "  'the',\n",
              "  'same',\n",
              "  'hyperparameters',\n",
              "  'we',\n",
              "  'used',\n",
              "  'in',\n",
              "  'the',\n",
              "  'paper',\n",
              "  'using',\n",
              "  'a',\n",
              "  'constant',\n",
              "  'learning',\n",
              "  'rate',\n",
              "  'of',\n",
              "  '0.001',\n",
              "  'you',\n",
              "  'can',\n",
              "  'pass',\n",
              "  'in',\n",
              "  'this',\n",
              "  'gin',\n",
              "  'file',\n",
              "  'which',\n",
              "  'is',\n",
              "  'included',\n",
              "  'in',\n",
              "  'the',\n",
              "  'T5',\n",
              "  'package',\n",
              "  'gin_file',\n",
              "  'learning_rate_schedules',\n",
              "  'constant_0_001.gin',\n",
              "  'The',\n",
              "  'operative',\n",
              "  'config',\n",
              "  'for',\n",
              "  'the',\n",
              "  'pre',\n",
              "  'trained',\n",
              "  'models',\n",
              "  'are',\n",
              "  'set',\n",
              "  'so',\n",
              "  'that',\n",
              "  'there',\n",
              "  'is',\n",
              "  'effectively',\n",
              "  'no',\n",
              "  'limit',\n",
              "  'on',\n",
              "  'the',\n",
              "  'number',\n",
              "  'of',\n",
              "  'train',\n",
              "  'steps',\n",
              "  '.'],\n",
              " ['If',\n",
              "  'you',\n",
              "  'd',\n",
              "  'like',\n",
              "  'to',\n",
              "  'train',\n",
              "  'for',\n",
              "  'a',\n",
              "  'specific',\n",
              "  'number',\n",
              "  'of',\n",
              "  'steps',\n",
              "  'you',\n",
              "  'll',\n",
              "  'need',\n",
              "  'to',\n",
              "  'pass',\n",
              "  'that',\n",
              "  'in',\n",
              "  '.'],\n",
              " ['Since',\n",
              "  'the',\n",
              "  'pre',\n",
              "  'trained',\n",
              "  'model',\n",
              "  'has',\n",
              "  'already',\n",
              "  'been',\n",
              "  'trained',\n",
              "  'for',\n",
              "  '1',\n",
              "  '000',\n",
              "  '000',\n",
              "  'steps',\n",
              "  'you',\n",
              "  'should',\n",
              "  'specify',\n",
              "  'the',\n",
              "  'total',\n",
              "  'number',\n",
              "  'of',\n",
              "  'steps',\n",
              "  'after',\n",
              "  'pre',\n",
              "  'training',\n",
              "  'and',\n",
              "  'fine',\n",
              "  'tuning',\n",
              "  '.'],\n",
              " ['For',\n",
              "  'example',\n",
              "  'if',\n",
              "  'you',\n",
              "  'want',\n",
              "  'to',\n",
              "  'fine',\n",
              "  'tune',\n",
              "  'for',\n",
              "  'an',\n",
              "  'additional',\n",
              "  '10',\n",
              "  '000',\n",
              "  'steps',\n",
              "  'you',\n",
              "  'should',\n",
              "  'pass',\n",
              "  'gin_param',\n",
              "  'run.train_steps',\n",
              "  '1010000',\n",
              "  'You',\n",
              "  'can',\n",
              "  'also',\n",
              "  'use',\n",
              "  'a',\n",
              "  'different',\n",
              "  'batch',\n",
              "  'size',\n",
              "  'for',\n",
              "  'fine',\n",
              "  'tuning',\n",
              "  '.'],\n",
              " ['We',\n",
              "  'set',\n",
              "  'the',\n",
              "  'batch',\n",
              "  'size',\n",
              "  'according',\n",
              "  'to',\n",
              "  'the',\n",
              "  'total',\n",
              "  'number',\n",
              "  'of',\n",
              "  'tokens',\n",
              "  'in',\n",
              "  'a',\n",
              "  'batch',\n",
              "  '.'],\n",
              " ['By',\n",
              "  'default',\n",
              "  'a',\n",
              "  'batch',\n",
              "  'uses',\n",
              "  'a',\n",
              "  'sequence',\n",
              "  'length',\n",
              "  'of',\n",
              "  '512',\n",
              "  '.'],\n",
              " ['To',\n",
              "  'set',\n",
              "  'the',\n",
              "  'number',\n",
              "  'of',\n",
              "  'tokens',\n",
              "  'in',\n",
              "  'a',\n",
              "  'batch',\n",
              "  'you',\n",
              "  'should',\n",
              "  'set',\n",
              "  'gin_param',\n",
              "  'tokens_per_batch',\n",
              "  '1048576',\n",
              "  'Eval',\n",
              "  'In',\n",
              "  'order',\n",
              "  'to',\n",
              "  'evaluate',\n",
              "  'a',\n",
              "  'model',\n",
              "  'in',\n",
              "  'the',\n",
              "  'T5',\n",
              "  'framework',\n",
              "  'you',\n",
              "  'need',\n",
              "  'to',\n",
              "  'use',\n",
              "  'the',\n",
              "  'eval.gin',\n",
              "  'file',\n",
              "  'specify',\n",
              "  'the',\n",
              "  'model',\n",
              "  'directory',\n",
              "  'decoding',\n",
              "  'method',\n",
              "  'and',\n",
              "  'which',\n",
              "  'checkpoint',\n",
              "  'step',\n",
              "  's',\n",
              "  'to',\n",
              "  'evaluate',\n",
              "  '.'],\n",
              " ['So',\n",
              "  'to',\n",
              "  'evaluate',\n",
              "  'on',\n",
              "  'the',\n",
              "  'GLUE',\n",
              "  'MRPC',\n",
              "  'task',\n",
              "  'using',\n",
              "  'beam',\n",
              "  'search',\n",
              "  'on',\n",
              "  'all',\n",
              "  'checkpoints',\n",
              "  'use',\n",
              "  'the',\n",
              "  'following',\n",
              "  'command',\n",
              "  't5_mesh_transformer',\n",
              "  'tpu',\n",
              "  'TPU_NAME',\n",
              "  'gcp_project',\n",
              "  'PROJECT',\n",
              "  'tpu_zone',\n",
              "  'ZONE',\n",
              "  'model_dir',\n",
              "  'MODEL_DIR',\n",
              "  'gin_file',\n",
              "  'MODEL_DIR',\n",
              "  'operative_config.gin',\n",
              "  't5_tfds_data_dir',\n",
              "  'DATA_DIR',\n",
              "  'gin_file',\n",
              "  'eval.gin',\n",
              "  'gin_file',\n",
              "  'beam_search.gin',\n",
              "  'gin_param',\n",
              "  'run.dataset_split',\n",
              "  'validation',\n",
              "  'gin_param',\n",
              "  'utils.tpu_mesh_shape.tpu_topology',\n",
              "  'TPU_SIZE',\n",
              "  'gin_param',\n",
              "  'MIXTURE_NAME',\n",
              "  'glue_mrpc_v002',\n",
              "  'gin_param',\n",
              "  'eval_checkpoint_step',\n",
              "  'all',\n",
              "  'To',\n",
              "  'evaluate',\n",
              "  'a',\n",
              "  'specific',\n",
              "  'checkpoint',\n",
              "  'simply',\n",
              "  'set',\n",
              "  'the',\n",
              "  'eval_checkpoint_step',\n",
              "  'parameter',\n",
              "  'to',\n",
              "  'appropriate',\n",
              "  'checkpoint',\n",
              "  '.'],\n",
              " ['gin_param',\n",
              "  'eval_checkpoint_step',\n",
              "  '100000',\n",
              "  'You',\n",
              "  'can',\n",
              "  'also',\n",
              "  'use',\n",
              "  'greedy_decode.gin',\n",
              "  'or',\n",
              "  'sample_decode.gin',\n",
              "  'instead',\n",
              "  'of',\n",
              "  'beam_search.gin',\n",
              "  'in',\n",
              "  'the',\n",
              "  'command',\n",
              "  'above',\n",
              "  '.'],\n",
              " ['Decode',\n",
              "  'In',\n",
              "  'order',\n",
              "  'to',\n",
              "  'produce',\n",
              "  'predictions',\n",
              "  'from',\n",
              "  'a',\n",
              "  'model',\n",
              "  'in',\n",
              "  'the',\n",
              "  'T5',\n",
              "  'framework',\n",
              "  'you',\n",
              "  'need',\n",
              "  'to',\n",
              "  'specify',\n",
              "  'the',\n",
              "  'model',\n",
              "  'directory',\n",
              "  'decoding',\n",
              "  'method',\n",
              "  'and',\n",
              "  'which',\n",
              "  'checkpoint',\n",
              "  'step',\n",
              "  's',\n",
              "  'to',\n",
              "  'use',\n",
              "  'for',\n",
              "  'decoding',\n",
              "  '.'],\n",
              " ['Assuming',\n",
              "  'you',\n",
              "  'have',\n",
              "  'a',\n",
              "  'text',\n",
              "  'file',\n",
              "  'of',\n",
              "  'input',\n",
              "  'sequences',\n",
              "  'stored',\n",
              "  'at',\n",
              "  'path',\n",
              "  'to',\n",
              "  'intputs.txt',\n",
              "  'an',\n",
              "  'example',\n",
              "  'command',\n",
              "  'would',\n",
              "  'be',\n",
              "  't5_mesh_transformer',\n",
              "  'tpu',\n",
              "  'TPU_NAME',\n",
              "  'gcp_project',\n",
              "  'PROJECT',\n",
              "  'tpu_zone',\n",
              "  'ZONE',\n",
              "  'model_dir',\n",
              "  'MODEL_DIR',\n",
              "  'gin_file',\n",
              "  'MODEL_DIR',\n",
              "  'operative_config.gin',\n",
              "  'gin_file',\n",
              "  'infer.gin',\n",
              "  'gin_file',\n",
              "  'sample_decode.gin',\n",
              "  'gin_param',\n",
              "  'input_filename',\n",
              "  'path',\n",
              "  'to',\n",
              "  'inputs.txt',\n",
              "  'gin_param',\n",
              "  'output_filename',\n",
              "  'tmp',\n",
              "  'outputs.txt',\n",
              "  'gin_param',\n",
              "  'utils.tpu_mesh_shape.tpu_topology',\n",
              "  'TPU_SIZE',\n",
              "  'gin_param',\n",
              "  'infer_checkpoint_step',\n",
              "  'all',\n",
              "  'To',\n",
              "  'predict',\n",
              "  'with',\n",
              "  'a',\n",
              "  'specific',\n",
              "  'checkpoint',\n",
              "  'simply',\n",
              "  'set',\n",
              "  'the',\n",
              "  'infer_checkpoint_step',\n",
              "  'parameter',\n",
              "  'to',\n",
              "  'appropriate',\n",
              "  'checkpoint',\n",
              "  '.'],\n",
              " ['gin_param',\n",
              "  'infer_checkpoint_step',\n",
              "  '100000',\n",
              "  'You',\n",
              "  'can',\n",
              "  'also',\n",
              "  'use',\n",
              "  'beam_search.gin',\n",
              "  'or',\n",
              "  'greedy_decode.gin',\n",
              "  'instead',\n",
              "  'of',\n",
              "  'sample_decode.gin',\n",
              "  'in',\n",
              "  'the',\n",
              "  'command',\n",
              "  'above',\n",
              "  '.'],\n",
              " ['Export',\n",
              "  'You',\n",
              "  'may',\n",
              "  'also',\n",
              "  'want',\n",
              "  'to',\n",
              "  'export',\n",
              "  'a',\n",
              "  'SavedModel',\n",
              "  'which',\n",
              "  'is',\n",
              "  'useful',\n",
              "  'for',\n",
              "  'serving',\n",
              "  'your',\n",
              "  'trained',\n",
              "  'model',\n",
              "  'e.g',\n",
              "  '.',\n",
              "  'when',\n",
              "  'deploying',\n",
              "  'with',\n",
              "  'ML',\n",
              "  'Engine',\n",
              "  'or',\n",
              "  'in',\n",
              "  'a',\n",
              "  'Docker',\n",
              "  'image',\n",
              "  '.'],\n",
              " ['t5_mesh_transformer',\n",
              "  'gcp_project',\n",
              "  'PROJECT',\n",
              "  'tpu_zone',\n",
              "  'ZONE',\n",
              "  'model_dir',\n",
              "  'MODEL_DIR',\n",
              "  'use_model_api',\n",
              "  'mode',\n",
              "  'export_predict',\n",
              "  'export_dir',\n",
              "  'path',\n",
              "  'to',\n",
              "  'export',\n",
              "  'dir',\n",
              "  'The',\n",
              "  'command',\n",
              "  'above',\n",
              "  'exports',\n",
              "  'the',\n",
              "  'latest',\n",
              "  'checkpoint',\n",
              "  'in',\n",
              "  'the',\n",
              "  'model',\n",
              "  'directory',\n",
              "  '.'],\n",
              " ['To',\n",
              "  'export',\n",
              "  'a',\n",
              "  'particular',\n",
              "  'checkpoint',\n",
              "  'add',\n",
              "  'the',\n",
              "  'following',\n",
              "  'flags',\n",
              "  'checkpoint_mode',\n",
              "  'specific',\n",
              "  'checkpoint_steps',\n",
              "  '1000000',\n",
              "  'The',\n",
              "  't5',\n",
              "  'deploy',\n",
              "  'notebook',\n",
              "  'demonstrates',\n",
              "  'exporting',\n",
              "  'a',\n",
              "  'SavedModel',\n",
              "  'and',\n",
              "  'packaging',\n",
              "  'it',\n",
              "  'in',\n",
              "  'a',\n",
              "  'Docker',\n",
              "  'image',\n",
              "  'for',\n",
              "  'serving',\n",
              "  '.'],\n",
              " ['GPU',\n",
              "  'Usage',\n",
              "  'If',\n",
              "  'you',\n",
              "  'would',\n",
              "  'like',\n",
              "  'to',\n",
              "  'use',\n",
              "  'GPU',\n",
              "  'instead',\n",
              "  'of',\n",
              "  'TPUs',\n",
              "  'you',\n",
              "  'can',\n",
              "  'modify',\n",
              "  'the',\n",
              "  'above',\n",
              "  'commands',\n",
              "  'by',\n",
              "  'removing',\n",
              "  'TPU',\n",
              "  'specific',\n",
              "  'flags',\n",
              "  'tpu',\n",
              "  'tpu_zone',\n",
              "  'gcp_project',\n",
              "  'and',\n",
              "  'setting',\n",
              "  'the',\n",
              "  'gin',\n",
              "  'params',\n",
              "  'for',\n",
              "  'mesh_shape',\n",
              "  'and',\n",
              "  'mesh_devices',\n",
              "  'based',\n",
              "  'on',\n",
              "  'your',\n",
              "  'desired',\n",
              "  'setup',\n",
              "  '.'],\n",
              " ['For',\n",
              "  'example',\n",
              "  'if',\n",
              "  'your',\n",
              "  'machine',\n",
              "  'has',\n",
              "  'access',\n",
              "  'to',\n",
              "  '6',\n",
              "  'GPUs',\n",
              "  'and',\n",
              "  'you',\n",
              "  'd',\n",
              "  'like',\n",
              "  'to',\n",
              "  'do',\n",
              "  '3',\n",
              "  'way',\n",
              "  'model',\n",
              "  'parallelism',\n",
              "  'and',\n",
              "  '2',\n",
              "  'way',\n",
              "  'data',\n",
              "  'parallelism',\n",
              "  'the',\n",
              "  'fine',\n",
              "  'tuning',\n",
              "  'command',\n",
              "  'above',\n",
              "  'would',\n",
              "  'become',\n",
              "  't5_mesh_transformer',\n",
              "  'model_dir',\n",
              "  'MODEL_DIR',\n",
              "  't5_tfds_data_dir',\n",
              "  'DATA_DIR',\n",
              "  'gin_file',\n",
              "  'dataset.gin',\n",
              "  'gin_param',\n",
              "  'utils.run.mesh_shape',\n",
              "  'model',\n",
              "  '3',\n",
              "  'batch',\n",
              "  '2',\n",
              "  'gin_param',\n",
              "  'utils.run.mesh_devices',\n",
              "  'gpu',\n",
              "  '0',\n",
              "  'gpu',\n",
              "  '1',\n",
              "  'gpu',\n",
              "  '2',\n",
              "  'gpu',\n",
              "  '3',\n",
              "  'gpu',\n",
              "  '4',\n",
              "  'gpu',\n",
              "  '5',\n",
              "  'gin_param',\n",
              "  'MIXTURE_NAME',\n",
              "  'glue_mrpc_v002',\n",
              "  'gin_file',\n",
              "  'gs',\n",
              "  't5',\n",
              "  'data',\n",
              "  'pretrained_models',\n",
              "  'small',\n",
              "  'operative_config.gin',\n",
              "  'With',\n",
              "  'a',\n",
              "  'single',\n",
              "  'GPU',\n",
              "  'the',\n",
              "  'command',\n",
              "  'is',\n",
              "  't5_mesh_transformer',\n",
              "  'model_dir',\n",
              "  'MODEL_DIR',\n",
              "  't5_tfds_data_dir',\n",
              "  'DATA_DIR',\n",
              "  'gin_file',\n",
              "  'dataset.gin',\n",
              "  'gin_param',\n",
              "  'utils.run.mesh_shape',\n",
              "  'model',\n",
              "  '1',\n",
              "  'batch',\n",
              "  '1',\n",
              "  'gin_param',\n",
              "  'utils.run.mesh_devices',\n",
              "  'gpu',\n",
              "  '0',\n",
              "  'gin_param',\n",
              "  'MIXTURE_NAME',\n",
              "  'glue_mrpc_v002',\n",
              "  'gin_file',\n",
              "  'gs',\n",
              "  't5',\n",
              "  'data',\n",
              "  'pretrained_models',\n",
              "  'small',\n",
              "  'operative_config.gin',\n",
              "  'Reproducing',\n",
              "  'our',\n",
              "  'experiments',\n",
              "  'We',\n",
              "  'provide',\n",
              "  'operative',\n",
              "  'configs',\n",
              "  'for',\n",
              "  'all',\n",
              "  'of',\n",
              "  'the',\n",
              "  'experiments',\n",
              "  'in',\n",
              "  'the',\n",
              "  'paper',\n",
              "  'in',\n",
              "  'gs',\n",
              "  't5',\n",
              "  'data',\n",
              "  'experiments',\n",
              "  '.'],\n",
              " ['The',\n",
              "  'experiments',\n",
              "  'folder',\n",
              "  'has',\n",
              "  'different',\n",
              "  'subdirectories',\n",
              "  'corresponding',\n",
              "  'to',\n",
              "  'the',\n",
              "  'different',\n",
              "  'sections',\n",
              "  'in',\n",
              "  'our',\n",
              "  'paper',\n",
              "  '.'],\n",
              " ['For',\n",
              "  'example',\n",
              "  'gs',\n",
              "  't5',\n",
              "  'data',\n",
              "  'experiments',\n",
              "  'objectives',\n",
              "  'contains',\n",
              "  'the',\n",
              "  'experiments',\n",
              "  'from',\n",
              "  'Section',\n",
              "  '3.3',\n",
              "  'Unsupervised',\n",
              "  'objectives',\n",
              "  '.'],\n",
              " ['Each',\n",
              "  'subdirectory',\n",
              "  'of',\n",
              "  'the',\n",
              "  'objectives',\n",
              "  'folder',\n",
              "  'contains',\n",
              "  'operative',\n",
              "  'configs',\n",
              "  'for',\n",
              "  'some',\n",
              "  'particular',\n",
              "  'experiment',\n",
              "  'where',\n",
              "  'loosely',\n",
              "  'speaking',\n",
              "  'an',\n",
              "  'experiment',\n",
              "  'is',\n",
              "  'one',\n",
              "  'of',\n",
              "  'the',\n",
              "  'rows',\n",
              "  'in',\n",
              "  'one',\n",
              "  'of',\n",
              "  'the',\n",
              "  'tables',\n",
              "  'in',\n",
              "  'our',\n",
              "  'paper',\n",
              "  '.'],\n",
              " ['Let',\n",
              "  's',\n",
              "  'say',\n",
              "  'you',\n",
              "  'want',\n",
              "  'to',\n",
              "  'reproduce',\n",
              "  'the',\n",
              "  'results',\n",
              "  'for',\n",
              "  'the',\n",
              "  'Prefix',\n",
              "  'language',\n",
              "  'modeling',\n",
              "  'objective',\n",
              "  'the',\n",
              "  'first',\n",
              "  'row',\n",
              "  'in',\n",
              "  'Table',\n",
              "  '4',\n",
              "  '.'],\n",
              " ['The',\n",
              "  'operative',\n",
              "  'configs',\n",
              "  'for',\n",
              "  'that',\n",
              "  'experiment',\n",
              "  'live',\n",
              "  'in',\n",
              "  'gs',\n",
              "  't5',\n",
              "  'data',\n",
              "  'experiments',\n",
              "  'objectives',\n",
              "  'obj',\n",
              "  'prefix_lm',\n",
              "  '.'],\n",
              " ['In',\n",
              "  'the',\n",
              "  'base',\n",
              "  'directory',\n",
              "  'there',\n",
              "  'is',\n",
              "  'an',\n",
              "  'operative',\n",
              "  'config',\n",
              "  'for',\n",
              "  'pre',\n",
              "  'training',\n",
              "  'the',\n",
              "  'model',\n",
              "  'gs',\n",
              "  't5',\n",
              "  'data',\n",
              "  'experiments',\n",
              "  'objectives',\n",
              "  'obj',\n",
              "  'prefix_lm',\n",
              "  'operative_config.gin',\n",
              "  '.'],\n",
              " ['Then',\n",
              "  'there',\n",
              "  'are',\n",
              "  'subdirectories',\n",
              "  'for',\n",
              "  'each',\n",
              "  'of',\n",
              "  'the',\n",
              "  'downstream',\n",
              "  'fine',\n",
              "  'tuning',\n",
              "  'mixtures',\n",
              "  'we',\n",
              "  'consider',\n",
              "  'each',\n",
              "  'of',\n",
              "  'which',\n",
              "  'has',\n",
              "  'its',\n",
              "  'own',\n",
              "  'operative',\n",
              "  'config',\n",
              "  'for',\n",
              "  'example',\n",
              "  'gs',\n",
              "  't5',\n",
              "  'data',\n",
              "  'experiments',\n",
              "  'objectives',\n",
              "  'obj',\n",
              "  'prefix_lm',\n",
              "  'cnn_dailymail_v002',\n",
              "  'operative_config.gin',\n",
              "  '.'],\n",
              " ['To',\n",
              "  'run',\n",
              "  'this',\n",
              "  'experiment',\n",
              "  'first',\n",
              "  'pre',\n",
              "  'train',\n",
              "  'a',\n",
              "  'model',\n",
              "  'with',\n",
              "  'the',\n",
              "  'pre',\n",
              "  'training',\n",
              "  'operative',\n",
              "  'config',\n",
              "  'export',\n",
              "  'PRETRAIN_MODEL_DIR',\n",
              "  'BUCKET',\n",
              "  'obj',\n",
              "  'prefix_lm',\n",
              "  't5_mesh_transformer',\n",
              "  'tpu',\n",
              "  'TPU_NAME',\n",
              "  'gcp_project',\n",
              "  'PROJECT',\n",
              "  'tpu_zone',\n",
              "  'ZONE',\n",
              "  'model_dir',\n",
              "  'PRETRAIN_MODEL_DIR',\n",
              "  'gin_file',\n",
              "  'gs',\n",
              "  't5',\n",
              "  'data',\n",
              "  'experiments',\n",
              "  'objectives',\n",
              "  'obj',\n",
              "  'prefix_lm',\n",
              "  'operative_config.gin',\n",
              "  'gin_param',\n",
              "  'utils.tpu_mesh_shape.model_parallelism',\n",
              "  '1',\n",
              "  'gin_param',\n",
              "  'utils.tpu_mesh_shape.tpu_topology',\n",
              "  'TPU_SIZE',\n",
              "  'Then',\n",
              "  'you',\n",
              "  'can',\n",
              "  'fine',\n",
              "  'tune',\n",
              "  'the',\n",
              "  'pre',\n",
              "  'trained',\n",
              "  'model',\n",
              "  'on',\n",
              "  'CNN',\n",
              "  'Daily',\n",
              "  'Mail',\n",
              "  'like',\n",
              "  'so',\n",
              "  'export',\n",
              "  'FINETUNE_MODEL_DIR',\n",
              "  'BUCKET',\n",
              "  'obj',\n",
              "  'prefix_lm',\n",
              "  'cnn_dailymail_v002',\n",
              "  't5_mesh_transformer',\n",
              "  'tpu',\n",
              "  'TPU_NAME',\n",
              "  'gcp_project',\n",
              "  'PROJECT',\n",
              "  'tpu_zone',\n",
              "  'ZONE',\n",
              "  'model_dir',\n",
              "  'FINETUNE_MODEL_DIR',\n",
              "  'gin_file',\n",
              "  'gs',\n",
              "  't5',\n",
              "  'data',\n",
              "  'experiments',\n",
              "  'objectives',\n",
              "  'obj',\n",
              "  'prefix_lm',\n",
              "  'cnn_dailymail_v002',\n",
              "  'operative_config.gin',\n",
              "  'gin_param',\n",
              "  'init_checkpoint',\n",
              "  'PRETRAIN_MODEL_DIR',\n",
              "  'model.ckpt',\n",
              "  '524288',\n",
              "  'gin_param',\n",
              "  'utils.tpu_mesh_shape.model_parallelism',\n",
              "  '1',\n",
              "  'gin_param',\n",
              "  'utils.tpu_mesh_shape.tpu_topology',\n",
              "  'TPU_SIZE',\n",
              "  'Useful',\n",
              "  'Options',\n",
              "  'Some',\n",
              "  'training',\n",
              "  'variants',\n",
              "  'need',\n",
              "  'multiple',\n",
              "  'flags',\n",
              "  'to',\n",
              "  'be',\n",
              "  'set',\n",
              "  'at',\n",
              "  'the',\n",
              "  'same',\n",
              "  'time',\n",
              "  '.'],\n",
              " ['For',\n",
              "  'each',\n",
              "  'of',\n",
              "  'the',\n",
              "  'below',\n",
              "  'variants',\n",
              "  'add',\n",
              "  'the',\n",
              "  'group',\n",
              "  'of',\n",
              "  'flags',\n",
              "  'to',\n",
              "  '.',\n",
              "  'third_party',\n",
              "  'py',\n",
              "  't5',\n",
              "  'google',\n",
              "  'scripts',\n",
              "  'run_finetune.sh',\n",
              "  '.'],\n",
              " ['Deterministic',\n",
              "  'training',\n",
              "  'train_gin_param',\n",
              "  'mesh_train_dataset_fn.seed',\n",
              "  'SEED',\n",
              "  'train_gin_param',\n",
              "  'utils.run.skip_seen_data',\n",
              "  'True',\n",
              "  'Language',\n",
              "  'model',\n",
              "  'objective',\n",
              "  'lm',\n",
              "  'train_gin_param',\n",
              "  'utils.run.model_type',\n",
              "  'lm',\n",
              "  'Released',\n",
              "  'Model',\n",
              "  'Checkpoints',\n",
              "  'We',\n",
              "  'have',\n",
              "  'released',\n",
              "  'the',\n",
              "  'following',\n",
              "  'checkpoints',\n",
              "  'for',\n",
              "  'pre',\n",
              "  'trained',\n",
              "  'models',\n",
              "  'described',\n",
              "  'in',\n",
              "  'our',\n",
              "  'paper',\n",
              "  'T5',\n",
              "  'Small',\n",
              "  '60',\n",
              "  'million',\n",
              "  'parameters',\n",
              "  'gs',\n",
              "  't5',\n",
              "  'data',\n",
              "  'pretrained_models',\n",
              "  'small',\n",
              "  'T5',\n",
              "  'Base',\n",
              "  '220',\n",
              "  'million',\n",
              "  'parameters',\n",
              "  'gs',\n",
              "  't5',\n",
              "  'data',\n",
              "  'pretrained_models',\n",
              "  'base',\n",
              "  'T5',\n",
              "  'Large',\n",
              "  '770',\n",
              "  'million',\n",
              "  'parameters',\n",
              "  'gs',\n",
              "  't5',\n",
              "  'data',\n",
              "  'pretrained_models',\n",
              "  'large',\n",
              "  'T5',\n",
              "  '3B',\n",
              "  '3',\n",
              "  'billion',\n",
              "  'parameters',\n",
              "  'gs',\n",
              "  't5',\n",
              "  'data',\n",
              "  'pretrained_models',\n",
              "  '3B',\n",
              "  'T5',\n",
              "  '11B',\n",
              "  '11',\n",
              "  'billion',\n",
              "  'parameters',\n",
              "  'gs',\n",
              "  't5',\n",
              "  'data',\n",
              "  'pretrained_models',\n",
              "  '11B',\n",
              "  'See',\n",
              "  'here',\n",
              "  'for',\n",
              "  'a',\n",
              "  'list',\n",
              "  'of',\n",
              "  'additional',\n",
              "  'experimental',\n",
              "  'pre',\n",
              "  'trained',\n",
              "  'model',\n",
              "  'checkpoints',\n",
              "  '.'],\n",
              " ['How',\n",
              "  'to',\n",
              "  'Cite',\n",
              "  'If',\n",
              "  'you',\n",
              "  'extend',\n",
              "  'or',\n",
              "  'use',\n",
              "  'this',\n",
              "  'work',\n",
              "  'please',\n",
              "  'cite',\n",
              "  'the',\n",
              "  'paper',\n",
              "  'where',\n",
              "  'it',\n",
              "  'was',\n",
              "  'introduced',\n",
              "  '@',\n",
              "  'article',\n",
              "  '2020t5',\n",
              "  'author',\n",
              "  'Colin',\n",
              "  'Raffel',\n",
              "  'and',\n",
              "  'Noam',\n",
              "  'Shazeer',\n",
              "  'and',\n",
              "  'Adam',\n",
              "  'Roberts',\n",
              "  'and',\n",
              "  'Katherine',\n",
              "  'Lee',\n",
              "  'and',\n",
              "  'Sharan',\n",
              "  'Narang',\n",
              "  'and',\n",
              "  'Michael',\n",
              "  'Matena',\n",
              "  'and',\n",
              "  'Yanqi',\n",
              "  'Zhou',\n",
              "  'and',\n",
              "  'Wei',\n",
              "  'Li',\n",
              "  'and',\n",
              "  'Peter',\n",
              "  'J.',\n",
              "  'Liu',\n",
              "  'title',\n",
              "  'Exploring',\n",
              "  'the',\n",
              "  'Limits',\n",
              "  'of',\n",
              "  'Transfer',\n",
              "  'Learning',\n",
              "  'with',\n",
              "  'a',\n",
              "  'Unified',\n",
              "  'Text',\n",
              "  'to',\n",
              "  'Text',\n",
              "  'Transformer',\n",
              "  'journal',\n",
              "  'Journal',\n",
              "  'of',\n",
              "  'Machine',\n",
              "  'Learning',\n",
              "  'Research',\n",
              "  'year',\n",
              "  '2020',\n",
              "  'volume',\n",
              "  '21',\n",
              "  'number',\n",
              "  '140',\n",
              "  'pages',\n",
              "  '1',\n",
              "  '67',\n",
              "  'url',\n",
              "  'http',\n",
              "  'jmlr.org',\n",
              "  'papers',\n",
              "  'v21',\n",
              "  '20',\n",
              "  '074.html']]"
            ]
          },
          "execution_count": 205,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tokenized_sent = [nt.word_tokenize(s) for s in sent]\n",
        "tokenized_sent"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Daur2p_hvEwT",
        "outputId": "77a5143f-c967-4b63-8e10-dc13066910bd"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[[('T5', 'NNP'),\n",
              "  ('Text', 'NNP'),\n",
              "  ('To', 'TO'),\n",
              "  ('Text', 'NNP'),\n",
              "  ('Transfer', 'NNP'),\n",
              "  ('Transformer', 'NNP'),\n",
              "  ('As', 'IN'),\n",
              "  ('of', 'IN'),\n",
              "  ('July', 'NNP'),\n",
              "  ('2022', 'CD'),\n",
              "  ('we', 'PRP'),\n",
              "  ('recommend', 'VBP'),\n",
              "  ('using', 'VBG'),\n",
              "  ('T5X', 'NNP'),\n",
              "  ('T5X', 'NNP'),\n",
              "  ('is', 'VBZ'),\n",
              "  ('the', 'DT'),\n",
              "  ('new', 'JJ'),\n",
              "  ('and', 'CC'),\n",
              "  ('improved', 'JJ'),\n",
              "  ('implementation', 'NN'),\n",
              "  ('of', 'IN'),\n",
              "  ('T5', 'NNP'),\n",
              "  ('and', 'CC'),\n",
              "  ('more', 'RBR'),\n",
              "  ('in', 'IN'),\n",
              "  ('JAX', 'NNP'),\n",
              "  ('and', 'CC'),\n",
              "  ('Flax', 'NNP'),\n",
              "  ('.', '.')],\n",
              " [('T5', 'NN'),\n",
              "  ('on', 'IN'),\n",
              "  ('Tensorflow', 'NNP'),\n",
              "  ('with', 'IN'),\n",
              "  ('MeshTF', 'NNP'),\n",
              "  ('is', 'VBZ'),\n",
              "  ('no', 'RB'),\n",
              "  ('longer', 'RBR'),\n",
              "  ('actively', 'RB'),\n",
              "  ('developed', 'VBN'),\n",
              "  ('.', '.')],\n",
              " [('If', 'IN'),\n",
              "  ('you', 'PRP'),\n",
              "  ('are', 'VBP'),\n",
              "  ('new', 'JJ'),\n",
              "  ('to', 'TO'),\n",
              "  ('T5', 'NNP'),\n",
              "  ('we', 'PRP'),\n",
              "  ('recommend', 'VBP'),\n",
              "  ('starting', 'VBG'),\n",
              "  ('with', 'IN'),\n",
              "  ('T5X', 'NNP'),\n",
              "  ('.', '.')],\n",
              " [('The', 'DT'),\n",
              "  ('t5', 'NN'),\n",
              "  ('library', 'JJ'),\n",
              "  ('serves', 'NNS'),\n",
              "  ('primarily', 'RB'),\n",
              "  ('as', 'IN'),\n",
              "  ('code', 'NN'),\n",
              "  ('for', 'IN'),\n",
              "  ('reproducing', 'VBG'),\n",
              "  ('the', 'DT'),\n",
              "  ('experiments', 'NNS'),\n",
              "  ('in', 'IN'),\n",
              "  ('Exploring', 'VBG'),\n",
              "  ('the', 'DT'),\n",
              "  ('Limits', 'NNS'),\n",
              "  ('of', 'IN'),\n",
              "  ('Transfer', 'NNP'),\n",
              "  ('Learning', 'NNP'),\n",
              "  ('with', 'IN'),\n",
              "  ('a', 'DT'),\n",
              "  ('Unified', 'NNP'),\n",
              "  ('Text', 'NNP'),\n",
              "  ('to', 'TO'),\n",
              "  ('Text', 'VB'),\n",
              "  ('Transformer', 'NNP'),\n",
              "  ('.', '.')],\n",
              " [('In', 'IN'),\n",
              "  ('the', 'DT'),\n",
              "  ('paper', 'NN'),\n",
              "  ('we', 'PRP'),\n",
              "  ('demonstrate', 'VBP'),\n",
              "  ('how', 'WRB'),\n",
              "  ('to', 'TO'),\n",
              "  ('achieve', 'VB'),\n",
              "  ('state', 'NN'),\n",
              "  ('of', 'IN'),\n",
              "  ('the', 'DT'),\n",
              "  ('art', 'NN'),\n",
              "  ('results', 'NNS'),\n",
              "  ('on', 'IN'),\n",
              "  ('multiple', 'JJ'),\n",
              "  ('NLP', 'NNP'),\n",
              "  ('tasks', 'NNS'),\n",
              "  ('using', 'VBG'),\n",
              "  ('a', 'DT'),\n",
              "  ('text', 'NN'),\n",
              "  ('to', 'TO'),\n",
              "  ('text', 'VB'),\n",
              "  ('transformer', 'JJ'),\n",
              "  ('pre', 'NN'),\n",
              "  ('trained', 'VBN'),\n",
              "  ('on', 'IN'),\n",
              "  ('a', 'DT'),\n",
              "  ('large', 'JJ'),\n",
              "  ('text', 'NN'),\n",
              "  ('corpus', 'NN'),\n",
              "  ('.', '.')],\n",
              " [('The', 'DT'),\n",
              "  ('bulk', 'NN'),\n",
              "  ('of', 'IN'),\n",
              "  ('the', 'DT'),\n",
              "  ('code', 'NN'),\n",
              "  ('in', 'IN'),\n",
              "  ('this', 'DT'),\n",
              "  ('repository', 'NN'),\n",
              "  ('is', 'VBZ'),\n",
              "  ('used', 'VBN'),\n",
              "  ('for', 'IN'),\n",
              "  ('loading', 'VBG'),\n",
              "  ('preprocessing', 'VBG'),\n",
              "  ('mixing', 'NN'),\n",
              "  ('and', 'CC'),\n",
              "  ('evaluating', 'VBG'),\n",
              "  ('datasets', 'NNS'),\n",
              "  ('.', '.')],\n",
              " [('It', 'PRP'),\n",
              "  ('also', 'RB'),\n",
              "  ('provides', 'VBZ'),\n",
              "  ('a', 'DT'),\n",
              "  ('way', 'NN'),\n",
              "  ('to', 'TO'),\n",
              "  ('fine', 'VB'),\n",
              "  ('tune', 'IN'),\n",
              "  ('the', 'DT'),\n",
              "  ('pre', 'NN'),\n",
              "  ('trained', 'VBD'),\n",
              "  ('models', 'NNS'),\n",
              "  ('released', 'VBN'),\n",
              "  ('alongside', 'IN'),\n",
              "  ('the', 'DT'),\n",
              "  ('publication', 'NN'),\n",
              "  ('.', '.')],\n",
              " [('The', 'DT'),\n",
              "  ('t5', 'JJ'),\n",
              "  ('library', 'NN'),\n",
              "  ('can', 'MD'),\n",
              "  ('be', 'VB'),\n",
              "  ('used', 'VBN'),\n",
              "  ('for', 'IN'),\n",
              "  ('future', 'JJ'),\n",
              "  ('model', 'NN'),\n",
              "  ('development', 'NN'),\n",
              "  ('by', 'IN'),\n",
              "  ('providing', 'VBG'),\n",
              "  ('useful', 'JJ'),\n",
              "  ('modules', 'NNS'),\n",
              "  ('for', 'IN'),\n",
              "  ('training', 'NN'),\n",
              "  ('and', 'CC'),\n",
              "  ('fine', 'JJ'),\n",
              "  ('tuning', 'VBG'),\n",
              "  ('potentially', 'RB'),\n",
              "  ('huge', 'JJ'),\n",
              "  ('models', 'NNS'),\n",
              "  ('on', 'IN'),\n",
              "  ('mixtures', 'NNS'),\n",
              "  ('of', 'IN'),\n",
              "  ('text', 'NN'),\n",
              "  ('to', 'TO'),\n",
              "  ('text', 'VB'),\n",
              "  ('tasks', 'NNS'),\n",
              "  ('.', '.')],\n",
              " [('Table', 'NN'),\n",
              "  ('of', 'IN'),\n",
              "  ('Contents', 'NNP'),\n",
              "  ('Library', 'NNP'),\n",
              "  ('Usage', 'NNP'),\n",
              "  ('Dataset', 'NNP'),\n",
              "  ('Preparation', 'NNP'),\n",
              "  ('C4', 'NNP'),\n",
              "  ('Installation', 'NNP'),\n",
              "  ('Setting', 'NNP'),\n",
              "  ('up', 'RP'),\n",
              "  ('TPUs', 'NNP'),\n",
              "  ('on', 'IN'),\n",
              "  ('GCP', 'NNP'),\n",
              "  ('Training', 'NNP'),\n",
              "  ('Fine', 'NNP'),\n",
              "  ('Tuning', 'NNP'),\n",
              "  ('Eval', 'NNP'),\n",
              "  ('Decode', 'NNP'),\n",
              "  ('Export', 'NNP'),\n",
              "  ('GPU', 'NNP'),\n",
              "  ('Usage', 'NNP'),\n",
              "  ('Reproducing', 'NNP'),\n",
              "  ('our', 'PRP$'),\n",
              "  ('experiments', 'NNS'),\n",
              "  ('Useful', 'JJ'),\n",
              "  ('Options', 'NNS'),\n",
              "  ('Released', 'VBN'),\n",
              "  ('Model', 'NNP'),\n",
              "  ('Checkpoints', 'NNP'),\n",
              "  ('How', 'NNP'),\n",
              "  ('to', 'TO'),\n",
              "  ('Cite', 'NNP'),\n",
              "  ('Library', 'NNP'),\n",
              "  ('t5.data', 'NN'),\n",
              "  ('t5.data', 'NN'),\n",
              "  ('is', 'VBZ'),\n",
              "  ('a', 'DT'),\n",
              "  ('package', 'NN'),\n",
              "  ('for', 'IN'),\n",
              "  ('defining', 'VBG'),\n",
              "  ('Task', 'NNP'),\n",
              "  ('objects', 'NNS'),\n",
              "  ('that', 'WDT'),\n",
              "  ('provide', 'VBP'),\n",
              "  ('tf.data.Datasets', 'NNS'),\n",
              "  ('.', '.')],\n",
              " [('Each', 'DT'),\n",
              "  ('Task', 'NN'),\n",
              "  ('is', 'VBZ'),\n",
              "  ('made', 'VBN'),\n",
              "  ('up', 'IN'),\n",
              "  ('of', 'IN'),\n",
              "  ('a', 'DT'),\n",
              "  ('data', 'NN'),\n",
              "  ('source', 'NN'),\n",
              "  ('text', 'NN'),\n",
              "  ('preprocessor', 'NN'),\n",
              "  ('function', 'NN'),\n",
              "  ('s', 'VBD'),\n",
              "  ('a', 'DT'),\n",
              "  ('SentencePiece', 'NNP'),\n",
              "  ('model', 'NN'),\n",
              "  ('metric', 'JJ'),\n",
              "  ('function', 'NN'),\n",
              "  ('s', 'NN'),\n",
              "  ('Additionally', 'NNP'),\n",
              "  ('you', 'PRP'),\n",
              "  ('may', 'MD'),\n",
              "  ('optionally', 'RB'),\n",
              "  ('provide', 'VB'),\n",
              "  ('token', 'NN'),\n",
              "  ('preprocessor', 'NN'),\n",
              "  ('function', 'NN'),\n",
              "  ('s', 'NN'),\n",
              "  ('postprocess', 'NN'),\n",
              "  ('function', 'NN'),\n",
              "  ('s', 'VBD'),\n",
              "  ('The', 'DT'),\n",
              "  ('data', 'NNS'),\n",
              "  ('source', 'NN'),\n",
              "  ('can', 'MD'),\n",
              "  ('be', 'VB'),\n",
              "  ('an', 'DT'),\n",
              "  ('arbitrary', 'JJ'),\n",
              "  ('function', 'NN'),\n",
              "  ('that', 'WDT'),\n",
              "  ('provides', 'VBZ'),\n",
              "  ('a', 'DT'),\n",
              "  ('tf.data.Dataset', 'NN'),\n",
              "  ('but', 'CC'),\n",
              "  ('we', 'PRP'),\n",
              "  ('also', 'RB'),\n",
              "  ('provide', 'VBP'),\n",
              "  ('simpler', 'JJR'),\n",
              "  ('wrappers', 'NNS'),\n",
              "  ('for', 'IN'),\n",
              "  ('datasets', 'NNS'),\n",
              "  ('available', 'JJ'),\n",
              "  ('in', 'IN'),\n",
              "  ('TensorFlow', 'NNP'),\n",
              "  ('Datasets', 'NNP'),\n",
              "  ('TFDS', 'NNP'),\n",
              "  ('a', 'DT'),\n",
              "  ('TfdsTask', 'NNP'),\n",
              "  ('or', 'CC'),\n",
              "  ('stored', 'VBN'),\n",
              "  ('as', 'IN'),\n",
              "  ('text', 'JJ'),\n",
              "  ('files', 'NNS'),\n",
              "  ('with', 'IN'),\n",
              "  ('one', 'CD'),\n",
              "  ('example', 'NN'),\n",
              "  ('per', 'IN'),\n",
              "  ('line', 'NN'),\n",
              "  ('a', 'DT'),\n",
              "  ('TextLineTask', 'NNP'),\n",
              "  ('.', '.')],\n",
              " [('The', 'DT'),\n",
              "  ('text', 'NN'),\n",
              "  ('preprocessor', 'NN'),\n",
              "  ('converts', 'VBZ'),\n",
              "  ('the', 'DT'),\n",
              "  ('examples', 'NNS'),\n",
              "  ('in', 'IN'),\n",
              "  ('the', 'DT'),\n",
              "  ('source', 'NN'),\n",
              "  ('dataset', 'NN'),\n",
              "  ('into', 'IN'),\n",
              "  ('the', 'DT'),\n",
              "  ('appropriate', 'JJ'),\n",
              "  ('format', 'NN'),\n",
              "  ('for', 'IN'),\n",
              "  ('a', 'DT'),\n",
              "  ('text', 'NN'),\n",
              "  ('to', 'TO'),\n",
              "  ('text', 'VB'),\n",
              "  ('model', 'NN'),\n",
              "  ('with', 'IN'),\n",
              "  ('fields', 'NNS'),\n",
              "  ('for', 'IN'),\n",
              "  ('inputs', 'NNS'),\n",
              "  ('and', 'CC'),\n",
              "  ('targets', 'NNS'),\n",
              "  ('.', '.')],\n",
              " [('For', 'IN'),\n",
              "  ('example', 'NN'),\n",
              "  ('the', 'DT'),\n",
              "  ('predefined', 'JJ'),\n",
              "  ('t5.data.preprocessors.translate', 'NN'),\n",
              "  ('preprocessor', 'NN'),\n",
              "  ('converts', 'NNS'),\n",
              "  ('inputs', 'NNS'),\n",
              "  ('in', 'IN'),\n",
              "  ('the', 'DT'),\n",
              "  ('form', 'NN'),\n",
              "  ('de', 'IN'),\n",
              "  ('Das', 'NNP'),\n",
              "  ('ist', 'NN'),\n",
              "  ('gut', 'NN'),\n",
              "  ('.', '.')],\n",
              " [('en', 'NN'), ('That', 'WDT'), ('is', 'VBZ'), ('good', 'JJ'), ('.', '.')],\n",
              " [('to', 'TO'),\n",
              "  ('the', 'DT'),\n",
              "  ('form', 'NN'),\n",
              "  ('inputs', 'VBZ'),\n",
              "  ('translate', 'JJ'),\n",
              "  ('German', 'NNP'),\n",
              "  ('to', 'TO'),\n",
              "  ('English', 'VB'),\n",
              "  ('Das', 'NNP'),\n",
              "  ('ist', 'JJ'),\n",
              "  ('gut', 'NN'),\n",
              "  ('.', '.')],\n",
              " [('targets', 'NNS'),\n",
              "  ('That', 'WDT'),\n",
              "  ('is', 'VBZ'),\n",
              "  ('good', 'JJ'),\n",
              "  ('.', '.')],\n",
              " [('In', 'IN'),\n",
              "  ('addition', 'NN'),\n",
              "  ('to', 'TO'),\n",
              "  ('text', 'VB'),\n",
              "  ('preprocessing', 'VBG'),\n",
              "  ('you', 'PRP'),\n",
              "  ('can', 'MD'),\n",
              "  ('also', 'RB'),\n",
              "  ('use', 'VB'),\n",
              "  ('one', 'CD'),\n",
              "  ('or', 'CC'),\n",
              "  ('more', 'JJR'),\n",
              "  ('token', 'JJ'),\n",
              "  ('preprocessors', 'NNS'),\n",
              "  ('to', 'TO'),\n",
              "  ('modify', 'VB'),\n",
              "  ('the', 'DT'),\n",
              "  ('inputs', 'NNS'),\n",
              "  ('post', 'NN'),\n",
              "  ('tokenization', 'NN'),\n",
              "  ('.', '.')],\n",
              " [('We', 'PRP'),\n",
              "  ('implemented', 'VBD'),\n",
              "  ('our', 'PRP$'),\n",
              "  ('unsupervised', 'JJ'),\n",
              "  ('pre', 'NN'),\n",
              "  ('training', 'NN'),\n",
              "  ('objectives', 'NNS'),\n",
              "  ('using', 'VBG'),\n",
              "  ('these', 'DT'),\n",
              "  ('token', 'JJ'),\n",
              "  ('preprocessors', 'NNS'),\n",
              "  ('.', '.')],\n",
              " [('We', 'PRP'),\n",
              "  ('provide', 'VBP'),\n",
              "  ('many', 'JJ'),\n",
              "  ('predefined', 'JJ'),\n",
              "  ('preprocessors', 'NNS'),\n",
              "  ('in', 'IN'),\n",
              "  ('t5.data.preprocessors', 'NNS'),\n",
              "  ('but', 'CC'),\n",
              "  ('you', 'PRP'),\n",
              "  ('may', 'MD'),\n",
              "  ('also', 'RB'),\n",
              "  ('define', 'VB'),\n",
              "  ('your', 'PRP$'),\n",
              "  ('own', 'JJ'),\n",
              "  ('.', '.')],\n",
              " [('The', 'DT'),\n",
              "  ('SentencePiece', 'NNP'),\n",
              "  ('model', 'NN'),\n",
              "  ('is', 'VBZ'),\n",
              "  ('used', 'VBN'),\n",
              "  ('to', 'TO'),\n",
              "  ('tokenize', 'VB'),\n",
              "  ('the', 'DT'),\n",
              "  ('input', 'NN'),\n",
              "  ('strings', 'NNS'),\n",
              "  ('and', 'CC'),\n",
              "  ('decode', 'VB'),\n",
              "  ('the', 'DT'),\n",
              "  ('output', 'NN'),\n",
              "  ('tokens', 'NNS'),\n",
              "  ('.', '.')],\n",
              " [('You', 'PRP'),\n",
              "  ('can', 'MD'),\n",
              "  ('create', 'VB'),\n",
              "  ('your', 'PRP$'),\n",
              "  ('own', 'JJ'),\n",
              "  ('model', 'NN'),\n",
              "  ('with', 'IN'),\n",
              "  ('the', 'DT'),\n",
              "  ('google', 'NN'),\n",
              "  ('sentencepiece', 'NN'),\n",
              "  ('library', 'NN'),\n",
              "  ('or', 'CC'),\n",
              "  ('use', 'VB'),\n",
              "  ('our', 'PRP$'),\n",
              "  ('default', 'NN'),\n",
              "  ('one', 'CD'),\n",
              "  ('at', 'IN'),\n",
              "  ('t5.data.DEFAULT_SPM_PATH', 'NN'),\n",
              "  ('.', '.')],\n",
              " [('If', 'IN'),\n",
              "  ('you', 'PRP'),\n",
              "  ('create', 'VBP'),\n",
              "  ('your', 'PRP$'),\n",
              "  ('own', 'JJ'),\n",
              "  ('you', 'PRP'),\n",
              "  ('must', 'MD'),\n",
              "  ('use', 'VB'),\n",
              "  ('the', 'DT'),\n",
              "  ('flags', 'NNS'),\n",
              "  ('pad_id', 'VBP'),\n",
              "  ('0', 'CD'),\n",
              "  ('eos_id', 'JJ'),\n",
              "  ('1', 'CD'),\n",
              "  ('unk_id', 'JJ'),\n",
              "  ('2', 'CD'),\n",
              "  ('bos_id', 'NN'),\n",
              "  ('1', 'CD'),\n",
              "  ('with', 'IN'),\n",
              "  ('spm_train', 'NN'),\n",
              "  ('to', 'TO'),\n",
              "  ('be', 'VB'),\n",
              "  ('compatible', 'JJ'),\n",
              "  ('with', 'IN'),\n",
              "  ('our', 'PRP$'),\n",
              "  ('model', 'NN'),\n",
              "  ('code', 'NN'),\n",
              "  ('.', '.')],\n",
              " [('The', 'DT'),\n",
              "  ('metric', 'JJ'),\n",
              "  ('function', 'NN'),\n",
              "  ('returns', 'VBZ'),\n",
              "  ('a', 'DT'),\n",
              "  ('score', 'NN'),\n",
              "  ('given', 'VBN'),\n",
              "  ('the', 'DT'),\n",
              "  ('target', 'NN'),\n",
              "  ('and', 'CC'),\n",
              "  ('prediction', 'NN'),\n",
              "  ('from', 'IN'),\n",
              "  ('the', 'DT'),\n",
              "  ('model', 'NN'),\n",
              "  ('.', '.')],\n",
              " [('You', 'PRP'),\n",
              "  ('may', 'MD'),\n",
              "  ('also', 'RB'),\n",
              "  ('define', 'VB'),\n",
              "  ('a', 'DT'),\n",
              "  ('postprocess', 'NN'),\n",
              "  ('function', 'NN'),\n",
              "  ('to', 'TO'),\n",
              "  ('convert', 'VB'),\n",
              "  ('the', 'DT'),\n",
              "  ('target', 'NN'),\n",
              "  ('and', 'CC'),\n",
              "  ('prediction', 'NN'),\n",
              "  ('text', 'NN'),\n",
              "  ('to', 'TO'),\n",
              "  ('another', 'DT'),\n",
              "  ('format', 'NN'),\n",
              "  ('before', 'IN'),\n",
              "  ('calling', 'VBG'),\n",
              "  ('the', 'DT'),\n",
              "  ('metric', 'JJ'),\n",
              "  ('.', '.')],\n",
              " [('We', 'PRP'),\n",
              "  ('provide', 'VBP'),\n",
              "  ('some', 'DT'),\n",
              "  ('predefined', 'JJ'),\n",
              "  ('metrics', 'NNS'),\n",
              "  ('in', 'IN'),\n",
              "  ('t5.evaluation.metrics', 'NNS'),\n",
              "  ('.', '.')],\n",
              " [('Finally', 'RB'),\n",
              "  ('t5.data', 'JJ'),\n",
              "  ('contains', 'VBZ'),\n",
              "  ('a', 'DT'),\n",
              "  ('Mixture', 'NN'),\n",
              "  ('class', 'NN'),\n",
              "  ('that', 'WDT'),\n",
              "  ('can', 'MD'),\n",
              "  ('be', 'VB'),\n",
              "  ('instantiated', 'VBN'),\n",
              "  ('to', 'TO'),\n",
              "  ('combine', 'VB'),\n",
              "  ('multiple', 'JJ'),\n",
              "  ('Task', 'NNP'),\n",
              "  ('datasets', 'NNS'),\n",
              "  ('for', 'IN'),\n",
              "  ('multi', 'NN'),\n",
              "  ('task', 'NN'),\n",
              "  ('training', 'VBG'),\n",
              "  ('using', 'VBG'),\n",
              "  ('various', 'JJ'),\n",
              "  ('functions', 'NNS'),\n",
              "  ('for', 'IN'),\n",
              "  ('specifying', 'VBG'),\n",
              "  ('the', 'DT'),\n",
              "  ('mixture', 'NN'),\n",
              "  ('rates', 'NNS'),\n",
              "  ('.', '.')],\n",
              " [('t5.evaluation', 'NN'),\n",
              "  ('t5.evaluation', 'NN'),\n",
              "  ('contains', 'VBZ'),\n",
              "  ('two', 'CD'),\n",
              "  ('core', 'NN'),\n",
              "  ('components', 'NNS'),\n",
              "  ('metrics', 'NNS'),\n",
              "  ('to', 'TO'),\n",
              "  ('be', 'VB'),\n",
              "  ('used', 'VBN'),\n",
              "  ('during', 'IN'),\n",
              "  ('evaluation', 'NN'),\n",
              "  ('utilities', 'NNS'),\n",
              "  ('for', 'IN'),\n",
              "  ('applying', 'VBG'),\n",
              "  ('these', 'DT'),\n",
              "  ('metrics', 'NNS'),\n",
              "  ('at', 'IN'),\n",
              "  ('evaluation', 'NN'),\n",
              "  ('time', 'NN'),\n",
              "  ('t5.models', 'NNS'),\n",
              "  ('t5.models', 'NNS'),\n",
              "  ('contains', 'NNS'),\n",
              "  ('shims', 'NNS'),\n",
              "  ('for', 'IN'),\n",
              "  ('connecting', 'VBG'),\n",
              "  ('T5', 'NNP'),\n",
              "  ('Tasks', 'NNP'),\n",
              "  ('and', 'CC'),\n",
              "  ('Mixtures', 'NNP'),\n",
              "  ('to', 'TO'),\n",
              "  ('a', 'DT'),\n",
              "  ('model', 'NN'),\n",
              "  ('implementation', 'NN'),\n",
              "  ('for', 'IN'),\n",
              "  ('training', 'VBG'),\n",
              "  ('evaluation', 'NN'),\n",
              "  ('and', 'CC'),\n",
              "  ('inference', 'NN'),\n",
              "  ('.', '.')],\n",
              " [('Currently', 'RB'),\n",
              "  ('there', 'EX'),\n",
              "  ('are', 'VBP'),\n",
              "  ('two', 'CD'),\n",
              "  ('shims', 'NNS'),\n",
              "  ('available', 'JJ'),\n",
              "  ('One', 'CD'),\n",
              "  ('for', 'IN'),\n",
              "  ('the', 'DT'),\n",
              "  ('Mesh', 'NNP'),\n",
              "  ('TensorFlow', 'NNP'),\n",
              "  ('Transformer', 'NNP'),\n",
              "  ('that', 'IN'),\n",
              "  ('we', 'PRP'),\n",
              "  ('used', 'VBD'),\n",
              "  ('in', 'IN'),\n",
              "  ('our', 'PRP$'),\n",
              "  ('paper', 'NN'),\n",
              "  ('and', 'CC'),\n",
              "  ('another', 'DT'),\n",
              "  ('for', 'IN'),\n",
              "  ('the', 'DT'),\n",
              "  ('Hugging', 'NNP'),\n",
              "  ('Face', 'NNP'),\n",
              "  ('Transformers', 'NNP'),\n",
              "  ('library', 'NN'),\n",
              "  ('.', '.')],\n",
              " [('The', 'DT'),\n",
              "  ('Hugging', 'NNP'),\n",
              "  ('Face', 'NNP'),\n",
              "  ('API', 'NNP'),\n",
              "  ('is', 'VBZ'),\n",
              "  ('currently', 'RB'),\n",
              "  ('experimental', 'JJ'),\n",
              "  ('and', 'CC'),\n",
              "  ('subject', 'JJ'),\n",
              "  ('to', 'TO'),\n",
              "  ('change', 'VB'),\n",
              "  ('but', 'CC'),\n",
              "  ('provides', 'VBZ'),\n",
              "  ('a', 'DT'),\n",
              "  ('simple', 'JJ'),\n",
              "  ('and', 'CC'),\n",
              "  ('easy', 'JJ'),\n",
              "  ('way', 'NN'),\n",
              "  ('to', 'TO'),\n",
              "  ('load', 'VB'),\n",
              "  ('fine', 'JJ'),\n",
              "  ('tune', 'NN'),\n",
              "  ('and', 'CC'),\n",
              "  ('evaluate', 'VB'),\n",
              "  ('our', 'PRP$'),\n",
              "  ('pre', 'NN'),\n",
              "  ('trained', 'VBN'),\n",
              "  ('models', 'NNS'),\n",
              "  ('using', 'VBG'),\n",
              "  ('PyTorch', 'NNP'),\n",
              "  ('on', 'IN'),\n",
              "  ('a', 'DT'),\n",
              "  ('single', 'JJ'),\n",
              "  ('GPU', 'NNP'),\n",
              "  ('.', '.')],\n",
              " [('If', 'IN'),\n",
              "  ('you', 'PRP'),\n",
              "  ('want', 'VBP'),\n",
              "  ('to', 'TO'),\n",
              "  ('use', 'VB'),\n",
              "  ('our', 'PRP$'),\n",
              "  ('largest', 'JJS'),\n",
              "  ('models', 'NNS'),\n",
              "  ('on', 'IN'),\n",
              "  ('TPUs', 'NNP'),\n",
              "  ('and', 'CC'),\n",
              "  ('or', 'CC'),\n",
              "  ('reproduce', 'VB'),\n",
              "  ('the', 'DT'),\n",
              "  ('results', 'NNS'),\n",
              "  ('in', 'IN'),\n",
              "  ('our', 'PRP$'),\n",
              "  ('paper', 'NN'),\n",
              "  ('you', 'PRP'),\n",
              "  ('should', 'MD'),\n",
              "  ('use', 'VB'),\n",
              "  ('the', 'DT'),\n",
              "  ('MtfModel', 'NNP'),\n",
              "  ('API', 'NNP'),\n",
              "  ('and', 'CC'),\n",
              "  ('the', 'DT'),\n",
              "  ('t5_mesh_transformer', 'NN'),\n",
              "  ('binary', 'NN'),\n",
              "  ('.', '.')],\n",
              " [('If', 'IN'),\n",
              "  ('you', 'PRP'),\n",
              "  ('are', 'VBP'),\n",
              "  ('interested', 'JJ'),\n",
              "  ('fine', 'JJ'),\n",
              "  ('tuning', 'VBG'),\n",
              "  ('our', 'PRP$'),\n",
              "  ('models', 'NNS'),\n",
              "  ('on', 'IN'),\n",
              "  ('a', 'DT'),\n",
              "  ('GPU', 'NNP'),\n",
              "  ('in', 'IN'),\n",
              "  ('PyTorch', 'NNP'),\n",
              "  ('you', 'PRP'),\n",
              "  ('should', 'MD'),\n",
              "  ('try', 'VB'),\n",
              "  ('the', 'DT'),\n",
              "  ('HfPyTorchModel', 'NNP'),\n",
              "  ('API', 'NNP'),\n",
              "  ('.', '.')],\n",
              " [('Since', 'IN'),\n",
              "  ('the', 'DT'),\n",
              "  ('HfPyTorchModel', 'NNP'),\n",
              "  ('is', 'VBZ'),\n",
              "  ('experimental', 'JJ'),\n",
              "  ('the', 'DT'),\n",
              "  ('remainder', 'NN'),\n",
              "  ('of', 'IN'),\n",
              "  ('this', 'DT'),\n",
              "  ('README', 'NNP'),\n",
              "  ('assumes', 'VBZ'),\n",
              "  ('usage', 'NN'),\n",
              "  ('of', 'IN'),\n",
              "  ('the', 'DT'),\n",
              "  ('MtfModel', 'NNP'),\n",
              "  ('and', 'CC'),\n",
              "  ('its', 'PRP$'),\n",
              "  ('associated', 'JJ'),\n",
              "  ('binary', 'NN'),\n",
              "  ('.', '.')],\n",
              " [('A', 'DT'),\n",
              "  ('usage', 'JJ'),\n",
              "  ('example', 'NN'),\n",
              "  ('of', 'IN'),\n",
              "  ('HfPyTorchModel', 'NNP'),\n",
              "  ('is', 'VBZ'),\n",
              "  ('available', 'JJ'),\n",
              "  ('here', 'RB'),\n",
              "  ('.', '.')],\n",
              " [('Usage', 'VB'),\n",
              "  ('The', 'DT'),\n",
              "  ('easiest', 'JJS'),\n",
              "  ('way', 'NN'),\n",
              "  ('to', 'TO'),\n",
              "  ('try', 'VB'),\n",
              "  ('out', 'RP'),\n",
              "  ('T5', 'NNP'),\n",
              "  ('is', 'VBZ'),\n",
              "  ('with', 'IN'),\n",
              "  ('a', 'DT'),\n",
              "  ('free', 'JJ'),\n",
              "  ('TPU', 'NN'),\n",
              "  ('in', 'IN'),\n",
              "  ('our', 'PRP$'),\n",
              "  ('Colab', 'NNP'),\n",
              "  ('Tutorial', 'NNP'),\n",
              "  ('.', '.')],\n",
              " [('Below', 'IN'),\n",
              "  ('we', 'PRP'),\n",
              "  ('provide', 'VBP'),\n",
              "  ('examples', 'NNS'),\n",
              "  ('for', 'IN'),\n",
              "  ('how', 'WRB'),\n",
              "  ('to', 'TO'),\n",
              "  ('pre', 'VB'),\n",
              "  ('train', 'NN'),\n",
              "  ('fine', 'JJ'),\n",
              "  ('tune', 'NN'),\n",
              "  ('evaluate', 'NN'),\n",
              "  ('and', 'CC'),\n",
              "  ('decode', 'NN'),\n",
              "  ('from', 'IN'),\n",
              "  ('a', 'DT'),\n",
              "  ('model', 'NN'),\n",
              "  ('from', 'IN'),\n",
              "  ('the', 'DT'),\n",
              "  ('command', 'NN'),\n",
              "  ('line', 'NN'),\n",
              "  ('with', 'IN'),\n",
              "  ('our', 'PRP$'),\n",
              "  ('codebase', 'NN'),\n",
              "  ('.', '.')],\n",
              " [('You', 'PRP'),\n",
              "  ('can', 'MD'),\n",
              "  ('use', 'VB'),\n",
              "  ('these', 'DT'),\n",
              "  ('instructions', 'NNS'),\n",
              "  ('to', 'TO'),\n",
              "  ('reproduce', 'VB'),\n",
              "  ('our', 'PRP$'),\n",
              "  ('results', 'NNS'),\n",
              "  ('fine', 'JJ'),\n",
              "  ('tune', 'VBP'),\n",
              "  ('one', 'CD'),\n",
              "  ('of', 'IN'),\n",
              "  ('our', 'PRP$'),\n",
              "  ('released', 'VBN'),\n",
              "  ('checkpoints', 'NNS'),\n",
              "  ('with', 'IN'),\n",
              "  ('your', 'PRP$'),\n",
              "  ('own', 'JJ'),\n",
              "  ('data', 'NNS'),\n",
              "  ('and', 'CC'),\n",
              "  ('or', 'CC'),\n",
              "  ('hyperparameters', 'NNS'),\n",
              "  ('or', 'CC'),\n",
              "  ('pre', 'NN'),\n",
              "  ('train', 'VBP'),\n",
              "  ('a', 'DT'),\n",
              "  ('model', 'NN'),\n",
              "  ('from', 'IN'),\n",
              "  ('scratch', 'NN'),\n",
              "  ('.', '.')],\n",
              " [('Dataset', 'NNP'),\n",
              "  ('Preparation', 'NNP'),\n",
              "  ('You', 'PRP'),\n",
              "  ('may', 'MD'),\n",
              "  ('either', 'VB'),\n",
              "  ('use', 'VB'),\n",
              "  ('a', 'DT'),\n",
              "  ('new', 'JJ'),\n",
              "  ('or', 'CC'),\n",
              "  ('pre', 'JJ'),\n",
              "  ('existing', 'VBG'),\n",
              "  ('Task', 'NN'),\n",
              "  ('or', 'CC'),\n",
              "  ('you', 'PRP'),\n",
              "  ('may', 'MD'),\n",
              "  ('load', 'VB'),\n",
              "  ('examples', 'NNS'),\n",
              "  ('from', 'IN'),\n",
              "  ('a', 'DT'),\n",
              "  ('preprocessed', 'JJ'),\n",
              "  ('TSV', 'NNP'),\n",
              "  ('file', 'NN'),\n",
              "  ('.', '.')],\n",
              " [('Using', 'VBG'),\n",
              "  ('a', 'DT'),\n",
              "  ('Task', 'NNP'),\n",
              "  ('Depending', 'NNP'),\n",
              "  ('on', 'IN'),\n",
              "  ('your', 'PRP$'),\n",
              "  ('data', 'NNS'),\n",
              "  ('source', 'NN'),\n",
              "  ('see', 'VBP'),\n",
              "  ('above', 'IN'),\n",
              "  ('you', 'PRP'),\n",
              "  ('will', 'MD'),\n",
              "  ('need', 'VB'),\n",
              "  ('to', 'TO'),\n",
              "  ('prepare', 'VB'),\n",
              "  ('your', 'PRP$'),\n",
              "  ('data', 'NNS'),\n",
              "  ('appropriately', 'RB'),\n",
              "  ('.', '.')],\n",
              " [('Task', 'NN'),\n",
              "  ('If', 'IN'),\n",
              "  ('using', 'VBG'),\n",
              "  ('a', 'DT'),\n",
              "  ('vanilla', 'NN'),\n",
              "  ('task', 'NN'),\n",
              "  ('just', 'RB'),\n",
              "  ('make', 'VB'),\n",
              "  ('sure', 'JJ'),\n",
              "  ('any', 'DT'),\n",
              "  ('file', 'NN'),\n",
              "  ('s', 'NN'),\n",
              "  ('loaded', 'VBN'),\n",
              "  ('by', 'IN'),\n",
              "  ('your', 'PRP$'),\n",
              "  ('dataset_fn', 'NNS'),\n",
              "  ('are', 'VBP'),\n",
              "  ('accessible', 'JJ'),\n",
              "  ('to', 'TO'),\n",
              "  ('the', 'DT'),\n",
              "  ('TPU', 'NNP'),\n",
              "  ('i.e', 'NN'),\n",
              "  ('.', '.'),\n",
              "  ('are', 'VBP'),\n",
              "  ('in', 'IN'),\n",
              "  ('a', 'DT'),\n",
              "  ('GCS', 'NNP'),\n",
              "  ('bucket', 'NN'),\n",
              "  ('and', 'CC'),\n",
              "  ('you', 'PRP'),\n",
              "  ('should', 'MD'),\n",
              "  ('be', 'VB'),\n",
              "  ('good', 'JJ'),\n",
              "  ('to', 'TO'),\n",
              "  ('go', 'VB')],\n",
              " [('TfdsTask', 'NNP'),\n",
              "  ('Most', 'JJS'),\n",
              "  ('of', 'IN'),\n",
              "  ('our', 'PRP$'),\n",
              "  ('predefined', 'JJ'),\n",
              "  ('Tasks', 'NNP'),\n",
              "  ('use', 'NN'),\n",
              "  ('TensorFlow', 'NNP'),\n",
              "  ('Datasets', 'NNP'),\n",
              "  ('TFDS', 'NNP'),\n",
              "  ('as', 'IN'),\n",
              "  ('their', 'PRP$'),\n",
              "  ('data', 'NNS'),\n",
              "  ('source', 'NN'),\n",
              "  ('.', '.')],\n",
              " [('When', 'WRB'),\n",
              "  ('you', 'PRP'),\n",
              "  ('run', 'VBP'),\n",
              "  ('our', 'PRP$'),\n",
              "  ('training', 'NN'),\n",
              "  ('binary', 'JJ'),\n",
              "  ('see', 'NN'),\n",
              "  ('instructions', 'NNS'),\n",
              "  ('below', 'IN'),\n",
              "  ('with', 'IN'),\n",
              "  ('a', 'DT'),\n",
              "  ('TfdsTask', 'NNP'),\n",
              "  ('the', 'DT'),\n",
              "  ('dataset', 'NN'),\n",
              "  ('will', 'MD'),\n",
              "  ('automatically', 'RB'),\n",
              "  ('be', 'VB'),\n",
              "  ('downloaded', 'VBN'),\n",
              "  ('and', 'CC'),\n",
              "  ('prepared', 'VBN'),\n",
              "  ('on', 'IN'),\n",
              "  ('its', 'PRP$'),\n",
              "  ('first', 'JJ'),\n",
              "  ('use', 'NN'),\n",
              "  ('.', '.')],\n",
              " [('After', 'IN'),\n",
              "  ('preparation', 'NN'),\n",
              "  ('is', 'VBZ'),\n",
              "  ('complete', 'JJ'),\n",
              "  ('the', 'DT'),\n",
              "  ('dataset', 'NN'),\n",
              "  ('is', 'VBZ'),\n",
              "  ('cached', 'VBN'),\n",
              "  ('to', 'TO'),\n",
              "  ('your', 'PRP$'),\n",
              "  ('local', 'JJ'),\n",
              "  ('storage', 'NN'),\n",
              "  ('to', 'TO'),\n",
              "  ('avoid', 'VB'),\n",
              "  ('this', 'DT'),\n",
              "  ('overhead', 'NN'),\n",
              "  ('in', 'IN'),\n",
              "  ('future', 'JJ'),\n",
              "  ('runs', 'NNS'),\n",
              "  ('.', '.')],\n",
              " [('If', 'IN'),\n",
              "  ('working', 'VBG'),\n",
              "  ('in', 'IN'),\n",
              "  ('the', 'DT'),\n",
              "  ('cloud', 'NN'),\n",
              "  ('we', 'PRP'),\n",
              "  ('recommend', 'VBP'),\n",
              "  ('you', 'PRP'),\n",
              "  ('set', 'VBP'),\n",
              "  ('the', 'DT'),\n",
              "  ('t5_tfds_data_dir', 'NN'),\n",
              "  ('flag', 'NN'),\n",
              "  ('to', 'TO'),\n",
              "  ('point', 'VB'),\n",
              "  ('to', 'TO'),\n",
              "  ('a', 'DT'),\n",
              "  ('persistent', 'JJ'),\n",
              "  ('storage', 'NN'),\n",
              "  ('location', 'NN'),\n",
              "  ('such', 'JJ'),\n",
              "  ('as', 'IN'),\n",
              "  ('a', 'DT'),\n",
              "  ('GCS', 'NNP'),\n",
              "  ('bucket', 'NN'),\n",
              "  ('.', '.')],\n",
              " [('This', 'DT'),\n",
              "  ('is', 'VBZ'),\n",
              "  ('a', 'DT'),\n",
              "  ('requirement', 'NN'),\n",
              "  ('when', 'WRB'),\n",
              "  ('training', 'NN'),\n",
              "  ('on', 'IN'),\n",
              "  ('TPU', 'NNP'),\n",
              "  ('.', '.')],\n",
              " [('C4', 'NNP'),\n",
              "  ('The', 'DT'),\n",
              "  ('C4', 'NNP'),\n",
              "  ('dataset', 'NN'),\n",
              "  ('we', 'PRP'),\n",
              "  ('created', 'VBD'),\n",
              "  ('for', 'IN'),\n",
              "  ('unsupervised', 'JJ'),\n",
              "  ('pre', 'NN'),\n",
              "  ('training', 'NN'),\n",
              "  ('is', 'VBZ'),\n",
              "  ('available', 'JJ'),\n",
              "  ('in', 'IN'),\n",
              "  ('TensorFlow', 'NNP'),\n",
              "  ('Datasets', 'NNPS'),\n",
              "  ('but', 'CC'),\n",
              "  ('it', 'PRP'),\n",
              "  ('requires', 'VBZ'),\n",
              "  ('a', 'DT'),\n",
              "  ('significant', 'JJ'),\n",
              "  ('amount', 'NN'),\n",
              "  ('of', 'IN'),\n",
              "  ('bandwidth', 'NN'),\n",
              "  ('for', 'IN'),\n",
              "  ('downloading', 'VBG'),\n",
              "  ('the', 'DT'),\n",
              "  ('raw', 'JJ'),\n",
              "  ('Common', 'NNP'),\n",
              "  ('Crawl', 'NNP'),\n",
              "  ('scrapes', 'VBZ'),\n",
              "  ('7', 'CD'),\n",
              "  ('TB', 'NN'),\n",
              "  ('and', 'CC'),\n",
              "  ('compute', 'NN'),\n",
              "  ('for', 'IN'),\n",
              "  ('its', 'PRP$'),\n",
              "  ('preparation', 'NN'),\n",
              "  ('335', 'CD'),\n",
              "  ('CPU', 'NNP'),\n",
              "  ('days', 'NNS'),\n",
              "  ('.', '.')],\n",
              " [('We', 'PRP'),\n",
              "  ('suggest', 'VBP'),\n",
              "  ('you', 'PRP'),\n",
              "  ('take', 'VBP'),\n",
              "  ('advantage', 'NN'),\n",
              "  ('of', 'IN'),\n",
              "  ('the', 'DT'),\n",
              "  ('Apache', 'NNP'),\n",
              "  ('Beam', 'NNP'),\n",
              "  ('support', 'NN'),\n",
              "  ('in', 'IN'),\n",
              "  ('TFDS', 'NNP'),\n",
              "  ('which', 'WDT'),\n",
              "  ('enables', 'VBZ'),\n",
              "  ('distributed', 'VBD'),\n",
              "  ('preprocessing', 'NN'),\n",
              "  ('of', 'IN'),\n",
              "  ('the', 'DT'),\n",
              "  ('dataset', 'NN'),\n",
              "  ('and', 'CC'),\n",
              "  ('can', 'MD'),\n",
              "  ('be', 'VB'),\n",
              "  ('run', 'VBN'),\n",
              "  ('on', 'IN'),\n",
              "  ('Google', 'NNP'),\n",
              "  ('Cloud', 'NNP'),\n",
              "  ('Dataflow', 'NNP'),\n",
              "  ('.', '.')],\n",
              " [('With', 'IN'),\n",
              "  ('500', 'CD'),\n",
              "  ('workers', 'NNS'),\n",
              "  ('the', 'DT'),\n",
              "  ('job', 'NN'),\n",
              "  ('should', 'MD'),\n",
              "  ('complete', 'VB'),\n",
              "  ('in', 'IN'),\n",
              "  ('16', 'CD'),\n",
              "  ('hours', 'NNS'),\n",
              "  ('.', '.')],\n",
              " [('After', 'IN'),\n",
              "  ('defining', 'VBG'),\n",
              "  ('MY_PROJECT', 'NNP'),\n",
              "  ('and', 'CC'),\n",
              "  ('MY_BUCKET', 'NNP'),\n",
              "  ('appropriately', 'RB'),\n",
              "  ('you', 'PRP'),\n",
              "  ('can', 'MD'),\n",
              "  ('build', 'VB'),\n",
              "  ('the', 'DT'),\n",
              "  ('dataset', 'NN'),\n",
              "  ('in', 'IN'),\n",
              "  ('DataFlow', 'NNP'),\n",
              "  ('from', 'IN'),\n",
              "  ('GCP', 'NNP'),\n",
              "  ('using', 'VBG'),\n",
              "  ('the', 'DT'),\n",
              "  ('following', 'JJ'),\n",
              "  ('commands', 'NNS'),\n",
              "  ('pip', 'VBP'),\n",
              "  ('install', 'JJ'),\n",
              "  ('tfds', 'NN'),\n",
              "  ('nightly', 'RB'),\n",
              "  ('c4', 'VBZ'),\n",
              "  ('echo', 'JJ'),\n",
              "  ('tfds', 'NNS'),\n",
              "  ('nightly', 'RB'),\n",
              "  ('c4', 'VBP'),\n",
              "  ('tmp', 'JJ'),\n",
              "  ('beam_requirements.txt', 'NN'),\n",
              "  ('python', 'NN'),\n",
              "  ('m', 'NN'),\n",
              "  ('tensorflow_datasets.scripts.download_and_prepare', 'NN'),\n",
              "  ('datasets', 'NNS'),\n",
              "  ('c4', 'VBP'),\n",
              "  ('en', 'IN'),\n",
              "  ('data_dir', 'NN'),\n",
              "  ('gs', 'NN'),\n",
              "  ('MY_BUCKET', 'NNP'),\n",
              "  ('tensorflow_datasets', 'NNS'),\n",
              "  ('beam_pipeline_options', 'NNS'),\n",
              "  ('project', 'VBP'),\n",
              "  ('MY_PROJECT', 'NNP'),\n",
              "  ('job_name', 'NN'),\n",
              "  ('c4', 'NN'),\n",
              "  ('staging_location', 'NN'),\n",
              "  ('gs', 'NN'),\n",
              "  ('MY_BUCKET', 'NNP'),\n",
              "  ('binaries', 'VBZ'),\n",
              "  ('temp_location', 'NN'),\n",
              "  ('gs', 'NN'),\n",
              "  ('MY_BUCKET', 'NNP'),\n",
              "  ('temp', 'NN'),\n",
              "  ('runner', 'NN'),\n",
              "  ('DataflowRunner', 'NNP'),\n",
              "  ('requirements_file', 'NN'),\n",
              "  ('tmp', 'NN'),\n",
              "  ('beam_requirements.txt', 'NN'),\n",
              "  ('experiments', 'NNS'),\n",
              "  ('shuffle_mode', 'JJ'),\n",
              "  ('service', 'NN'),\n",
              "  ('region', 'NN'),\n",
              "  ('MY_REGION', 'NNP'),\n",
              "  ('Read', 'NNP'),\n",
              "  ('more', 'RBR'),\n",
              "  ('in', 'IN'),\n",
              "  ('the', 'DT'),\n",
              "  ('TFDS', 'NNP'),\n",
              "  ('Beam', 'NNP'),\n",
              "  ('instructions', 'NNS'),\n",
              "  ('.', '.')],\n",
              " [('TextLineTask', 'VB'),\n",
              "  ('A', 'DT'),\n",
              "  ('TextLineTask', 'NNP'),\n",
              "  ('is', 'VBZ'),\n",
              "  ('useful', 'JJ'),\n",
              "  ('when', 'WRB'),\n",
              "  ('your', 'PRP$'),\n",
              "  ('data', 'NNS'),\n",
              "  ('source', 'NN'),\n",
              "  ('is', 'VBZ'),\n",
              "  ('a', 'DT'),\n",
              "  ('text', 'NN'),\n",
              "  ('file', 'NN'),\n",
              "  ('or', 'CC'),\n",
              "  ('files', 'NNS'),\n",
              "  ('with', 'IN'),\n",
              "  ('one', 'CD'),\n",
              "  ('example', 'NN'),\n",
              "  ('per', 'IN'),\n",
              "  ('line', 'NN'),\n",
              "  ('.', '.')],\n",
              " [('You', 'PRP'),\n",
              "  ('can', 'MD'),\n",
              "  ('then', 'RB'),\n",
              "  ('use', 'VB'),\n",
              "  ('a', 'DT'),\n",
              "  ('text', 'NN'),\n",
              "  ('preprocessor', 'NN'),\n",
              "  ('to', 'TO'),\n",
              "  ('convert', 'VB'),\n",
              "  ('each', 'DT'),\n",
              "  ('line', 'NN'),\n",
              "  ('into', 'IN'),\n",
              "  ('a', 'DT'),\n",
              "  ('dictionary', 'NN'),\n",
              "  ('of', 'IN'),\n",
              "  ('inputs', 'NNS'),\n",
              "  ('and', 'CC'),\n",
              "  ('targets', 'NNS'),\n",
              "  ('.', '.')],\n",
              " [('Make', 'NNP'),\n",
              "  ('sure', 'JJ'),\n",
              "  ('your', 'PRP$'),\n",
              "  ('files', 'NNS'),\n",
              "  ('are', 'VBP'),\n",
              "  ('accessible', 'JJ'),\n",
              "  ('to', 'TO'),\n",
              "  ('the', 'DT'),\n",
              "  ('TPU', 'NNP'),\n",
              "  ('i.e', 'NN'),\n",
              "  ('.', '.'),\n",
              "  ('are', 'VBP'),\n",
              "  ('in', 'IN'),\n",
              "  ('a', 'DT'),\n",
              "  ('GCS', 'NNP'),\n",
              "  ('bucket', 'NN'),\n",
              "  ('and', 'CC'),\n",
              "  ('you', 'PRP'),\n",
              "  ('should', 'MD'),\n",
              "  ('be', 'VB'),\n",
              "  ('good', 'JJ'),\n",
              "  ('to', 'TO'),\n",
              "  ('go', 'VB')],\n",
              " [('Using', 'VBG'),\n",
              "  ('a', 'DT'),\n",
              "  ('TSV', 'NNP'),\n",
              "  ('File', 'NNP'),\n",
              "  ('Directly', 'NNP'),\n",
              "  ('Instead', 'RB'),\n",
              "  ('of', 'IN'),\n",
              "  ('defining', 'VBG'),\n",
              "  ('a', 'DT'),\n",
              "  ('new', 'JJ'),\n",
              "  ('Task', 'NNP'),\n",
              "  ('you', 'PRP'),\n",
              "  ('may', 'MD'),\n",
              "  ('use', 'VB'),\n",
              "  ('a', 'DT'),\n",
              "  ('TSV', 'NNP'),\n",
              "  ('file', 'NN'),\n",
              "  ('or', 'CC'),\n",
              "  ('files', 'NNS'),\n",
              "  ('directly', 'RB'),\n",
              "  ('as', 'IN'),\n",
              "  ('your', 'PRP$'),\n",
              "  ('dataset', 'NN'),\n",
              "  ('where', 'WRB'),\n",
              "  ('each', 'DT'),\n",
              "  ('line', 'NN'),\n",
              "  ('is', 'VBZ'),\n",
              "  ('formatted', 'VBN'),\n",
              "  ('as', 'IN'),\n",
              "  ('input', 'NN'),\n",
              "  ('t', 'NN'),\n",
              "  ('target', 'NN'),\n",
              "  ('.', '.')],\n",
              " [('However', 'RB'),\n",
              "  ('there', 'EX'),\n",
              "  ('are', 'VBP'),\n",
              "  ('a', 'DT'),\n",
              "  ('couple', 'NN'),\n",
              "  ('of', 'IN'),\n",
              "  ('caveats', 'NNS'),\n",
              "  ('There', 'EX'),\n",
              "  ('is', 'VBZ'),\n",
              "  ('no', 'DT'),\n",
              "  ('way', 'NN'),\n",
              "  ('to', 'TO'),\n",
              "  ('define', 'VB'),\n",
              "  ('a', 'DT'),\n",
              "  ('text', 'NN'),\n",
              "  ('processor', 'NN'),\n",
              "  ('so', 'IN'),\n",
              "  ('the', 'DT'),\n",
              "  ('TSV', 'NNP'),\n",
              "  ('will', 'MD'),\n",
              "  ('need', 'VB'),\n",
              "  ('to', 'TO'),\n",
              "  ('contain', 'VB'),\n",
              "  ('your', 'PRP$'),\n",
              "  ('data', 'NNS'),\n",
              "  ('in', 'IN'),\n",
              "  ('a', 'DT'),\n",
              "  ('preprocessed', 'JJ'),\n",
              "  ('format', 'NN'),\n",
              "  ('.', '.')],\n",
              " [('There', 'EX'),\n",
              "  ('is', 'VBZ'),\n",
              "  ('also', 'RB'),\n",
              "  ('currently', 'RB'),\n",
              "  ('no', 'DT'),\n",
              "  ('way', 'NN'),\n",
              "  ('to', 'TO'),\n",
              "  ('set', 'VB'),\n",
              "  ('a', 'DT'),\n",
              "  ('token', 'NN'),\n",
              "  ('preprocessor', 'NN'),\n",
              "  ('postprocess', 'NN'),\n",
              "  ('function', 'NN'),\n",
              "  ('or', 'CC'),\n",
              "  ('metric', 'JJ'),\n",
              "  ('function', 'NN'),\n",
              "  ('for', 'IN'),\n",
              "  ('evaluation', 'NN'),\n",
              "  ('when', 'WRB'),\n",
              "  ('using', 'VBG'),\n",
              "  ('a', 'DT'),\n",
              "  ('TSV', 'NNP'),\n",
              "  ('file', 'NN'),\n",
              "  ('directly', 'RB'),\n",
              "  ('.', '.')],\n",
              " [('If', 'IN'),\n",
              "  ('you', 'PRP'),\n",
              "  ('need', 'VBP'),\n",
              "  ('any', 'DT'),\n",
              "  ('of', 'IN'),\n",
              "  ('these', 'DT'),\n",
              "  ('features', 'NNS'),\n",
              "  ('you', 'PRP'),\n",
              "  ('must', 'MD'),\n",
              "  ('define', 'VB'),\n",
              "  ('a', 'DT'),\n",
              "  ('new', 'JJ'),\n",
              "  ('Task', 'NNP'),\n",
              "  ('TfdsTask', 'NNP'),\n",
              "  ('or', 'CC'),\n",
              "  ('TextLineTask', 'NNP'),\n",
              "  ('.', '.')],\n",
              " [('Similar', 'JJ'),\n",
              "  ('to', 'TO'),\n",
              "  ('the', 'DT'),\n",
              "  ('above', 'JJ'),\n",
              "  ('cases', 'NNS'),\n",
              "  ('your', 'PRP$'),\n",
              "  ('TSV', 'NNP'),\n",
              "  ('file', 'NN'),\n",
              "  ('s', 'NN'),\n",
              "  ('must', 'MD'),\n",
              "  ('be', 'VB'),\n",
              "  ('accessible', 'JJ'),\n",
              "  ('to', 'TO'),\n",
              "  ('the', 'DT'),\n",
              "  ('TPU', 'NNP'),\n",
              "  ('i.e', 'NN'),\n",
              "  ('.', '.'),\n",
              "  ('are', 'VBP'),\n",
              "  ('in', 'IN'),\n",
              "  ('a', 'DT'),\n",
              "  ('GCS', 'NNP'),\n",
              "  ('bucket', 'NN'),\n",
              "  ('.', '.')],\n",
              " [('Installation', 'NN'),\n",
              "  ('To', 'TO'),\n",
              "  ('install', 'VB'),\n",
              "  ('the', 'DT'),\n",
              "  ('T5', 'NNP'),\n",
              "  ('package', 'NN'),\n",
              "  ('simply', 'RB'),\n",
              "  ('run', 'VB'),\n",
              "  ('pip', 'RB'),\n",
              "  ('install', 'JJ'),\n",
              "  ('t5', 'NN'),\n",
              "  ('gcp', 'NN'),\n",
              "  ('Setting', 'VBG'),\n",
              "  ('up', 'RP'),\n",
              "  ('TPUs', 'NNP'),\n",
              "  ('on', 'IN'),\n",
              "  ('GCP', 'NNP'),\n",
              "  ('You', 'PRP'),\n",
              "  ('will', 'MD'),\n",
              "  ('first', 'VB'),\n",
              "  ('need', 'VB'),\n",
              "  ('to', 'TO'),\n",
              "  ('launch', 'VB'),\n",
              "  ('a', 'DT'),\n",
              "  ('Virtual', 'JJ'),\n",
              "  ('Machine', 'NNP'),\n",
              "  ('VM', 'NNP'),\n",
              "  ('on', 'IN'),\n",
              "  ('Google', 'NNP'),\n",
              "  ('Cloud', 'NNP'),\n",
              "  ('.', '.')],\n",
              " [('Details', 'NNS'),\n",
              "  ('about', 'IN'),\n",
              "  ('launching', 'VBG'),\n",
              "  ('the', 'DT'),\n",
              "  ('VM', 'NNP'),\n",
              "  ('can', 'MD'),\n",
              "  ('be', 'VB'),\n",
              "  ('found', 'VBN'),\n",
              "  ('at', 'IN'),\n",
              "  ('the', 'DT'),\n",
              "  ('Google', 'NNP'),\n",
              "  ('Cloud', 'NNP'),\n",
              "  ('Documentation', 'NNP'),\n",
              "  ('.', '.')],\n",
              " [('In', 'IN'),\n",
              "  ('order', 'NN'),\n",
              "  ('to', 'TO'),\n",
              "  ('run', 'VB'),\n",
              "  ('training', 'NN'),\n",
              "  ('or', 'CC'),\n",
              "  ('eval', 'NN'),\n",
              "  ('on', 'IN'),\n",
              "  ('Cloud', 'NNP'),\n",
              "  ('TPUs', 'NNP'),\n",
              "  ('you', 'PRP'),\n",
              "  ('must', 'MD'),\n",
              "  ('set', 'VB'),\n",
              "  ('up', 'RP'),\n",
              "  ('the', 'DT'),\n",
              "  ('following', 'VBG'),\n",
              "  ('variables', 'NNS'),\n",
              "  ('based', 'VBN'),\n",
              "  ('on', 'IN'),\n",
              "  ('your', 'PRP$'),\n",
              "  ('project', 'NN'),\n",
              "  ('zone', 'NN'),\n",
              "  ('and', 'CC'),\n",
              "  ('GCS', 'NNP'),\n",
              "  ('bucket', 'NN'),\n",
              "  ('appropriately', 'RB'),\n",
              "  ('.', '.')],\n",
              " [('Please', 'NNP'),\n",
              "  ('refer', 'NN'),\n",
              "  ('to', 'TO'),\n",
              "  ('the', 'DT'),\n",
              "  ('Cloud', 'NNP'),\n",
              "  ('TPU', 'NNP'),\n",
              "  ('Quickstart', 'NNP'),\n",
              "  ('guide', 'NN'),\n",
              "  ('for', 'IN'),\n",
              "  ('more', 'JJR'),\n",
              "  ('details', 'NNS'),\n",
              "  ('.', '.')],\n",
              " [('export', 'NN'),\n",
              "  ('PROJECT', 'NNP'),\n",
              "  ('your_project_name', 'NNP'),\n",
              "  ('export', 'NN'),\n",
              "  ('ZONE', 'NNP'),\n",
              "  ('your_project_zone', 'NN'),\n",
              "  ('export', 'NN'),\n",
              "  ('BUCKET', 'NNP'),\n",
              "  ('gs', 'NN'),\n",
              "  ('yourbucket', 'NN'),\n",
              "  ('export', 'NN'),\n",
              "  ('TPU_NAME', 'NNP'),\n",
              "  ('t5', 'NN'),\n",
              "  ('tpu', 'NN'),\n",
              "  ('export', 'NN'),\n",
              "  ('TPU_SIZE', 'NNP'),\n",
              "  ('v3', 'NN'),\n",
              "  ('8', 'CD'),\n",
              "  ('export', 'NN'),\n",
              "  ('DATA_DIR', 'NNP'),\n",
              "  ('BUCKET', 'NNP'),\n",
              "  ('your_data_dir', 'NNP'),\n",
              "  ('export', 'NN'),\n",
              "  ('MODEL_DIR', 'NNP'),\n",
              "  ('BUCKET', 'NNP'),\n",
              "  ('your_model_dir', 'NNP'),\n",
              "  ('Please', 'NNP'),\n",
              "  ('use', 'VB'),\n",
              "  ('the', 'DT'),\n",
              "  ('following', 'JJ'),\n",
              "  ('command', 'NN'),\n",
              "  ('to', 'TO'),\n",
              "  ('create', 'VB'),\n",
              "  ('a', 'DT'),\n",
              "  ('TPU', 'NNP'),\n",
              "  ('device', 'NN'),\n",
              "  ('in', 'IN'),\n",
              "  ('the', 'DT'),\n",
              "  ('Cloud', 'NNP'),\n",
              "  ('VM', 'NNP'),\n",
              "  ('.', '.')],\n",
              " [('ctpu', 'VB'),\n",
              "  ('up', 'RP'),\n",
              "  ('name', 'NN'),\n",
              "  ('TPU_NAME', 'NNP'),\n",
              "  ('project', 'NN'),\n",
              "  ('PROJECT', 'NNP'),\n",
              "  ('zone', 'CD'),\n",
              "  ('ZONE', 'NNP'),\n",
              "  ('tpu', 'NN'),\n",
              "  ('size', 'NN'),\n",
              "  ('TPU_SIZE', 'NNP'),\n",
              "  ('tpu', 'VBZ'),\n",
              "  ('only', 'RB'),\n",
              "  ('noconf', 'JJ'),\n",
              "  ('Training', 'NNP'),\n",
              "  ('In', 'IN'),\n",
              "  ('the', 'DT'),\n",
              "  ('command', 'NN'),\n",
              "  ('below', 'IN'),\n",
              "  ('we', 'PRP'),\n",
              "  ('train', 'VBP'),\n",
              "  ('a', 'DT'),\n",
              "  ('model', 'NN'),\n",
              "  ('on', 'IN'),\n",
              "  ('the', 'DT'),\n",
              "  ('GLUE', 'NNP'),\n",
              "  ('Benchmark', 'NNP'),\n",
              "  ('MRPC', 'NNP'),\n",
              "  ('task', 'NN'),\n",
              "  ('from', 'IN'),\n",
              "  ('scratch', 'NN'),\n",
              "  ('.', '.')],\n",
              " [('You', 'PRP'),\n",
              "  ('can', 'MD'),\n",
              "  ('change', 'VB'),\n",
              "  ('the', 'DT'),\n",
              "  ('MIXTURE_NAME', 'NNP'),\n",
              "  ('gin', 'NN'),\n",
              "  ('parameter', 'NN'),\n",
              "  ('to', 'TO'),\n",
              "  ('use', 'VB'),\n",
              "  ('any', 'DT'),\n",
              "  ('of', 'IN'),\n",
              "  ('the', 'DT'),\n",
              "  ('tasks', 'NNS'),\n",
              "  ('or', 'CC'),\n",
              "  ('mixtures', 'NNS'),\n",
              "  ('provided', 'VBN'),\n",
              "  ('in', 'IN'),\n",
              "  ('our', 'PRP$'),\n",
              "  ('package', 'NN'),\n",
              "  ('.', '.')],\n",
              " [('t5_mesh_transformer', 'NN'),\n",
              "  ('tpu', 'NN'),\n",
              "  ('TPU_NAME', 'NNP'),\n",
              "  ('gcp_project', 'NN'),\n",
              "  ('PROJECT', 'NNP'),\n",
              "  ('tpu_zone', 'NN'),\n",
              "  ('ZONE', 'NNP'),\n",
              "  ('model_dir', 'NN'),\n",
              "  ('MODEL_DIR', 'NNP'),\n",
              "  ('t5_tfds_data_dir', 'NN'),\n",
              "  ('DATA_DIR', 'NNP'),\n",
              "  ('gin_file', 'NN'),\n",
              "  ('dataset.gin', 'NN'),\n",
              "  ('gin_file', 'NN'),\n",
              "  ('models', 'NNS'),\n",
              "  ('bi_v1.gin', 'VBP'),\n",
              "  ('gin_param', 'JJ'),\n",
              "  ('utils.tpu_mesh_shape.model_parallelism', 'NN'),\n",
              "  ('1', 'CD'),\n",
              "  ('gin_param', 'NN'),\n",
              "  ('utils.tpu_mesh_shape.tpu_topology', 'NN'),\n",
              "  ('TPU_SIZE', 'NNP'),\n",
              "  ('gin_param', 'NN'),\n",
              "  ('MIXTURE_NAME', 'NNP'),\n",
              "  ('glue_mrpc_v002', 'VBZ'),\n",
              "  ('The', 'DT'),\n",
              "  ('full', 'JJ'),\n",
              "  ('list', 'NN'),\n",
              "  ('of', 'IN'),\n",
              "  ('tasks', 'NNS'),\n",
              "  ('and', 'CC'),\n",
              "  ('mixtures', 'NNS'),\n",
              "  ('can', 'MD'),\n",
              "  ('be', 'VB'),\n",
              "  ('obtained', 'VBN'),\n",
              "  ('by', 'IN'),\n",
              "  ('running', 'VBG'),\n",
              "  ('python', 'NN'),\n",
              "  ('c', 'NN'),\n",
              "  ('import', 'NN'),\n",
              "  ('t5', 'NN'),\n",
              "  (';', ':'),\n",
              "  ('print', 'NN'),\n",
              "  ('t5.data.MixtureRegistry.names', 'NNS'),\n",
              "  ('You', 'PRP'),\n",
              "  ('may', 'MD'),\n",
              "  ('also', 'RB'),\n",
              "  ('define', 'VB'),\n",
              "  ('additional', 'JJ'),\n",
              "  ('tasks', 'NNS'),\n",
              "  ('and', 'CC'),\n",
              "  ('mixtures', 'NNS'),\n",
              "  ('in', 'IN'),\n",
              "  ('a', 'DT'),\n",
              "  ('new', 'JJ'),\n",
              "  ('file', 'NN'),\n",
              "  ('and', 'CC'),\n",
              "  ('import', 'NN'),\n",
              "  ('it', 'PRP'),\n",
              "  ('using', 'VBG'),\n",
              "  ('the', 'DT'),\n",
              "  ('module_import', 'NN'),\n",
              "  ('flag', 'NN'),\n",
              "  ('.', '.')],\n",
              " [('Alternatively', 'RB'),\n",
              "  ('you', 'PRP'),\n",
              "  ('could', 'MD'),\n",
              "  ('train', 'VB'),\n",
              "  ('with', 'IN'),\n",
              "  ('a', 'DT'),\n",
              "  ('TSV', 'NNP'),\n",
              "  ('file', 'NN'),\n",
              "  ('where', 'WRB'),\n",
              "  ('each', 'DT'),\n",
              "  ('line', 'NN'),\n",
              "  ('is', 'VBZ'),\n",
              "  ('formatted', 'VBN'),\n",
              "  ('as', 'IN'),\n",
              "  ('input', 'NN'),\n",
              "  ('t', 'NN'),\n",
              "  ('target', 'NN'),\n",
              "  ('see', 'VBP'),\n",
              "  ('above', 'IN'),\n",
              "  ('.', '.')],\n",
              " [('Fine', 'JJ'),\n",
              "  ('tuning', 'NN'),\n",
              "  ('In', 'IN'),\n",
              "  ('order', 'NN'),\n",
              "  ('to', 'TO'),\n",
              "  ('fine', 'VB'),\n",
              "  ('tune', 'JJ'),\n",
              "  ('one', 'CD'),\n",
              "  ('of', 'IN'),\n",
              "  ('our', 'PRP$'),\n",
              "  ('pre', 'NN'),\n",
              "  ('trained', 'VBN'),\n",
              "  ('models', 'NNS'),\n",
              "  ('you', 'PRP'),\n",
              "  ('need', 'VBP'),\n",
              "  ('to', 'TO'),\n",
              "  ('pass', 'VB'),\n",
              "  ('the', 'DT'),\n",
              "  ('operative', 'JJ'),\n",
              "  ('config', 'NN'),\n",
              "  ('of', 'IN'),\n",
              "  ('the', 'DT'),\n",
              "  ('pre', 'NN'),\n",
              "  ('trained', 'VBD'),\n",
              "  ('model', 'NN'),\n",
              "  ('to', 'TO'),\n",
              "  ('the', 'DT'),\n",
              "  ('training', 'NN'),\n",
              "  ('script', 'NN'),\n",
              "  ('.', '.')],\n",
              " [('The', 'DT'),\n",
              "  ('operative', 'JJ'),\n",
              "  ('config', 'NN'),\n",
              "  ('should', 'MD'),\n",
              "  ('be', 'VB'),\n",
              "  ('passed', 'VBN'),\n",
              "  ('in', 'IN'),\n",
              "  ('as', 'IN'),\n",
              "  ('a', 'DT'),\n",
              "  ('gin_file', 'JJ'),\n",
              "  ('flag', 'NN'),\n",
              "  ('.', '.')],\n",
              " [('It', 'PRP'),\n",
              "  ('specifies', 'VBZ'),\n",
              "  ('the', 'DT'),\n",
              "  ('model', 'NN'),\n",
              "  ('architecture', 'NN'),\n",
              "  ('and', 'CC'),\n",
              "  ('other', 'JJ'),\n",
              "  ('hyperparameters', 'NNS'),\n",
              "  ('.', '.')],\n",
              " [('In', 'IN'),\n",
              "  ('addition', 'NN'),\n",
              "  ('you', 'PRP'),\n",
              "  ('need', 'VBP'),\n",
              "  ('to', 'TO'),\n",
              "  ('specify', 'VB'),\n",
              "  ('the', 'DT'),\n",
              "  ('mixture', 'NN'),\n",
              "  ('to', 'TO'),\n",
              "  ('fine', 'VB'),\n",
              "  ('tune', 'NN'),\n",
              "  ('on', 'IN'),\n",
              "  ('.', '.')],\n",
              " [('For', 'IN'),\n",
              "  ('example', 'NN'),\n",
              "  ('to', 'TO'),\n",
              "  ('fine', 'VB'),\n",
              "  ('tune', 'IN'),\n",
              "  ('the', 'DT'),\n",
              "  ('T5', 'NNP'),\n",
              "  ('small', 'JJ'),\n",
              "  ('model', 'NN'),\n",
              "  ('on', 'IN'),\n",
              "  ('the', 'DT'),\n",
              "  ('glue_mrpc_v002', 'JJ'),\n",
              "  ('mixture', 'NN'),\n",
              "  ('please', 'NN'),\n",
              "  ('run', 'VB'),\n",
              "  ('t5_mesh_transformer', 'JJR'),\n",
              "  ('tpu', 'NN'),\n",
              "  ('TPU_NAME', 'NNP'),\n",
              "  ('gcp_project', 'NN'),\n",
              "  ('PROJECT', 'NNP'),\n",
              "  ('tpu_zone', 'NN'),\n",
              "  ('ZONE', 'NNP'),\n",
              "  ('model_dir', 'NN'),\n",
              "  ('MODEL_DIR', 'NNP'),\n",
              "  ('t5_tfds_data_dir', 'NN'),\n",
              "  ('DATA_DIR', 'NNP'),\n",
              "  ('gin_file', 'NN'),\n",
              "  ('dataset.gin', 'NN'),\n",
              "  ('gin_param', 'VBD'),\n",
              "  ('utils.tpu_mesh_shape.model_parallelism', 'NN'),\n",
              "  ('1', 'CD'),\n",
              "  ('gin_param', 'NN'),\n",
              "  ('utils.tpu_mesh_shape.tpu_topology', 'NN'),\n",
              "  ('TPU_SIZE', 'NNP'),\n",
              "  ('gin_param', 'NN'),\n",
              "  ('MIXTURE_NAME', 'NNP'),\n",
              "  ('glue_mrpc_v002', 'NN'),\n",
              "  ('gin_file', 'NN'),\n",
              "  ('gs', 'NN'),\n",
              "  ('t5', 'NN'),\n",
              "  ('data', 'NNS'),\n",
              "  ('pretrained_models', 'NNS'),\n",
              "  ('small', 'JJ'),\n",
              "  ('operative_config.gin', 'VBP'),\n",
              "  ('The', 'DT'),\n",
              "  ('correct', 'JJ'),\n",
              "  ('pre', 'NN'),\n",
              "  ('trained', 'VBD'),\n",
              "  ('checkpoint', 'JJ'),\n",
              "  ('path', 'NN'),\n",
              "  ('is', 'VBZ'),\n",
              "  ('included', 'VBN'),\n",
              "  ('in', 'IN'),\n",
              "  ('the', 'DT'),\n",
              "  ('operative', 'JJ'),\n",
              "  ('config', 'NN'),\n",
              "  ('.', '.')],\n",
              " [('You', 'PRP'),\n",
              "  ('may', 'MD'),\n",
              "  ('also', 'RB'),\n",
              "  ('define', 'VB'),\n",
              "  ('additional', 'JJ'),\n",
              "  ('tasks', 'NNS'),\n",
              "  ('and', 'CC'),\n",
              "  ('mixtures', 'NNS'),\n",
              "  ('in', 'IN'),\n",
              "  ('a', 'DT'),\n",
              "  ('new', 'JJ'),\n",
              "  ('file', 'NN'),\n",
              "  ('and', 'CC'),\n",
              "  ('import', 'NN'),\n",
              "  ('it', 'PRP'),\n",
              "  ('using', 'VBG'),\n",
              "  ('the', 'DT'),\n",
              "  ('module_import', 'NN'),\n",
              "  ('flag', 'NN'),\n",
              "  ('.', '.')],\n",
              " [('Alternatively', 'RB'),\n",
              "  ('you', 'PRP'),\n",
              "  ('could', 'MD'),\n",
              "  ('fine', 'VB'),\n",
              "  ('tune', 'NN'),\n",
              "  ('with', 'IN'),\n",
              "  ('a', 'DT'),\n",
              "  ('TSV', 'NNP'),\n",
              "  ('file', 'NN'),\n",
              "  ('where', 'WRB'),\n",
              "  ('each', 'DT'),\n",
              "  ('line', 'NN'),\n",
              "  ('is', 'VBZ'),\n",
              "  ('formatted', 'VBN'),\n",
              "  ('as', 'IN'),\n",
              "  ('input', 'NN'),\n",
              "  ('t', 'NN'),\n",
              "  ('target', 'NN'),\n",
              "  ('see', 'VBP'),\n",
              "  ('above', 'IN'),\n",
              "  ('.', '.')],\n",
              " [('For', 'IN'),\n",
              "  ('example', 'NN'),\n",
              "  ('you', 'PRP'),\n",
              "  ('could', 'MD'),\n",
              "  ('try', 'VB'),\n",
              "  ('one', 'CD'),\n",
              "  ('of', 'IN'),\n",
              "  ('the', 'DT'),\n",
              "  ('paired', 'JJ'),\n",
              "  ('translation', 'NN'),\n",
              "  ('datasets', 'NNS'),\n",
              "  ('from', 'IN'),\n",
              "  ('WMT', 'NNP'),\n",
              "  ('19', 'CD'),\n",
              "  ('News', 'NNP'),\n",
              "  ('Commentary', 'NNP'),\n",
              "  ('14', 'CD'),\n",
              "  ('training', 'NN'),\n",
              "  ('set', 'VBN'),\n",
              "  ('e.g', 'RB'),\n",
              "  ('.', '.'),\n",
              "  ('English', 'JJ'),\n",
              "  ('French', 'JJ'),\n",
              "  ('.', '.')],\n",
              " [('When', 'WRB'),\n",
              "  ('using', 'VBG'),\n",
              "  ('a', 'DT'),\n",
              "  ('TSV', 'NNP'),\n",
              "  ('file', 'NN'),\n",
              "  ('you', 'PRP'),\n",
              "  ('would', 'MD'),\n",
              "  ('replace', 'VB'),\n",
              "  ('the', 'DT'),\n",
              "  ('MIXTURE_NAME', 'NNP'),\n",
              "  ('flag', 'NN'),\n",
              "  ('with', 'IN'),\n",
              "  ('gin_param', 'JJ'),\n",
              "  ('utils.run.train_dataset_fn', 'JJ'),\n",
              "  ('@', 'NN'),\n",
              "  ('t5.models.mesh_transformer.tsv_dataset_fn', 'NN'),\n",
              "  ('gin_param', 'NN'),\n",
              "  ('tsv_dataset_fn.filename', 'NN'),\n",
              "  ('gs', 'JJ'),\n",
              "  ('path', 'NN'),\n",
              "  ('to', 'TO'),\n",
              "  ('tsv', 'VB'),\n",
              "  ('To', 'TO'),\n",
              "  ('fine', 'VB'),\n",
              "  ('tune', 'NN'),\n",
              "  ('with', 'IN'),\n",
              "  ('the', 'DT'),\n",
              "  ('same', 'JJ'),\n",
              "  ('hyperparameters', 'NNS'),\n",
              "  ('we', 'PRP'),\n",
              "  ('used', 'VBD'),\n",
              "  ('in', 'IN'),\n",
              "  ('the', 'DT'),\n",
              "  ('paper', 'NN'),\n",
              "  ('using', 'VBG'),\n",
              "  ('a', 'DT'),\n",
              "  ('constant', 'JJ'),\n",
              "  ('learning', 'NN'),\n",
              "  ('rate', 'NN'),\n",
              "  ('of', 'IN'),\n",
              "  ('0.001', 'CD'),\n",
              "  ('you', 'PRP'),\n",
              "  ('can', 'MD'),\n",
              "  ('pass', 'VB'),\n",
              "  ('in', 'IN'),\n",
              "  ('this', 'DT'),\n",
              "  ('gin', 'NN'),\n",
              "  ('file', 'NN'),\n",
              "  ('which', 'WDT'),\n",
              "  ('is', 'VBZ'),\n",
              "  ('included', 'VBN'),\n",
              "  ('in', 'IN'),\n",
              "  ('the', 'DT'),\n",
              "  ('T5', 'NNP'),\n",
              "  ('package', 'NN'),\n",
              "  ('gin_file', 'NN'),\n",
              "  ('learning_rate_schedules', 'VBZ'),\n",
              "  ('constant_0_001.gin', 'VBP'),\n",
              "  ('The', 'DT'),\n",
              "  ('operative', 'JJ'),\n",
              "  ('config', 'NN'),\n",
              "  ('for', 'IN'),\n",
              "  ('the', 'DT'),\n",
              "  ('pre', 'NN'),\n",
              "  ('trained', 'JJ'),\n",
              "  ('models', 'NNS'),\n",
              "  ('are', 'VBP'),\n",
              "  ('set', 'VBN'),\n",
              "  ('so', 'RB'),\n",
              "  ('that', 'IN'),\n",
              "  ('there', 'EX'),\n",
              "  ('is', 'VBZ'),\n",
              "  ('effectively', 'RB'),\n",
              "  ('no', 'DT'),\n",
              "  ('limit', 'NN'),\n",
              "  ('on', 'IN'),\n",
              "  ('the', 'DT'),\n",
              "  ('number', 'NN'),\n",
              "  ('of', 'IN'),\n",
              "  ('train', 'JJ'),\n",
              "  ('steps', 'NNS'),\n",
              "  ('.', '.')],\n",
              " [('If', 'IN'),\n",
              "  ('you', 'PRP'),\n",
              "  ('d', 'VBP'),\n",
              "  ('like', 'IN'),\n",
              "  ('to', 'TO'),\n",
              "  ('train', 'VB'),\n",
              "  ('for', 'IN'),\n",
              "  ('a', 'DT'),\n",
              "  ('specific', 'JJ'),\n",
              "  ('number', 'NN'),\n",
              "  ('of', 'IN'),\n",
              "  ('steps', 'NNS'),\n",
              "  ('you', 'PRP'),\n",
              "  ('ll', 'VBP'),\n",
              "  ('need', 'VBP'),\n",
              "  ('to', 'TO'),\n",
              "  ('pass', 'VB'),\n",
              "  ('that', 'DT'),\n",
              "  ('in', 'IN'),\n",
              "  ('.', '.')],\n",
              " [('Since', 'IN'),\n",
              "  ('the', 'DT'),\n",
              "  ('pre', 'NN'),\n",
              "  ('trained', 'VBD'),\n",
              "  ('model', 'NN'),\n",
              "  ('has', 'VBZ'),\n",
              "  ('already', 'RB'),\n",
              "  ('been', 'VBN'),\n",
              "  ('trained', 'VBN'),\n",
              "  ('for', 'IN'),\n",
              "  ('1', 'CD'),\n",
              "  ('000', 'CD'),\n",
              "  ('000', 'CD'),\n",
              "  ('steps', 'NNS'),\n",
              "  ('you', 'PRP'),\n",
              "  ('should', 'MD'),\n",
              "  ('specify', 'VB'),\n",
              "  ('the', 'DT'),\n",
              "  ('total', 'JJ'),\n",
              "  ('number', 'NN'),\n",
              "  ('of', 'IN'),\n",
              "  ('steps', 'NNS'),\n",
              "  ('after', 'IN'),\n",
              "  ('pre', 'JJ'),\n",
              "  ('training', 'NN'),\n",
              "  ('and', 'CC'),\n",
              "  ('fine', 'JJ'),\n",
              "  ('tuning', 'NN'),\n",
              "  ('.', '.')],\n",
              " [('For', 'IN'),\n",
              "  ('example', 'NN'),\n",
              "  ('if', 'IN'),\n",
              "  ('you', 'PRP'),\n",
              "  ('want', 'VBP'),\n",
              "  ('to', 'TO'),\n",
              "  ('fine', 'VB'),\n",
              "  ('tune', 'NN'),\n",
              "  ('for', 'IN'),\n",
              "  ('an', 'DT'),\n",
              "  ('additional', 'JJ'),\n",
              "  ('10', 'CD'),\n",
              "  ('000', 'CD'),\n",
              "  ('steps', 'NNS'),\n",
              "  ('you', 'PRP'),\n",
              "  ('should', 'MD'),\n",
              "  ('pass', 'VB'),\n",
              "  ('gin_param', 'JJ'),\n",
              "  ('run.train_steps', 'NNS'),\n",
              "  ('1010000', 'CD'),\n",
              "  ('You', 'PRP'),\n",
              "  ('can', 'MD'),\n",
              "  ('also', 'RB'),\n",
              "  ('use', 'VB'),\n",
              "  ('a', 'DT'),\n",
              "  ('different', 'JJ'),\n",
              "  ('batch', 'NN'),\n",
              "  ('size', 'NN'),\n",
              "  ('for', 'IN'),\n",
              "  ('fine', 'JJ'),\n",
              "  ('tuning', 'NN'),\n",
              "  ('.', '.')],\n",
              " [('We', 'PRP'),\n",
              "  ('set', 'VBP'),\n",
              "  ('the', 'DT'),\n",
              "  ('batch', 'NN'),\n",
              "  ('size', 'NN'),\n",
              "  ('according', 'VBG'),\n",
              "  ('to', 'TO'),\n",
              "  ('the', 'DT'),\n",
              "  ('total', 'JJ'),\n",
              "  ('number', 'NN'),\n",
              "  ('of', 'IN'),\n",
              "  ('tokens', 'NNS'),\n",
              "  ('in', 'IN'),\n",
              "  ('a', 'DT'),\n",
              "  ('batch', 'NN'),\n",
              "  ('.', '.')],\n",
              " [('By', 'IN'),\n",
              "  ('default', 'NN'),\n",
              "  ('a', 'DT'),\n",
              "  ('batch', 'NN'),\n",
              "  ('uses', 'VBZ'),\n",
              "  ('a', 'DT'),\n",
              "  ('sequence', 'NN'),\n",
              "  ('length', 'NN'),\n",
              "  ('of', 'IN'),\n",
              "  ('512', 'CD'),\n",
              "  ('.', '.')],\n",
              " [('To', 'TO'),\n",
              "  ('set', 'VB'),\n",
              "  ('the', 'DT'),\n",
              "  ('number', 'NN'),\n",
              "  ('of', 'IN'),\n",
              "  ('tokens', 'NNS'),\n",
              "  ('in', 'IN'),\n",
              "  ('a', 'DT'),\n",
              "  ('batch', 'NN'),\n",
              "  ('you', 'PRP'),\n",
              "  ('should', 'MD'),\n",
              "  ('set', 'VB'),\n",
              "  ('gin_param', 'NN'),\n",
              "  ('tokens_per_batch', 'NN'),\n",
              "  ('1048576', 'CD'),\n",
              "  ('Eval', 'NN'),\n",
              "  ('In', 'IN'),\n",
              "  ('order', 'NN'),\n",
              "  ('to', 'TO'),\n",
              "  ('evaluate', 'VB'),\n",
              "  ('a', 'DT'),\n",
              "  ('model', 'NN'),\n",
              "  ('in', 'IN'),\n",
              "  ('the', 'DT'),\n",
              "  ('T5', 'NNP'),\n",
              "  ('framework', 'NN'),\n",
              "  ('you', 'PRP'),\n",
              "  ('need', 'VBP'),\n",
              "  ('to', 'TO'),\n",
              "  ('use', 'VB'),\n",
              "  ('the', 'DT'),\n",
              "  ('eval.gin', 'NN'),\n",
              "  ('file', 'NN'),\n",
              "  ('specify', 'VB'),\n",
              "  ('the', 'DT'),\n",
              "  ('model', 'NN'),\n",
              "  ('directory', 'NN'),\n",
              "  ('decoding', 'VBG'),\n",
              "  ('method', 'NN'),\n",
              "  ('and', 'CC'),\n",
              "  ('which', 'WDT'),\n",
              "  ('checkpoint', 'VBP'),\n",
              "  ('step', 'NN'),\n",
              "  ('s', 'NN'),\n",
              "  ('to', 'TO'),\n",
              "  ('evaluate', 'VB'),\n",
              "  ('.', '.')],\n",
              " [('So', 'RB'),\n",
              "  ('to', 'TO'),\n",
              "  ('evaluate', 'VB'),\n",
              "  ('on', 'IN'),\n",
              "  ('the', 'DT'),\n",
              "  ('GLUE', 'NNP'),\n",
              "  ('MRPC', 'NNP'),\n",
              "  ('task', 'NN'),\n",
              "  ('using', 'VBG'),\n",
              "  ('beam', 'JJ'),\n",
              "  ('search', 'NN'),\n",
              "  ('on', 'IN'),\n",
              "  ('all', 'DT'),\n",
              "  ('checkpoints', 'NNS'),\n",
              "  ('use', 'VBP'),\n",
              "  ('the', 'DT'),\n",
              "  ('following', 'JJ'),\n",
              "  ('command', 'NN'),\n",
              "  ('t5_mesh_transformer', 'NN'),\n",
              "  ('tpu', 'NN'),\n",
              "  ('TPU_NAME', 'NNP'),\n",
              "  ('gcp_project', 'NN'),\n",
              "  ('PROJECT', 'NNP'),\n",
              "  ('tpu_zone', 'NN'),\n",
              "  ('ZONE', 'NNP'),\n",
              "  ('model_dir', 'NN'),\n",
              "  ('MODEL_DIR', 'NNP'),\n",
              "  ('gin_file', 'NN'),\n",
              "  ('MODEL_DIR', 'NNP'),\n",
              "  ('operative_config.gin', 'NN'),\n",
              "  ('t5_tfds_data_dir', 'NN'),\n",
              "  ('DATA_DIR', 'NNP'),\n",
              "  ('gin_file', 'NN'),\n",
              "  ('eval.gin', 'NN'),\n",
              "  ('gin_file', 'NN'),\n",
              "  ('beam_search.gin', 'NN'),\n",
              "  ('gin_param', 'NN'),\n",
              "  ('run.dataset_split', 'NN'),\n",
              "  ('validation', 'NN'),\n",
              "  ('gin_param', 'NN'),\n",
              "  ('utils.tpu_mesh_shape.tpu_topology', 'NN'),\n",
              "  ('TPU_SIZE', 'NNP'),\n",
              "  ('gin_param', 'NN'),\n",
              "  ('MIXTURE_NAME', 'NNP'),\n",
              "  ('glue_mrpc_v002', 'NN'),\n",
              "  ('gin_param', 'NN'),\n",
              "  ('eval_checkpoint_step', 'NN'),\n",
              "  ('all', 'DT'),\n",
              "  ('To', 'TO'),\n",
              "  ('evaluate', 'VB'),\n",
              "  ('a', 'DT'),\n",
              "  ('specific', 'JJ'),\n",
              "  ('checkpoint', 'NN'),\n",
              "  ('simply', 'RB'),\n",
              "  ('set', 'VBD'),\n",
              "  ('the', 'DT'),\n",
              "  ('eval_checkpoint_step', 'NN'),\n",
              "  ('parameter', 'NN'),\n",
              "  ('to', 'TO'),\n",
              "  ('appropriate', 'VB'),\n",
              "  ('checkpoint', 'NN'),\n",
              "  ('.', '.')],\n",
              " [('gin_param', 'JJ'),\n",
              "  ('eval_checkpoint_step', 'NN'),\n",
              "  ('100000', 'CD'),\n",
              "  ('You', 'PRP'),\n",
              "  ('can', 'MD'),\n",
              "  ('also', 'RB'),\n",
              "  ('use', 'VB'),\n",
              "  ('greedy_decode.gin', 'NN'),\n",
              "  ('or', 'CC'),\n",
              "  ('sample_decode.gin', 'NN'),\n",
              "  ('instead', 'RB'),\n",
              "  ('of', 'IN'),\n",
              "  ('beam_search.gin', 'NN'),\n",
              "  ('in', 'IN'),\n",
              "  ('the', 'DT'),\n",
              "  ('command', 'NN'),\n",
              "  ('above', 'IN'),\n",
              "  ('.', '.')],\n",
              " [('Decode', 'NNP'),\n",
              "  ('In', 'IN'),\n",
              "  ('order', 'NN'),\n",
              "  ('to', 'TO'),\n",
              "  ('produce', 'VB'),\n",
              "  ('predictions', 'NNS'),\n",
              "  ('from', 'IN'),\n",
              "  ('a', 'DT'),\n",
              "  ('model', 'NN'),\n",
              "  ('in', 'IN'),\n",
              "  ('the', 'DT'),\n",
              "  ('T5', 'NNP'),\n",
              "  ('framework', 'NN'),\n",
              "  ('you', 'PRP'),\n",
              "  ('need', 'VBP'),\n",
              "  ('to', 'TO'),\n",
              "  ('specify', 'VB'),\n",
              "  ('the', 'DT'),\n",
              "  ('model', 'NN'),\n",
              "  ('directory', 'NN'),\n",
              "  ('decoding', 'VBG'),\n",
              "  ('method', 'NN'),\n",
              "  ('and', 'CC'),\n",
              "  ('which', 'WDT'),\n",
              "  ('checkpoint', 'VBP'),\n",
              "  ('step', 'NN'),\n",
              "  ('s', 'NN'),\n",
              "  ('to', 'TO'),\n",
              "  ('use', 'VB'),\n",
              "  ('for', 'IN'),\n",
              "  ('decoding', 'NN'),\n",
              "  ('.', '.')],\n",
              " [('Assuming', 'VBG'),\n",
              "  ('you', 'PRP'),\n",
              "  ('have', 'VBP'),\n",
              "  ('a', 'DT'),\n",
              "  ('text', 'NN'),\n",
              "  ('file', 'NN'),\n",
              "  ('of', 'IN'),\n",
              "  ('input', 'NN'),\n",
              "  ('sequences', 'NNS'),\n",
              "  ('stored', 'VBD'),\n",
              "  ('at', 'IN'),\n",
              "  ('path', 'NN'),\n",
              "  ('to', 'TO'),\n",
              "  ('intputs.txt', 'VB'),\n",
              "  ('an', 'DT'),\n",
              "  ('example', 'NN'),\n",
              "  ('command', 'NN'),\n",
              "  ('would', 'MD'),\n",
              "  ('be', 'VB'),\n",
              "  ('t5_mesh_transformer', 'JJ'),\n",
              "  ('tpu', 'NN'),\n",
              "  ('TPU_NAME', 'NNP'),\n",
              "  ('gcp_project', 'NN'),\n",
              "  ('PROJECT', 'NNP'),\n",
              "  ('tpu_zone', 'NN'),\n",
              "  ('ZONE', 'NNP'),\n",
              "  ('model_dir', 'NN'),\n",
              "  ('MODEL_DIR', 'NNP'),\n",
              "  ('gin_file', 'NN'),\n",
              "  ('MODEL_DIR', 'NNP'),\n",
              "  ('operative_config.gin', 'NN'),\n",
              "  ('gin_file', 'NN'),\n",
              "  ('infer.gin', 'NN'),\n",
              "  ('gin_file', 'NN'),\n",
              "  ('sample_decode.gin', 'NN'),\n",
              "  ('gin_param', 'NN'),\n",
              "  ('input_filename', 'JJ'),\n",
              "  ('path', 'NN'),\n",
              "  ('to', 'TO'),\n",
              "  ('inputs.txt', 'VB'),\n",
              "  ('gin_param', 'JJ'),\n",
              "  ('output_filename', 'NN'),\n",
              "  ('tmp', 'NN'),\n",
              "  ('outputs.txt', 'JJ'),\n",
              "  ('gin_param', 'NN'),\n",
              "  ('utils.tpu_mesh_shape.tpu_topology', 'NN'),\n",
              "  ('TPU_SIZE', 'NNP'),\n",
              "  ('gin_param', 'NN'),\n",
              "  ('infer_checkpoint_step', 'NN'),\n",
              "  ('all', 'DT'),\n",
              "  ('To', 'TO'),\n",
              "  ('predict', 'VB'),\n",
              "  ('with', 'IN'),\n",
              "  ('a', 'DT'),\n",
              "  ('specific', 'JJ'),\n",
              "  ('checkpoint', 'NN'),\n",
              "  ('simply', 'RB'),\n",
              "  ('set', 'VBD'),\n",
              "  ('the', 'DT'),\n",
              "  ('infer_checkpoint_step', 'NN'),\n",
              "  ('parameter', 'NN'),\n",
              "  ('to', 'TO'),\n",
              "  ('appropriate', 'VB'),\n",
              "  ('checkpoint', 'NN'),\n",
              "  ('.', '.')],\n",
              " [('gin_param', 'JJ'),\n",
              "  ('infer_checkpoint_step', 'NN'),\n",
              "  ('100000', 'CD'),\n",
              "  ('You', 'PRP'),\n",
              "  ('can', 'MD'),\n",
              "  ('also', 'RB'),\n",
              "  ('use', 'VB'),\n",
              "  ('beam_search.gin', 'NN'),\n",
              "  ('or', 'CC'),\n",
              "  ('greedy_decode.gin', 'NN'),\n",
              "  ('instead', 'RB'),\n",
              "  ('of', 'IN'),\n",
              "  ('sample_decode.gin', 'NN'),\n",
              "  ('in', 'IN'),\n",
              "  ('the', 'DT'),\n",
              "  ('command', 'NN'),\n",
              "  ('above', 'IN'),\n",
              "  ('.', '.')],\n",
              " [('Export', 'NNP'),\n",
              "  ('You', 'PRP'),\n",
              "  ('may', 'MD'),\n",
              "  ('also', 'RB'),\n",
              "  ('want', 'VB'),\n",
              "  ('to', 'TO'),\n",
              "  ('export', 'VB'),\n",
              "  ('a', 'DT'),\n",
              "  ('SavedModel', 'NNP'),\n",
              "  ('which', 'WDT'),\n",
              "  ('is', 'VBZ'),\n",
              "  ('useful', 'JJ'),\n",
              "  ('for', 'IN'),\n",
              "  ('serving', 'VBG'),\n",
              "  ('your', 'PRP$'),\n",
              "  ('trained', 'JJ'),\n",
              "  ('model', 'NN'),\n",
              "  ('e.g', 'NN'),\n",
              "  ('.', '.'),\n",
              "  ('when', 'WRB'),\n",
              "  ('deploying', 'VBG'),\n",
              "  ('with', 'IN'),\n",
              "  ('ML', 'NNP'),\n",
              "  ('Engine', 'NNP'),\n",
              "  ('or', 'CC'),\n",
              "  ('in', 'IN'),\n",
              "  ('a', 'DT'),\n",
              "  ('Docker', 'NNP'),\n",
              "  ('image', 'NN'),\n",
              "  ('.', '.')],\n",
              " [('t5_mesh_transformer', 'NN'),\n",
              "  ('gcp_project', 'NN'),\n",
              "  ('PROJECT', 'NNP'),\n",
              "  ('tpu_zone', 'NN'),\n",
              "  ('ZONE', 'NNP'),\n",
              "  ('model_dir', 'NN'),\n",
              "  ('MODEL_DIR', 'NNP'),\n",
              "  ('use_model_api', 'JJ'),\n",
              "  ('mode', 'NN'),\n",
              "  ('export_predict', 'NN'),\n",
              "  ('export_dir', 'VBZ'),\n",
              "  ('path', 'NN'),\n",
              "  ('to', 'TO'),\n",
              "  ('export', 'VB'),\n",
              "  ('dir', 'VB'),\n",
              "  ('The', 'DT'),\n",
              "  ('command', 'NN'),\n",
              "  ('above', 'IN'),\n",
              "  ('exports', 'NNS'),\n",
              "  ('the', 'DT'),\n",
              "  ('latest', 'JJS'),\n",
              "  ('checkpoint', 'NN'),\n",
              "  ('in', 'IN'),\n",
              "  ('the', 'DT'),\n",
              "  ('model', 'NN'),\n",
              "  ('directory', 'NN'),\n",
              "  ('.', '.')],\n",
              " [('To', 'TO'),\n",
              "  ('export', 'VB'),\n",
              "  ('a', 'DT'),\n",
              "  ('particular', 'JJ'),\n",
              "  ('checkpoint', 'NN'),\n",
              "  ('add', 'VBP'),\n",
              "  ('the', 'DT'),\n",
              "  ('following', 'JJ'),\n",
              "  ('flags', 'NNS'),\n",
              "  ('checkpoint_mode', 'VBP'),\n",
              "  ('specific', 'JJ'),\n",
              "  ('checkpoint_steps', 'NNS'),\n",
              "  ('1000000', 'CD'),\n",
              "  ('The', 'DT'),\n",
              "  ('t5', 'NN'),\n",
              "  ('deploy', 'NN'),\n",
              "  ('notebook', 'NN'),\n",
              "  ('demonstrates', 'VBZ'),\n",
              "  ('exporting', 'VBG'),\n",
              "  ('a', 'DT'),\n",
              "  ('SavedModel', 'NNP'),\n",
              "  ('and', 'CC'),\n",
              "  ('packaging', 'VBG'),\n",
              "  ('it', 'PRP'),\n",
              "  ('in', 'IN'),\n",
              "  ('a', 'DT'),\n",
              "  ('Docker', 'NNP'),\n",
              "  ('image', 'NN'),\n",
              "  ('for', 'IN'),\n",
              "  ('serving', 'VBG'),\n",
              "  ('.', '.')],\n",
              " [('GPU', 'NNP'),\n",
              "  ('Usage', 'NNP'),\n",
              "  ('If', 'IN'),\n",
              "  ('you', 'PRP'),\n",
              "  ('would', 'MD'),\n",
              "  ('like', 'VB'),\n",
              "  ('to', 'TO'),\n",
              "  ('use', 'VB'),\n",
              "  ('GPU', 'NNP'),\n",
              "  ('instead', 'RB'),\n",
              "  ('of', 'IN'),\n",
              "  ('TPUs', 'NNP'),\n",
              "  ('you', 'PRP'),\n",
              "  ('can', 'MD'),\n",
              "  ('modify', 'VB'),\n",
              "  ('the', 'DT'),\n",
              "  ('above', 'JJ'),\n",
              "  ('commands', 'NNS'),\n",
              "  ('by', 'IN'),\n",
              "  ('removing', 'VBG'),\n",
              "  ('TPU', 'NNP'),\n",
              "  ('specific', 'JJ'),\n",
              "  ('flags', 'NNS'),\n",
              "  ('tpu', 'VBP'),\n",
              "  ('tpu_zone', 'NN'),\n",
              "  ('gcp_project', 'NN'),\n",
              "  ('and', 'CC'),\n",
              "  ('setting', 'VBG'),\n",
              "  ('the', 'DT'),\n",
              "  ('gin', 'NN'),\n",
              "  ('params', 'NN'),\n",
              "  ('for', 'IN'),\n",
              "  ('mesh_shape', 'NN'),\n",
              "  ('and', 'CC'),\n",
              "  ('mesh_devices', 'NNS'),\n",
              "  ('based', 'VBN'),\n",
              "  ('on', 'IN'),\n",
              "  ('your', 'PRP$'),\n",
              "  ('desired', 'JJ'),\n",
              "  ('setup', 'NN'),\n",
              "  ('.', '.')],\n",
              " [('For', 'IN'),\n",
              "  ('example', 'NN'),\n",
              "  ('if', 'IN'),\n",
              "  ('your', 'PRP$'),\n",
              "  ('machine', 'NN'),\n",
              "  ('has', 'VBZ'),\n",
              "  ('access', 'NN'),\n",
              "  ('to', 'TO'),\n",
              "  ('6', 'CD'),\n",
              "  ('GPUs', 'NNP'),\n",
              "  ('and', 'CC'),\n",
              "  ('you', 'PRP'),\n",
              "  ('d', 'VBP'),\n",
              "  ('like', 'IN'),\n",
              "  ('to', 'TO'),\n",
              "  ('do', 'VB'),\n",
              "  ('3', 'CD'),\n",
              "  ('way', 'NN'),\n",
              "  ('model', 'NN'),\n",
              "  ('parallelism', 'NN'),\n",
              "  ('and', 'CC'),\n",
              "  ('2', 'CD'),\n",
              "  ('way', 'NN'),\n",
              "  ('data', 'NNS'),\n",
              "  ('parallelism', 'NN'),\n",
              "  ('the', 'DT'),\n",
              "  ('fine', 'JJ'),\n",
              "  ('tuning', 'NN'),\n",
              "  ('command', 'NN'),\n",
              "  ('above', 'IN'),\n",
              "  ('would', 'MD'),\n",
              "  ('become', 'VB'),\n",
              "  ('t5_mesh_transformer', 'JJ'),\n",
              "  ('model_dir', 'NNS'),\n",
              "  ('MODEL_DIR', 'NNP'),\n",
              "  ('t5_tfds_data_dir', 'NN'),\n",
              "  ('DATA_DIR', 'NNP'),\n",
              "  ('gin_file', 'NN'),\n",
              "  ('dataset.gin', 'NN'),\n",
              "  ('gin_param', 'NN'),\n",
              "  ('utils.run.mesh_shape', 'NN'),\n",
              "  ('model', 'NN'),\n",
              "  ('3', 'CD'),\n",
              "  ('batch', 'NN'),\n",
              "  ('2', 'CD'),\n",
              "  ('gin_param', 'NN'),\n",
              "  ('utils.run.mesh_devices', 'NNS'),\n",
              "  ('gpu', 'VBP'),\n",
              "  ('0', 'CD'),\n",
              "  ('gpu', 'NN'),\n",
              "  ('1', 'CD'),\n",
              "  ('gpu', 'NN'),\n",
              "  ('2', 'CD'),\n",
              "  ('gpu', 'NN'),\n",
              "  ('3', 'CD'),\n",
              "  ('gpu', 'NN'),\n",
              "  ('4', 'CD'),\n",
              "  ('gpu', 'NN'),\n",
              "  ('5', 'CD'),\n",
              "  ('gin_param', 'NN'),\n",
              "  ('MIXTURE_NAME', 'NNP'),\n",
              "  ('glue_mrpc_v002', 'NN'),\n",
              "  ('gin_file', 'NN'),\n",
              "  ('gs', 'NN'),\n",
              "  ('t5', 'NN'),\n",
              "  ('data', 'NNS'),\n",
              "  ('pretrained_models', 'NNS'),\n",
              "  ('small', 'JJ'),\n",
              "  ('operative_config.gin', 'VBP'),\n",
              "  ('With', 'IN'),\n",
              "  ('a', 'DT'),\n",
              "  ('single', 'JJ'),\n",
              "  ('GPU', 'NNP'),\n",
              "  ('the', 'DT'),\n",
              "  ('command', 'NN'),\n",
              "  ('is', 'VBZ'),\n",
              "  ('t5_mesh_transformer', 'JJ'),\n",
              "  ('model_dir', 'NN'),\n",
              "  ('MODEL_DIR', 'NNP'),\n",
              "  ('t5_tfds_data_dir', 'NN'),\n",
              "  ('DATA_DIR', 'NNP'),\n",
              "  ('gin_file', 'NN'),\n",
              "  ('dataset.gin', 'NN'),\n",
              "  ('gin_param', 'NN'),\n",
              "  ('utils.run.mesh_shape', 'NN'),\n",
              "  ('model', 'NN'),\n",
              "  ('1', 'CD'),\n",
              "  ('batch', 'NN'),\n",
              "  ('1', 'CD'),\n",
              "  ('gin_param', 'NN'),\n",
              "  ('utils.run.mesh_devices', 'NNS'),\n",
              "  ('gpu', 'VBP'),\n",
              "  ('0', 'CD'),\n",
              "  ('gin_param', 'NN'),\n",
              "  ('MIXTURE_NAME', 'NNP'),\n",
              "  ('glue_mrpc_v002', 'NN'),\n",
              "  ('gin_file', 'NN'),\n",
              "  ('gs', 'NN'),\n",
              "  ('t5', 'NN'),\n",
              "  ('data', 'NNS'),\n",
              "  ('pretrained_models', 'NNS'),\n",
              "  ('small', 'JJ'),\n",
              "  ('operative_config.gin', 'VBP'),\n",
              "  ('Reproducing', 'VBG'),\n",
              "  ('our', 'PRP$'),\n",
              "  ('experiments', 'NNS'),\n",
              "  ('We', 'PRP'),\n",
              "  ('provide', 'VBP'),\n",
              "  ('operative', 'JJ'),\n",
              "  ('configs', 'NNS'),\n",
              "  ('for', 'IN'),\n",
              "  ('all', 'DT'),\n",
              "  ('of', 'IN'),\n",
              "  ('the', 'DT'),\n",
              "  ('experiments', 'NNS'),\n",
              "  ('in', 'IN'),\n",
              "  ('the', 'DT'),\n",
              "  ('paper', 'NN'),\n",
              "  ('in', 'IN'),\n",
              "  ('gs', 'JJ'),\n",
              "  ('t5', 'NN'),\n",
              "  ('data', 'NNS'),\n",
              "  ('experiments', 'NNS'),\n",
              "  ('.', '.')],\n",
              " [('The', 'DT'),\n",
              "  ('experiments', 'NNS'),\n",
              "  ('folder', 'NN'),\n",
              "  ('has', 'VBZ'),\n",
              "  ('different', 'JJ'),\n",
              "  ('subdirectories', 'NNS'),\n",
              "  ('corresponding', 'VBG'),\n",
              "  ('to', 'TO'),\n",
              "  ('the', 'DT'),\n",
              "  ('different', 'JJ'),\n",
              "  ('sections', 'NNS'),\n",
              "  ('in', 'IN'),\n",
              "  ('our', 'PRP$'),\n",
              "  ('paper', 'NN'),\n",
              "  ('.', '.')],\n",
              " [('For', 'IN'),\n",
              "  ('example', 'NN'),\n",
              "  ('gs', 'NN'),\n",
              "  ('t5', 'NN'),\n",
              "  ('data', 'NNS'),\n",
              "  ('experiments', 'NNS'),\n",
              "  ('objectives', 'NNS'),\n",
              "  ('contains', 'VBZ'),\n",
              "  ('the', 'DT'),\n",
              "  ('experiments', 'NNS'),\n",
              "  ('from', 'IN'),\n",
              "  ('Section', 'NNP'),\n",
              "  ('3.3', 'CD'),\n",
              "  ('Unsupervised', 'VBD'),\n",
              "  ('objectives', 'NNS'),\n",
              "  ('.', '.')],\n",
              " [('Each', 'DT'),\n",
              "  ('subdirectory', 'NN'),\n",
              "  ('of', 'IN'),\n",
              "  ('the', 'DT'),\n",
              "  ('objectives', 'NNS'),\n",
              "  ('folder', 'VBP'),\n",
              "  ('contains', 'NNS'),\n",
              "  ('operative', 'JJ'),\n",
              "  ('configs', 'NNS'),\n",
              "  ('for', 'IN'),\n",
              "  ('some', 'DT'),\n",
              "  ('particular', 'JJ'),\n",
              "  ('experiment', 'NN'),\n",
              "  ('where', 'WRB'),\n",
              "  ('loosely', 'RB'),\n",
              "  ('speaking', 'VBG'),\n",
              "  ('an', 'DT'),\n",
              "  ('experiment', 'NN'),\n",
              "  ('is', 'VBZ'),\n",
              "  ('one', 'CD'),\n",
              "  ('of', 'IN'),\n",
              "  ('the', 'DT'),\n",
              "  ('rows', 'NNS'),\n",
              "  ('in', 'IN'),\n",
              "  ('one', 'CD'),\n",
              "  ('of', 'IN'),\n",
              "  ('the', 'DT'),\n",
              "  ('tables', 'NNS'),\n",
              "  ('in', 'IN'),\n",
              "  ('our', 'PRP$'),\n",
              "  ('paper', 'NN'),\n",
              "  ('.', '.')],\n",
              " [('Let', 'VB'),\n",
              "  ('s', 'NNS'),\n",
              "  ('say', 'VB'),\n",
              "  ('you', 'PRP'),\n",
              "  ('want', 'VBP'),\n",
              "  ('to', 'TO'),\n",
              "  ('reproduce', 'VB'),\n",
              "  ('the', 'DT'),\n",
              "  ('results', 'NNS'),\n",
              "  ('for', 'IN'),\n",
              "  ('the', 'DT'),\n",
              "  ('Prefix', 'NNP'),\n",
              "  ('language', 'NN'),\n",
              "  ('modeling', 'VBG'),\n",
              "  ('objective', 'VBP'),\n",
              "  ('the', 'DT'),\n",
              "  ('first', 'JJ'),\n",
              "  ('row', 'NN'),\n",
              "  ('in', 'IN'),\n",
              "  ('Table', 'JJ'),\n",
              "  ('4', 'CD'),\n",
              "  ('.', '.')],\n",
              " [('The', 'DT'),\n",
              "  ('operative', 'JJ'),\n",
              "  ('configs', 'NN'),\n",
              "  ('for', 'IN'),\n",
              "  ('that', 'DT'),\n",
              "  ('experiment', 'JJ'),\n",
              "  ('live', 'NN'),\n",
              "  ('in', 'IN'),\n",
              "  ('gs', 'JJ'),\n",
              "  ('t5', 'NN'),\n",
              "  ('data', 'NNS'),\n",
              "  ('experiments', 'NNS'),\n",
              "  ('objectives', 'NNS'),\n",
              "  ('obj', 'VBP'),\n",
              "  ('prefix_lm', 'NN'),\n",
              "  ('.', '.')],\n",
              " [('In', 'IN'),\n",
              "  ('the', 'DT'),\n",
              "  ('base', 'NN'),\n",
              "  ('directory', 'NN'),\n",
              "  ('there', 'EX'),\n",
              "  ('is', 'VBZ'),\n",
              "  ('an', 'DT'),\n",
              "  ('operative', 'JJ'),\n",
              "  ('config', 'NN'),\n",
              "  ('for', 'IN'),\n",
              "  ('pre', 'NN'),\n",
              "  ('training', 'VBG'),\n",
              "  ('the', 'DT'),\n",
              "  ('model', 'NN'),\n",
              "  ('gs', 'NN'),\n",
              "  ('t5', 'NN'),\n",
              "  ('data', 'NNS'),\n",
              "  ('experiments', 'NNS'),\n",
              "  ('objectives', 'NNS'),\n",
              "  ('obj', 'VBP'),\n",
              "  ('prefix_lm', 'JJ'),\n",
              "  ('operative_config.gin', 'NN'),\n",
              "  ('.', '.')],\n",
              " [('Then', 'RB'),\n",
              "  ('there', 'EX'),\n",
              "  ('are', 'VBP'),\n",
              "  ('subdirectories', 'NNS'),\n",
              "  ('for', 'IN'),\n",
              "  ('each', 'DT'),\n",
              "  ('of', 'IN'),\n",
              "  ('the', 'DT'),\n",
              "  ('downstream', 'NN'),\n",
              "  ('fine', 'NN'),\n",
              "  ('tuning', 'VBG'),\n",
              "  ('mixtures', 'NNS'),\n",
              "  ('we', 'PRP'),\n",
              "  ('consider', 'VBP'),\n",
              "  ('each', 'DT'),\n",
              "  ('of', 'IN'),\n",
              "  ('which', 'WDT'),\n",
              "  ('has', 'VBZ'),\n",
              "  ('its', 'PRP$'),\n",
              "  ('own', 'JJ'),\n",
              "  ('operative', 'JJ'),\n",
              "  ('config', 'NN'),\n",
              "  ('for', 'IN'),\n",
              "  ('example', 'NN'),\n",
              "  ('gs', 'NN'),\n",
              "  ('t5', 'NN'),\n",
              "  ('data', 'NNS'),\n",
              "  ('experiments', 'NNS'),\n",
              "  ('objectives', 'NNS'),\n",
              "  ('obj', 'VBP'),\n",
              "  ('prefix_lm', 'JJ'),\n",
              "  ('cnn_dailymail_v002', 'NN'),\n",
              "  ('operative_config.gin', 'NN'),\n",
              "  ('.', '.')],\n",
              " [('To', 'TO'),\n",
              "  ('run', 'VB'),\n",
              "  ('this', 'DT'),\n",
              "  ('experiment', 'NN'),\n",
              "  ('first', 'RB'),\n",
              "  ('pre', 'VBZ'),\n",
              "  ('train', 'VB'),\n",
              "  ('a', 'DT'),\n",
              "  ('model', 'NN'),\n",
              "  ('with', 'IN'),\n",
              "  ('the', 'DT'),\n",
              "  ('pre', 'NN'),\n",
              "  ('training', 'NN'),\n",
              "  ('operative', 'JJ'),\n",
              "  ('config', 'NN'),\n",
              "  ('export', 'NN'),\n",
              "  ('PRETRAIN_MODEL_DIR', 'NNP'),\n",
              "  ('BUCKET', 'NNP'),\n",
              "  ('obj', 'MD'),\n",
              "  ('prefix_lm', 'VB'),\n",
              "  ('t5_mesh_transformer', 'JJR'),\n",
              "  ('tpu', 'NN'),\n",
              "  ('TPU_NAME', 'NNP'),\n",
              "  ('gcp_project', 'NN'),\n",
              "  ('PROJECT', 'NNP'),\n",
              "  ('tpu_zone', 'NN'),\n",
              "  ('ZONE', 'NNP'),\n",
              "  ('model_dir', 'NN'),\n",
              "  ('PRETRAIN_MODEL_DIR', 'NNP'),\n",
              "  ('gin_file', 'NN'),\n",
              "  ('gs', 'NN'),\n",
              "  ('t5', 'NN'),\n",
              "  ('data', 'NNS'),\n",
              "  ('experiments', 'NNS'),\n",
              "  ('objectives', 'NNS'),\n",
              "  ('obj', 'VBP'),\n",
              "  ('prefix_lm', 'JJ'),\n",
              "  ('operative_config.gin', 'NN'),\n",
              "  ('gin_param', 'VBD'),\n",
              "  ('utils.tpu_mesh_shape.model_parallelism', 'NN'),\n",
              "  ('1', 'CD'),\n",
              "  ('gin_param', 'NN'),\n",
              "  ('utils.tpu_mesh_shape.tpu_topology', 'NN'),\n",
              "  ('TPU_SIZE', 'NNP'),\n",
              "  ('Then', 'RB'),\n",
              "  ('you', 'PRP'),\n",
              "  ('can', 'MD'),\n",
              "  ('fine', 'VB'),\n",
              "  ('tune', 'VB'),\n",
              "  ('the', 'DT'),\n",
              "  ('pre', 'NN'),\n",
              "  ('trained', 'VBD'),\n",
              "  ('model', 'NN'),\n",
              "  ('on', 'IN'),\n",
              "  ('CNN', 'NNP'),\n",
              "  ('Daily', 'NNP'),\n",
              "  ('Mail', 'NNP'),\n",
              "  ('like', 'IN'),\n",
              "  ('so', 'RB'),\n",
              "  ('export', 'JJ'),\n",
              "  ('FINETUNE_MODEL_DIR', 'NNP'),\n",
              "  ('BUCKET', 'NNP'),\n",
              "  ('obj', 'MD'),\n",
              "  ('prefix_lm', 'VB'),\n",
              "  ('cnn_dailymail_v002', 'JJ'),\n",
              "  ('t5_mesh_transformer', 'NN'),\n",
              "  ('tpu', 'NN'),\n",
              "  ('TPU_NAME', 'NNP'),\n",
              "  ('gcp_project', 'NN'),\n",
              "  ('PROJECT', 'NNP'),\n",
              "  ('tpu_zone', 'NN'),\n",
              "  ('ZONE', 'NNP'),\n",
              "  ('model_dir', 'NN'),\n",
              "  ('FINETUNE_MODEL_DIR', 'NNP'),\n",
              "  ('gin_file', 'NN'),\n",
              "  ('gs', 'NN'),\n",
              "  ('t5', 'NN'),\n",
              "  ('data', 'NNS'),\n",
              "  ('experiments', 'NNS'),\n",
              "  ('objectives', 'NNS'),\n",
              "  ('obj', 'VBP'),\n",
              "  ('prefix_lm', 'JJ'),\n",
              "  ('cnn_dailymail_v002', 'NN'),\n",
              "  ('operative_config.gin', 'NN'),\n",
              "  ('gin_param', 'NN'),\n",
              "  ('init_checkpoint', 'NN'),\n",
              "  ('PRETRAIN_MODEL_DIR', 'NNP'),\n",
              "  ('model.ckpt', 'VBZ'),\n",
              "  ('524288', 'CD'),\n",
              "  ('gin_param', 'NN'),\n",
              "  ('utils.tpu_mesh_shape.model_parallelism', 'NN'),\n",
              "  ('1', 'CD'),\n",
              "  ('gin_param', 'NN'),\n",
              "  ('utils.tpu_mesh_shape.tpu_topology', 'NN'),\n",
              "  ('TPU_SIZE', 'NNP'),\n",
              "  ('Useful', 'NNP'),\n",
              "  ('Options', 'NNP'),\n",
              "  ('Some', 'DT'),\n",
              "  ('training', 'NN'),\n",
              "  ('variants', 'NNS'),\n",
              "  ('need', 'VBP'),\n",
              "  ('multiple', 'JJ'),\n",
              "  ('flags', 'NNS'),\n",
              "  ('to', 'TO'),\n",
              "  ('be', 'VB'),\n",
              "  ('set', 'VBN'),\n",
              "  ('at', 'IN'),\n",
              "  ('the', 'DT'),\n",
              "  ('same', 'JJ'),\n",
              "  ('time', 'NN'),\n",
              "  ('.', '.')],\n",
              " [('For', 'IN'),\n",
              "  ('each', 'DT'),\n",
              "  ('of', 'IN'),\n",
              "  ('the', 'DT'),\n",
              "  ('below', 'NN'),\n",
              "  ('variants', 'NNS'),\n",
              "  ('add', 'VBP'),\n",
              "  ('the', 'DT'),\n",
              "  ('group', 'NN'),\n",
              "  ('of', 'IN'),\n",
              "  ('flags', 'NNS'),\n",
              "  ('to', 'TO'),\n",
              "  ('.', '.'),\n",
              "  ('third_party', 'VB'),\n",
              "  ('py', 'JJ'),\n",
              "  ('t5', 'NN'),\n",
              "  ('google', 'NN'),\n",
              "  ('scripts', 'NNS'),\n",
              "  ('run_finetune.sh', 'VBP'),\n",
              "  ('.', '.')],\n",
              " [('Deterministic', 'JJ'),\n",
              "  ('training', 'NN'),\n",
              "  ('train_gin_param', 'NN'),\n",
              "  ('mesh_train_dataset_fn.seed', 'VBD'),\n",
              "  ('SEED', 'NNP'),\n",
              "  ('train_gin_param', 'JJ'),\n",
              "  ('utils.run.skip_seen_data', 'NNS'),\n",
              "  ('True', 'NNP'),\n",
              "  ('Language', 'NNP'),\n",
              "  ('model', 'FW'),\n",
              "  ('objective', 'JJ'),\n",
              "  ('lm', 'NN'),\n",
              "  ('train_gin_param', 'NN'),\n",
              "  ('utils.run.model_type', 'JJ'),\n",
              "  ('lm', 'NN'),\n",
              "  ('Released', 'VBN'),\n",
              "  ('Model', 'NNP'),\n",
              "  ('Checkpoints', 'NNPS'),\n",
              "  ('We', 'PRP'),\n",
              "  ('have', 'VBP'),\n",
              "  ('released', 'VBN'),\n",
              "  ('the', 'DT'),\n",
              "  ('following', 'JJ'),\n",
              "  ('checkpoints', 'NNS'),\n",
              "  ('for', 'IN'),\n",
              "  ('pre', 'NN'),\n",
              "  ('trained', 'VBN'),\n",
              "  ('models', 'NNS'),\n",
              "  ('described', 'VBN'),\n",
              "  ('in', 'IN'),\n",
              "  ('our', 'PRP$'),\n",
              "  ('paper', 'NN'),\n",
              "  ('T5', 'NNP'),\n",
              "  ('Small', 'NNP'),\n",
              "  ('60', 'CD'),\n",
              "  ('million', 'CD'),\n",
              "  ('parameters', 'NNS'),\n",
              "  ('gs', 'VBP'),\n",
              "  ('t5', 'JJ'),\n",
              "  ('data', 'NNS'),\n",
              "  ('pretrained_models', 'NNS'),\n",
              "  ('small', 'JJ'),\n",
              "  ('T5', 'NNP'),\n",
              "  ('Base', 'NNP'),\n",
              "  ('220', 'CD'),\n",
              "  ('million', 'CD'),\n",
              "  ('parameters', 'NNS'),\n",
              "  ('gs', 'VBP'),\n",
              "  ('t5', 'JJ'),\n",
              "  ('data', 'NNS'),\n",
              "  ('pretrained_models', 'NNS'),\n",
              "  ('base', 'NN'),\n",
              "  ('T5', 'NNP'),\n",
              "  ('Large', 'NNP'),\n",
              "  ('770', 'CD'),\n",
              "  ('million', 'CD'),\n",
              "  ('parameters', 'NNS'),\n",
              "  ('gs', 'VBP'),\n",
              "  ('t5', 'JJ'),\n",
              "  ('data', 'NNS'),\n",
              "  ('pretrained_models', 'NNS'),\n",
              "  ('large', 'JJ'),\n",
              "  ('T5', 'NNP'),\n",
              "  ('3B', 'CD'),\n",
              "  ('3', 'CD'),\n",
              "  ('billion', 'CD'),\n",
              "  ('parameters', 'NNS'),\n",
              "  ('gs', 'VBP'),\n",
              "  ('t5', 'JJ'),\n",
              "  ('data', 'NNS'),\n",
              "  ('pretrained_models', 'NNS'),\n",
              "  ('3B', 'CD'),\n",
              "  ('T5', 'NNP'),\n",
              "  ('11B', 'CD'),\n",
              "  ('11', 'CD'),\n",
              "  ('billion', 'CD'),\n",
              "  ('parameters', 'NNS'),\n",
              "  ('gs', 'VBP'),\n",
              "  ('t5', 'JJ'),\n",
              "  ('data', 'NNS'),\n",
              "  ('pretrained_models', 'NNS'),\n",
              "  ('11B', 'CD'),\n",
              "  ('See', 'NNP'),\n",
              "  ('here', 'RB'),\n",
              "  ('for', 'IN'),\n",
              "  ('a', 'DT'),\n",
              "  ('list', 'NN'),\n",
              "  ('of', 'IN'),\n",
              "  ('additional', 'JJ'),\n",
              "  ('experimental', 'JJ'),\n",
              "  ('pre', 'NN'),\n",
              "  ('trained', 'VBD'),\n",
              "  ('model', 'NN'),\n",
              "  ('checkpoints', 'NNS'),\n",
              "  ('.', '.')],\n",
              " [('How', 'WRB'),\n",
              "  ('to', 'TO'),\n",
              "  ('Cite', 'VB'),\n",
              "  ('If', 'IN'),\n",
              "  ('you', 'PRP'),\n",
              "  ('extend', 'VBP'),\n",
              "  ('or', 'CC'),\n",
              "  ('use', 'VBP'),\n",
              "  ('this', 'DT'),\n",
              "  ('work', 'NN'),\n",
              "  ('please', 'NN'),\n",
              "  ('cite', 'VB'),\n",
              "  ('the', 'DT'),\n",
              "  ('paper', 'NN'),\n",
              "  ('where', 'WRB'),\n",
              "  ('it', 'PRP'),\n",
              "  ('was', 'VBD'),\n",
              "  ('introduced', 'VBN'),\n",
              "  ('@', 'JJ'),\n",
              "  ('article', 'NN'),\n",
              "  ('2020t5', 'CD'),\n",
              "  ('author', 'NN'),\n",
              "  ('Colin', 'NNP'),\n",
              "  ('Raffel', 'NNP'),\n",
              "  ('and', 'CC'),\n",
              "  ('Noam', 'NNP'),\n",
              "  ('Shazeer', 'NNP'),\n",
              "  ('and', 'CC'),\n",
              "  ('Adam', 'NNP'),\n",
              "  ('Roberts', 'NNP'),\n",
              "  ('and', 'CC'),\n",
              "  ('Katherine', 'NNP'),\n",
              "  ('Lee', 'NNP'),\n",
              "  ('and', 'CC'),\n",
              "  ('Sharan', 'NNP'),\n",
              "  ('Narang', 'NNP'),\n",
              "  ('and', 'CC'),\n",
              "  ('Michael', 'NNP'),\n",
              "  ('Matena', 'NNP'),\n",
              "  ('and', 'CC'),\n",
              "  ('Yanqi', 'NNP'),\n",
              "  ('Zhou', 'NNP'),\n",
              "  ('and', 'CC'),\n",
              "  ('Wei', 'NNP'),\n",
              "  ('Li', 'NNP'),\n",
              "  ('and', 'CC'),\n",
              "  ('Peter', 'NNP'),\n",
              "  ('J.', 'NNP'),\n",
              "  ('Liu', 'NNP'),\n",
              "  ('title', 'NN'),\n",
              "  ('Exploring', 'VBG'),\n",
              "  ('the', 'DT'),\n",
              "  ('Limits', 'NNS'),\n",
              "  ('of', 'IN'),\n",
              "  ('Transfer', 'NNP'),\n",
              "  ('Learning', 'NNP'),\n",
              "  ('with', 'IN'),\n",
              "  ('a', 'DT'),\n",
              "  ('Unified', 'NNP'),\n",
              "  ('Text', 'NNP'),\n",
              "  ('to', 'TO'),\n",
              "  ('Text', 'VB'),\n",
              "  ('Transformer', 'NNP'),\n",
              "  ('journal', 'JJ'),\n",
              "  ('Journal', 'NNP'),\n",
              "  ('of', 'IN'),\n",
              "  ('Machine', 'NNP'),\n",
              "  ('Learning', 'NNP'),\n",
              "  ('Research', 'NNP'),\n",
              "  ('year', 'NN'),\n",
              "  ('2020', 'CD'),\n",
              "  ('volume', 'NN'),\n",
              "  ('21', 'CD'),\n",
              "  ('number', 'NN'),\n",
              "  ('140', 'CD'),\n",
              "  ('pages', 'NNS'),\n",
              "  ('1', 'CD'),\n",
              "  ('67', 'CD'),\n",
              "  ('url', 'JJ'),\n",
              "  ('http', 'NN'),\n",
              "  ('jmlr.org', 'NN'),\n",
              "  ('papers', 'NNS'),\n",
              "  ('v21', 'VBP'),\n",
              "  ('20', 'CD'),\n",
              "  ('074.html', 'CD')]]"
            ]
          },
          "execution_count": 206,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "pos_sentences = [nltk.pos_tag(s) for s in tokenized_sent]\n",
        "pos_sentences"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hsCjFVu-vEwT"
      },
      "outputs": [],
      "source": [
        "def extract_entities(sent):\n",
        "    grammar = r\"\"\"\n",
        "    NBAR:\n",
        "        # Nouns and Adjectives, terminated with Nouns\n",
        "        {<NN.*>*<NN.*>}\n",
        "\n",
        "    NP:\n",
        "        {<NBAR>}\n",
        "        # Above, connected with in/of/etc...\n",
        "        {<NBAR><IN><NBAR>}\n",
        "    \"\"\"\n",
        "    chunker = nltk.RegexpParser(grammar)\n",
        "    ne = set()\n",
        "    chunk = chunker.parse(nltk.pos_tag(nltk.word_tokenize(sent)))\n",
        "    for tree in chunk.subtrees(filter=lambda t: t.label() == 'NP'):\n",
        "        ne.add(''.join([child[0] for child in tree.leaves()]))\n",
        "\n",
        "    return ne"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Qu7ufdpHvEwT",
        "outputId": "b14b7076-a684-449b-8219-9e1d4c0e1b06"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "100"
            ]
          },
          "execution_count": 214,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "file = [extract_entities(s) for s in sent]\n",
        "len(file)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "on5Oy49bvEwT",
        "outputId": "1c9b8306-ffc4-483a-dcd0-2bcb04d6209a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "10780"
            ]
          },
          "execution_count": 213,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "f = open('out.txt', mode='w',encoding='utf8')\n",
        "f.write(''.join(str(file)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W2_ozQJcvEwT"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "mlCJhsx8zQHm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Method 3"
      ],
      "metadata": {
        "id": "Q7m4Wk2P8REi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install git+https://github.com/LIAAD/yake"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V3OJ7mMR8Ttd",
        "outputId": "cc9d0a47-0ae7-4582-8d04-02a4a94fbeca"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting git+https://github.com/LIAAD/yake\n",
            "  Cloning https://github.com/LIAAD/yake to /tmp/pip-req-build-shzcerw5\n",
            "  Running command git clone -q https://github.com/LIAAD/yake /tmp/pip-req-build-shzcerw5\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.7/dist-packages (from yake==0.4.8) (0.8.10)\n",
            "Requirement already satisfied: click>=6.0 in /usr/local/lib/python3.7/dist-packages (from yake==0.4.8) (7.1.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from yake==0.4.8) (1.21.6)\n",
            "Collecting segtok\n",
            "  Downloading segtok-1.5.11-py3-none-any.whl (24 kB)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.7/dist-packages (from yake==0.4.8) (2.6.3)\n",
            "Collecting jellyfish\n",
            "  Downloading jellyfish-0.9.0.tar.gz (132 kB)\n",
            "\u001b[K     |████████████████████████████████| 132 kB 7.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: regex in /usr/local/lib/python3.7/dist-packages (from segtok->yake==0.4.8) (2022.6.2)\n",
            "Building wheels for collected packages: yake, jellyfish\n",
            "  Building wheel for yake (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for yake: filename=yake-0.4.8-py2.py3-none-any.whl size=62600 sha256=a635e212fc3e7b4ac3430203983c3a2b7d2f54a6e348de900ff89c96fef7e435\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-tnqv6kz4/wheels/52/79/f4/dae9309f60266aa3767a4381405002b6f2955fbcf038d804da\n",
            "  Building wheel for jellyfish (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for jellyfish: filename=jellyfish-0.9.0-cp37-cp37m-linux_x86_64.whl size=73983 sha256=d4c6ae09b476c66203b193014be76a3b97d332e677bf2d34a32027c6bf436ef5\n",
            "  Stored in directory: /root/.cache/pip/wheels/fe/99/4e/646ce766df0d070b0ef04db27aa11543e2767fda3075aec31b\n",
            "Successfully built yake jellyfish\n",
            "Installing collected packages: segtok, jellyfish, yake\n",
            "Successfully installed jellyfish-0.9.0 segtok-1.5.11 yake-0.4.8\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import yake\n",
        "kw_extractor = yake.KeywordExtractor()\n",
        "language = \"en\"\n",
        "max_ngram_size = 2\n",
        "deduplication_threshold = 0.5\n",
        "numOfKeywords = 40\n",
        "custom_kw_extractor = yake.KeywordExtractor(lan=language, n=max_ngram_size, dedupLim=deduplication_threshold, top=numOfKeywords, features=None)\n",
        "keywords = custom_kw_extractor.extract_keywords(doc)\n",
        "for kw in keywords:\n",
        "  print(kw)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hEili0tg8VL-",
        "outputId": "394802b5-c123-4c94-f3f1-6a5870932fcc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "('model', 0.004750107900258748)\n",
            "('gin', 0.006368172083336199)\n",
            "('tpu', 0.006930692942439782)\n",
            "('data', 0.0073947595640955)\n",
            "('dir', 0.008740692866710358)\n",
            "('file', 0.010142358915108266)\n",
            "('param', 0.010861867633295082)\n",
            "('tpu tpu', 0.011893383833310484)\n",
            "('project', 0.015015566552052556)\n",
            "('dir gin', 0.01550502161956351)\n",
            "('text', 0.015555035198363322)\n",
            "('zone model', 0.015655704035416513)\n",
            "('project project', 0.01692806864087311)\n",
            "('pre trained', 0.01746405821457486)\n",
            "('pre', 0.01817374786102248)\n",
            "('mesh', 0.018834202185529406)\n",
            "('operative', 0.02104007197873297)\n",
            "('zone', 0.021391360008356678)\n",
            "('fine tune', 0.021759833239032918)\n",
            "('dir data', 0.022427622414471597)\n",
            "('param utils.tpu', 0.022882561375090156)\n",
            "('transformer tpu', 0.023732458472404155)\n",
            "('checkpoint', 0.024074841860466517)\n",
            "('data experiments', 0.025490371312550154)\n",
            "('training', 0.029686764030033258)\n",
            "('tsv file', 0.030922054700451684)\n",
            "('topology tpu', 0.034162410962350294)\n",
            "('param mixture', 0.03731175301738711)\n",
            "('bucket', 0.03846781305129134)\n",
            "('tfds', 0.041574183681881136)\n",
            "('task', 0.04352469137055122)\n",
            "('tune', 0.04356348586785008)\n",
            "('tsv', 0.04524940147670431)\n",
            "('size', 0.05288915739826682)\n",
            "('set', 0.052978929724868715)\n",
            "('experiments objectives', 0.05525449380408357)\n",
            "('data source', 0.05629005998532794)\n",
            "('datasets', 0.05717033826416879)\n",
            "('text transformer', 0.05738450873944067)\n",
            "('steps', 0.05863377782295227)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers\n",
        "import transformers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ddjZQAr6_lzw",
        "outputId": "92391357-5bd4-42af-c052-1f5a2becd373"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.24.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.8.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.13.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2022.6.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.64.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.10.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.10.1)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.13.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.6)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.10.0->transformers) (4.1.1)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.9)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.10.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2022.9.24)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline\n",
        "import re\n",
        "\n",
        "# Instatiate the model from checkpoint\n",
        "model_checkpoint = \"bert-large-uncased-whole-word-masking-finetuned-squad\"\n",
        "model = pipeline(\n",
        "    'question-answering',\n",
        "    model=model_checkpoint,\n",
        "    tokenizer=model_checkpoint\n",
        ")\n",
        "\n",
        "body = '''The C4 dataset we created for unsupervised pre-training is available in TensorFlow Datasets, but it requires a significant amount of bandwidth for downloading the raw Common Crawl scrapes (~7 TB) and compute for its preparation (~335 CPU-days). We suggest you take advantage of the Apache Beam support in TFDS, which enables distributed preprocessing of the dataset and can be run on Google Cloud Dataflow. With 500 workers, the job should complete in ~16 hours.\n",
        "After defining MY_PROJECT and MY_BUCKET appropriately, you can build the dataset in DataFlow from GCP using the following commands:\n",
        "pip install tfds-nightly[c4]\n",
        "echo 'tfds-nightly[c4]' > /tmp/beam_requirements.txt\n",
        "python -m tensorflow_datasets.scripts.download_and_prepare \\\n",
        "  --datasets=c4/en \\\n",
        "  --data_dir=gs://$MY_BUCKET/tensorflow_datasets \\\n",
        "  --beam_pipeline_options=\"project=$MY_PROJECT,job_name=c4,staging_location=gs://$MY_BUCKET/binaries,temp_location=gs://$MY_BUCKET/temp,runner=DataflowRunner,requirements_file=/tmp/beam_requirements.txt,experiments=shuffle_mode=service,region=$MY_REGION\"'''\n",
        "\n",
        "questions = [\n",
        "  \"What are the commands to build the dataset?\"\n",
        "]\n",
        "\n",
        "answers = model(\n",
        "    context=body,\n",
        "    question=questions,\n",
        "    top_k=2 # Gives 2 answers per question (change it and try!)\n",
        ")\n",
        "\n",
        "# Summing scores for repeated answers\n",
        "# unique_answers = {}\n",
        "\n",
        "# for a in answers:\n",
        "#   if a[0][\"answer\"] in unique_answers:\n",
        "#     unique_answers[a[0][\"answer\"]] += a[\"score\"]\n",
        "#   else:\n",
        "#     unique_answers[a[0][\"answer\"]] = a[\"score\"]\n",
        "\n",
        "# # Converting dict to arr\n",
        "# result = [(a, s) for (a,s) in unique_answers.items()]\n",
        "\n",
        "# # Ordering by most score\n",
        "# result.sort(key=lambda tup: tup[1], reverse=True)\n",
        "\n",
        "# # Displaying result\n",
        "# print(result)"
      ],
      "metadata": {
        "id": "Wa894KxG8q1E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for a in answers:\n",
        "  print(a)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nKjSk_T4Aa-k",
        "outputId": "3136f874-b981-4edf-b51e-d27096877248"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'score': 0.10213088989257812, 'start': 595, 'end': 623, 'answer': 'pip install tfds-nightly[c4]'}\n",
            "{'score': 0.09012065827846527, 'start': 595, 'end': 619, 'answer': 'pip install tfds-nightly'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "corpus = '\\n'.join(sent)"
      ],
      "metadata": {
        "id": "jHvC0hFOAdQZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "corpus"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "id": "UO8fo7WoFuF2",
        "outputId": "d33192ef-6a2a-4d4c-e11d-b1c211f27782"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "' T5  Text To Text Transfer Transformer As of July 2022  we recommend using T5X  T5X is the new and improved implementation of T5  and more  in JAX and Flax.\\nT5 on Tensorflow with MeshTF is no longer actively developed.\\nIf you are new to T5  we recommend starting with T5X.\\nThe t5 library serves primarily as code for reproducing the experiments in Exploring the Limits of Transfer Learning with a Unified Text to Text Transformer.\\nIn the paper  we demonstrate how to achieve state of the art results on multiple NLP tasks using a text to text transformer pre trained on a large text corpus.\\nThe bulk of the code in this repository is used for loading  preprocessing  mixing  and evaluating datasets.\\nIt also provides a way to fine tune the pre trained models released alongside the publication.\\nThe t5 library can be used for future model development by providing useful modules for training and fine tuning  potentially huge  models on mixtures of text to text tasks.\\nTable of Contents  Library Usage  Dataset Preparation  C4 Installation Setting up TPUs on GCP Training Fine Tuning Eval Decode Export GPU Usage Reproducing our experiments Useful Options   Released Model Checkpoints How to Cite  Library t5.data t5.data is a package for defining Task objects that provide tf.data.Datasets.\\nEach Task is made up of   a data source text preprocessor function s  a SentencePiece model metric function s   Additionally  you may optionally provide   token preprocessor function s  postprocess function s   The data source can be an arbitrary function that provides a tf.data.Dataset  but we also provide simpler wrappers for datasets available in TensorFlow Datasets  TFDS   a TfdsTask  or stored as text files with one example per line  a TextLineTask .\\nThe text preprocessor converts the examples in the source dataset into the appropriate format for a text to text model with fields for inputs and targets.\\nFor example  the predefined t5.data.preprocessors.translate preprocessor converts inputs in the form   de    Das ist gut.\\n    en    That is good.  \\nto the form   inputs    translate German to English  Das ist gut.\\n    targets    That is good.  \\nIn addition to text preprocessing  you can also use one or more token preprocessors to modify the inputs post tokenization.\\nWe implemented our unsupervised pre training objectives using these token preprocessors.\\nWe provide many predefined preprocessors in t5.data.preprocessors  but you may also define your own.\\nThe SentencePiece model is used to tokenize the input strings and decode the output tokens.\\nYou can create your own model with the google sentencepiece library  or use our default one at t5.data.DEFAULT_SPM_PATH.\\nIf you create your own  you must use the flags   pad_id 0   eos_id 1   unk_id 2   bos_id  1 with spm_train to be compatible with our model code.\\nThe metric function returns a score given the target and prediction from the model.\\nYou may also define a postprocess function to convert the target and prediction text to another format before calling the metric.\\nWe provide some predefined metrics in t5.evaluation.metrics.\\nFinally  t5.data contains a Mixture class that can be instantiated to combine multiple Task datasets for multi task training using various functions for specifying the mixture rates.\\nt5.evaluation t5.evaluation contains two core components   metrics to be used during evaluation utilities for applying these metrics at evaluation time  t5.models t5.models contains shims for connecting T5 Tasks and Mixtures to a model implementation for training  evaluation  and inference.\\nCurrently there are two shims available  One for the Mesh TensorFlow Transformer that we used in our paper and another for the Hugging Face Transformers library.\\nThe Hugging Face API is currently experimental and subject to change  but provides a simple and easy way to load  fine tune  and evaluate our pre trained models using PyTorch on a single GPU.\\nIf you want to use our largest models on TPUs and or reproduce the results in our paper  you should use the MtfModel API and the t5_mesh_transformer binary.\\nIf you are interested fine tuning our models on a GPU in PyTorch  you should try the HfPyTorchModel API.\\nSince the HfPyTorchModel is experimental  the remainder of this README assumes usage of the MtfModel and its associated binary.\\nA usage example of HfPyTorchModel is available here.\\nUsage The easiest way to try out T5 is with a free TPU in our Colab Tutorial.\\nBelow we provide examples for how to pre train  fine tune  evaluate  and decode from a model from the command line with our codebase.\\nYou can use these instructions to reproduce our results  fine tune one of our released checkpoints with your own data and or hyperparameters  or pre train a model from scratch.\\nDataset Preparation You may either use a new or pre existing Task  or you may load examples from a preprocessed TSV file.\\nUsing a Task Depending on your data source  see above   you will need to prepare your data appropriately.\\nTask If using a vanilla task  just make sure any file s  loaded by your dataset_fn are accessible to the TPU  i.e.  are in a GCS bucket   and you should be good to go \\nTfdsTask Most of our predefined Tasks use TensorFlow Datasets  TFDS  as their data source.\\nWhen you run our training binary  see instructions below  with a TfdsTask  the dataset will automatically be downloaded and prepared on its first use.\\nAfter preparation is complete  the dataset is cached to your local storage to avoid this overhead in future runs.\\nIf working in the cloud  we recommend you set the   t5_tfds_data_dir flag to point to a persistent storage location  such as a GCS bucket.\\nThis is a requirement when training on TPU.\\nC4 The C4 dataset we created for unsupervised pre training is available in TensorFlow Datasets  but it requires a significant amount of bandwidth for downloading the raw Common Crawl scrapes   7 TB  and compute for its preparation   335 CPU days .\\nWe suggest you take advantage of the Apache Beam support in TFDS  which enables distributed preprocessing of the dataset and can be run on Google Cloud Dataflow.\\nWith 500 workers  the job should complete in  16 hours.\\nAfter defining MY_PROJECT and MY_BUCKET appropriately  you can build the dataset in DataFlow from GCP using the following commands  pip install tfds nightly c4  echo  tfds nightly c4      tmp beam_requirements.txt python  m tensorflow_datasets.scripts.download_and_prepare      datasets c4 en      data_dir gs    MY_BUCKET tensorflow_datasets      beam_pipeline_options  project  MY_PROJECT job_name c4 staging_location gs    MY_BUCKET binaries temp_location gs    MY_BUCKET temp runner DataflowRunner requirements_file  tmp beam_requirements.txt experiments shuffle_mode service region  MY_REGION  Read more in the TFDS Beam instructions.\\nTextLineTask A TextLineTask is useful when your data source is a text file  or files  with one example per line.\\nYou can then use a text preprocessor to convert each line into a dictionary of inputs and targets.\\nMake sure your files are accessible to the TPU  i.e.  are in a GCS bucket   and you should be good to go \\nUsing a TSV File Directly Instead of defining a new Task  you may use a TSV file  or files  directly as your dataset where each line is formatted as  input t target .\\nHowever  there are a couple of caveats   There is no way to define a text processor  so the TSV will need to contain your data in a preprocessed format.\\nThere is also currently no way to set a token preprocessor  postprocess function  or metric function for evaluation when using a TSV file directly.\\nIf you need any of these features  you must define a new Task  TfdsTask  or TextLineTask.\\nSimilar to the above cases  your TSV file s  must be accessible to the TPU  i.e.  are in a GCS bucket .\\nInstallation To install the T5 package  simply run  pip install t5 gcp  Setting up TPUs on GCP You will first need to launch a Virtual Machine  VM  on Google Cloud.\\nDetails about launching the VM can be found at the Google Cloud Documentation.\\nIn order to run training or eval on Cloud TPUs  you must set up the following variables based on your project  zone and GCS bucket appropriately.\\nPlease refer to the Cloud TPU Quickstart guide for more details.\\nexport PROJECT your_project_name export ZONE your_project_zone export BUCKET gs   yourbucket  export TPU_NAME t5 tpu export TPU_SIZE v3 8 export DATA_DIR    BUCKET  your_data_dir  export MODEL_DIR    BUCKET  your_model_dir  Please use the following command to create a TPU device in the Cloud VM.\\nctpu up   name  TPU_NAME   project  PROJECT   zone  ZONE   tpu size  TPU_SIZE            tpu only   noconf Training In the command below  we train a model on the GLUE Benchmark MRPC task from scratch.\\nYou can change the MIXTURE_NAME gin parameter to use any of the tasks or mixtures provided in our package.\\nt5_mesh_transformer       tpu    TPU_NAME        gcp_project    PROJECT        tpu_zone    ZONE        model_dir    MODEL_DIR        t5_tfds_data_dir    DATA_DIR        gin_file  dataset.gin       gin_file  models bi_v1.gin       gin_param  utils.tpu_mesh_shape.model_parallelism   1       gin_param  utils.tpu_mesh_shape.tpu_topology      TPU_SIZE         gin_param  MIXTURE_NAME    glue_mrpc_v002   The full list of tasks and mixtures can be obtained by running  python  c  import t5; print t5.data.MixtureRegistry.names     You may also define additional tasks and mixtures in a new file and import it using the   module_import flag.\\nAlternatively  you could train with a TSV file where each line is formatted as  input t target   see above .\\nFine tuning In order to fine tune one of our pre trained models  you need to pass the operative config of the pre trained model to the training script.\\nThe operative config should be passed in as a gin_file flag.\\nIt specifies the model architecture and other hyperparameters.\\nIn addition  you need to specify the mixture to fine tune on.\\nFor example  to fine tune the T5 small model on the glue_mrpc_v002 mixture  please run  t5_mesh_transformer       tpu    TPU_NAME        gcp_project    PROJECT        tpu_zone    ZONE        model_dir    MODEL_DIR        t5_tfds_data_dir    DATA_DIR        gin_file  dataset.gin       gin_param  utils.tpu_mesh_shape.model_parallelism   1       gin_param  utils.tpu_mesh_shape.tpu_topology      TPU_SIZE         gin_param  MIXTURE_NAME    glue_mrpc_v002        gin_file  gs   t5 data pretrained_models small operative_config.gin  The correct pre trained checkpoint path is included in the operative config.\\nYou may also define additional tasks and mixtures in a new file and import it using the   module_import flag.\\nAlternatively  you could fine tune with a TSV file where each line is formatted as  input t target   see above .\\nFor example  you could try one of the paired translation datasets from WMT  19 News Commentary 14 training set  e.g.  English French .\\nWhen using a TSV file  you would replace the MIXTURE_NAME flag with    gin_param  utils.run.train_dataset_fn   @t5.models.mesh_transformer.tsv_dataset_fn    gin_param  tsv_dataset_fn.filename    gs  path to tsv   To fine tune with the same hyperparameters we used in the paper  using a constant learning rate of 0.001   you can pass in this gin file which is included in the T5 package    gin_file  learning_rate_schedules constant_0_001.gin   The operative config for the pre trained models are set so that there is effectively no limit on the number of train steps.\\nIf you d like to train for a specific number of steps  you ll need to pass that in.\\nSince the pre trained model has already been trained for 1 000 000 steps  you should specify the total number of steps after pre training and fine tuning.\\nFor example  if you want to fine tune for an additional 10 000 steps  you should pass   gin_param  run.train_steps   1010000   You can also use a different batch size for fine tuning.\\nWe set the batch size according to the total number of tokens in a batch.\\nBy default  a batch uses a sequence length of 512.\\nTo set the number of tokens in a batch  you should set   gin_param    tokens_per_batch 1048576   Eval In order to evaluate a model in the T5 framework  you need to use the eval.gin file  specify the model directory  decoding method  and which checkpoint step s  to evaluate.\\nSo  to evaluate on the GLUE MRPC task using beam search on all checkpoints  use the following command  t5_mesh_transformer      tpu    TPU_NAME        gcp_project    PROJECT        tpu_zone    ZONE        model_dir    MODEL_DIR        gin_file    MODEL_DIR  operative_config.gin       t5_tfds_data_dir   DATA_DIR       gin_file  eval.gin       gin_file  beam_search.gin       gin_param  run.dataset_split    validation        gin_param  utils.tpu_mesh_shape.tpu_topology      TPU_SIZE         gin_param  MIXTURE_NAME    glue_mrpc_v002        gin_param  eval_checkpoint_step    all   To evaluate a specific checkpoint  simply set the eval_checkpoint_step parameter to appropriate checkpoint.\\n  gin_param  eval_checkpoint_step   100000   You can also use greedy_decode.gin or sample_decode.gin instead of beam_search.gin in the command above.\\nDecode In order to produce predictions from a model in the T5 framework  you need to specify the model directory  decoding method  and which checkpoint step s  to use for decoding.\\nAssuming you have a text file of input sequences stored at  path to intputs.txt  an example command would be  t5_mesh_transformer      tpu    TPU_NAME        gcp_project    PROJECT        tpu_zone    ZONE        model_dir    MODEL_DIR        gin_file    MODEL_DIR  operative_config.gin       gin_file  infer.gin       gin_file  sample_decode.gin       gin_param  input_filename     path to inputs.txt       gin_param  output_filename     tmp outputs.txt       gin_param  utils.tpu_mesh_shape.tpu_topology      TPU_SIZE        gin_param  infer_checkpoint_step    all   To predict with a specific checkpoint  simply set the infer_checkpoint_step parameter to appropriate checkpoint.\\n  gin_param  infer_checkpoint_step   100000   You can also use beam_search.gin or greedy_decode.gin instead of sample_decode.gin in the command above.\\nExport You may also want to export a SavedModel  which is useful for serving your trained model   e.g.  when deploying with ML Engine or in a Docker image .\\nt5_mesh_transformer      gcp_project    PROJECT        tpu_zone    ZONE        model_dir    MODEL_DIR        use_model_api      mode  export_predict       export_dir   path to export dir  The command above exports the latest checkpoint in the model directory.\\nTo export a particular checkpoint  add the following flags      checkpoint_mode  specific       checkpoint_steps 1000000 The t5 deploy notebook demonstrates exporting a SavedModel and packaging it in a Docker image for serving.\\nGPU Usage If you would like to use GPU instead of TPUs  you can modify the above commands by removing TPU specific flags    tpu    tpu_zone    gcp_project  and setting the gin params for mesh_shape and mesh_devices based on your desired setup.\\nFor example  if your machine has access to 6 GPUs and you d like to do 3 way model parallelism and 2 way data parallelism  the fine tuning command above would become  t5_mesh_transformer       model_dir    MODEL_DIR        t5_tfds_data_dir    DATA_DIR        gin_file  dataset.gin       gin_param  utils.run.mesh_shape    model 3 batch 2        gin_param  utils.run.mesh_devices     gpu 0   gpu 1   gpu 2   gpu 3   gpu 4   gpu 5         gin_param  MIXTURE_NAME    glue_mrpc_v002        gin_file  gs   t5 data pretrained_models small operative_config.gin  With a single GPU  the command is  t5_mesh_transformer       model_dir    MODEL_DIR        t5_tfds_data_dir    DATA_DIR        gin_file  dataset.gin       gin_param  utils.run.mesh_shape    model 1 batch 1        gin_param  utils.run.mesh_devices     gpu 0         gin_param  MIXTURE_NAME    glue_mrpc_v002        gin_file  gs   t5 data pretrained_models small operative_config.gin  Reproducing our experiments We provide operative configs for all of the experiments in the paper in gs   t5 data experiments.\\nThe experiments folder has different subdirectories corresponding to the different sections in our paper.\\nFor example  gs   t5 data experiments objectives contains the experiments from Section 3.3   Unsupervised objectives  .\\nEach subdirectory of the objectives folder contains operative configs for some particular experiment  where loosely speaking an  experiment  is one of the rows in one of the tables in our paper .\\nLet s say you want to reproduce the results for the  Prefix language modeling  objective  the first row in Table 4 .\\nThe operative configs for that experiment live in gs   t5 data experiments objectives obj prefix_lm.\\nIn the base directory  there is an operative config for pre training the model  gs   t5 data experiments objectives obj prefix_lm operative_config.gin .\\nThen  there are subdirectories for each of the downstream fine tuning mixtures we consider  each of which has its own operative config  for example  gs   t5 data experiments objectives obj prefix_lm cnn_dailymail_v002 operative_config.gin .\\nTo run this experiment  first pre train a model with the pre training operative config  export PRETRAIN_MODEL_DIR    BUCKET  obj prefix_lm  t5_mesh_transformer       tpu    TPU_NAME        gcp_project    PROJECT        tpu_zone    ZONE        model_dir    PRETRAIN_MODEL_DIR        gin_file  gs   t5 data experiments objectives obj prefix_lm operative_config.gin       gin_param  utils.tpu_mesh_shape.model_parallelism   1       gin_param  utils.tpu_mesh_shape.tpu_topology      TPU_SIZE    Then  you can fine tune the pre trained model on CNN Daily Mail like so  export FINETUNE_MODEL_DIR    BUCKET  obj prefix_lm cnn_dailymail_v002  t5_mesh_transformer       tpu    TPU_NAME        gcp_project    PROJECT        tpu_zone    ZONE        model_dir    FINETUNE_MODEL_DIR        gin_file  gs   t5 data experiments objectives obj prefix_lm cnn_dailymail_v002 operative_config.gin       gin_param  init_checkpoint      PRETRAIN_MODEL_DIR  model.ckpt 524288        gin_param  utils.tpu_mesh_shape.model_parallelism   1       gin_param  utils.tpu_mesh_shape.tpu_topology      TPU_SIZE    Useful Options Some training variants need multiple flags to be set at the same time.\\nFor each of the below variants  add the group of flags to . third_party py t5 google scripts run_finetune.sh.\\nDeterministic training     train_gin_param  mesh_train_dataset_fn.seed   SEED        train_gin_param  utils.run.skip_seen_data   True   Language model     objective  lm       train_gin_param  utils.run.model_type    lm    Released Model Checkpoints We have released the following checkpoints for pre trained models described in our paper   T5 Small  60 million parameters   gs   t5 data pretrained_models small T5 Base  220 million parameters   gs   t5 data pretrained_models base T5 Large  770 million parameters   gs   t5 data pretrained_models large T5 3B  3 billion parameters   gs   t5 data pretrained_models 3B T5 11B  11 billion parameters   gs   t5 data pretrained_models 11B  See here for a list of additional experimental pre trained model checkpoints.\\nHow to Cite If you extend or use this work  please cite the paper where it was introduced  @article 2020t5    author     Colin Raffel and Noam Shazeer and Adam Roberts and Katherine Lee and Sharan Narang and Michael Matena and Yanqi Zhou and Wei Li and Peter J. Liu     title      Exploring the Limits of Transfer Learning with a Unified Text to Text Transformer     journal    Journal of Machine Learning Research     year       2020     volume     21     number     140     pages      1 67     url        http   jmlr.org papers v21 20 074.html   '"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# MEthod 4\n"
      ],
      "metadata": {
        "id": "GPKeUvP_zTbs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install git+https://github.com/ramsrigouthamg/Questgen.ai\n",
        "# !pip install sense2vec==1.0.2\n",
        "# !pip install git+https://github.com/boudinfl/pke.git\n",
        "\n",
        "# !python -m nltk.downloader universal_tagset\n",
        "!python -m spacy download en"
      ],
      "metadata": {
        "id": "ghw9TGdzHUi9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "660f99ed-904c-4132-e6d3-dd2e8c32a05f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting en_core_web_sm==2.3.1\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-2.3.1/en_core_web_sm-2.3.1.tar.gz (12.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 12.0 MB 6.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: spacy<2.4.0,>=2.3.0 in /usr/local/lib/python3.7/dist-packages (from en_core_web_sm==2.3.1) (2.3.8)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.7/dist-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (1.1.3)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (2.0.7)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (1.0.9)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.7/dist-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (4.64.1)\n",
            "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (1.0.6)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (0.7.9)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.7/dist-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (2.23.0)\n",
            "Requirement already satisfied: thinc<7.5.0,>=7.4.1 in /usr/local/lib/python3.7/dist-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (7.4.6)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (3.0.8)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (57.4.0)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.7/dist-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (1.0.2)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (1.21.5)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (0.10.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (3.10.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (4.1.1)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (2022.9.24)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (1.24.3)\n",
            "Building wheels for collected packages: en-core-web-sm\n",
            "  Building wheel for en-core-web-sm (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for en-core-web-sm: filename=en_core_web_sm-2.3.1-py3-none-any.whl size=12047104 sha256=a3241afdd3839632afc9647813fe23898c1dff3a75983d91041d64f894aa8024\n",
            "  Stored in directory: /root/.cache/pip/wheels/b7/0d/f0/7ecae8427c515065d75410989e15e5785dd3975fe06e795cd9\n",
            "Successfully built en-core-web-sm\n",
            "Installing collected packages: en-core-web-sm\n",
            "  Attempting uninstall: en-core-web-sm\n",
            "    Found existing installation: en-core-web-sm 3.4.1\n",
            "    Uninstalling en-core-web-sm-3.4.1:\n",
            "      Successfully uninstalled en-core-web-sm-3.4.1\n",
            "Successfully installed en-core-web-sm-2.3.1\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the model via spacy.load('en_core_web_sm')\n",
            "\u001b[38;5;2m✔ Linking successful\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/en_core_web_sm -->\n",
            "/usr/local/lib/python3.7/dist-packages/spacy/data/en\n",
            "You can now load the model via spacy.load('en')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://github.com/explosion/sense2vec/releases/download/v1.0.0/s2v_reddit_2015_md.tar.gz\n",
        "!tar -xvf  s2v_reddit_2015_md.tar.gz\n",
        "!ls s2v_old"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VZLcwzgpzSwU",
        "outputId": "83abb7f6-ed42-46e9-9791-84048e940a9f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-11-22 19:29:25--  https://github.com/explosion/sense2vec/releases/download/v1.0.0/s2v_reddit_2015_md.tar.gz\n",
            "Resolving github.com (github.com)... 20.205.243.166\n",
            "Connecting to github.com (github.com)|20.205.243.166|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://objects.githubusercontent.com/github-production-release-asset-2e65be/50261113/52126080-0993-11ea-8190-8f0e295df22a?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20221122%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20221122T192925Z&X-Amz-Expires=300&X-Amz-Signature=ab108c89426f61e77275283499f8d32d2dceede1818f7be025d778746979e71d&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=50261113&response-content-disposition=attachment%3B%20filename%3Ds2v_reddit_2015_md.tar.gz&response-content-type=application%2Foctet-stream [following]\n",
            "--2022-11-22 19:29:26--  https://objects.githubusercontent.com/github-production-release-asset-2e65be/50261113/52126080-0993-11ea-8190-8f0e295df22a?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20221122%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20221122T192925Z&X-Amz-Expires=300&X-Amz-Signature=ab108c89426f61e77275283499f8d32d2dceede1818f7be025d778746979e71d&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=50261113&response-content-disposition=attachment%3B%20filename%3Ds2v_reddit_2015_md.tar.gz&response-content-type=application%2Foctet-stream\n",
            "Resolving objects.githubusercontent.com (objects.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to objects.githubusercontent.com (objects.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 600444501 (573M) [application/octet-stream]\n",
            "Saving to: ‘s2v_reddit_2015_md.tar.gz’\n",
            "\n",
            "s2v_reddit_2015_md. 100%[===================>] 572.63M  5.98MB/s    in 2m 22s  \n",
            "\n",
            "2022-11-22 19:31:48 (4.04 MB/s) - ‘s2v_reddit_2015_md.tar.gz’ saved [600444501/600444501]\n",
            "\n",
            "./._s2v_old\n",
            "./s2v_old/\n",
            "./s2v_old/._freqs.json\n",
            "./s2v_old/freqs.json\n",
            "./s2v_old/._vectors\n",
            "./s2v_old/vectors\n",
            "./s2v_old/._cfg\n",
            "./s2v_old/cfg\n",
            "./s2v_old/._strings.json\n",
            "./s2v_old/strings.json\n",
            "./s2v_old/._key2row\n",
            "./s2v_old/key2row\n",
            "cfg  freqs.json  key2row  strings.json\tvectors\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pprint import pprint\n",
        "from Questgen import main\n",
        "qe= main.BoolQGen()\n",
        "payload = {\n",
        "            \"input_text\": \"T5 is an encoder-decoder model and converts all NLP problems into a text-to-text format. It is trained using teacher forcing. This means that for training, we always need an input sequence and a corresponding target sequence. The input sequence is fed to the model using input_ids. The target sequence is shifted to the right, i.e., prepended by a start-sequence token and fed to the decoder using the decoder_input_ids. In teacher-forcing style, the target sequence is then appended by the EOS token and corresponds to the labels. The PAD token is hereby used as the start-sequence token. T5 can be trained / fine-tuned both in a supervised and unsupervised fashion.\"\n",
        "        }\n",
        "output = qe.predict_boolq(payload)\n",
        "pprint (output)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VgG0UuKV05A_",
        "outputId": "fecfbbae-58fb-42d2-e27a-a89346271d1b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'Boolean Questions': ['Is t5 encoder and decoder the same?',\n",
            "                       'Is the encoder and decoder the same thing?',\n",
            "                       'Is t5 an encoder and decoder model?'],\n",
            " 'Count': 4,\n",
            " 'Text': 'T5 is an encoder-decoder model and converts all NLP problems into a '\n",
            "         'text-to-text format. It is trained using teacher forcing. This means '\n",
            "         'that for training, we always need an input sequence and a '\n",
            "         'corresponding target sequence. The input sequence is fed to the '\n",
            "         'model using input_ids. The target sequence is shifted to the right, '\n",
            "         'i.e., prepended by a start-sequence token and fed to the decoder '\n",
            "         'using the decoder_input_ids. In teacher-forcing style, the target '\n",
            "         'sequence is then appended by the EOS token and corresponds to the '\n",
            "         'labels. The PAD token is hereby used as the start-sequence token. T5 '\n",
            "         'can be trained / fine-tuned both in a supervised and unsupervised '\n",
            "         'fashion.'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "payload = {\n",
        "            \"input_text\": '''T5 is an encoder-decoder model and converts all NLP problems into a text-to-text format.\n",
        "            It is trained using teacher forcing. This means that for training, we always need an input sequence and a corresponding target sequence.\n",
        "            The input sequence is fed to the model using input_ids. The target sequence is shifted to the right, i.e., prepended by a start-sequence token and fed to the decoder using the decoder_input_ids.\n",
        "            In teacher-forcing style, the target sequence is then appended by the EOS token and corresponds to the labels.\n",
        "            The PAD token is hereby used as the start-sequence token. T5 can be trained / fine-tuned both in a supervised and unsupervised fashion.'''\n",
        "        }\n",
        "output = qe.predict_boolq(payload)\n",
        "pprint (output)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NcDs88qv14sW",
        "outputId": "eab270f8-15e9-4cb2-9c4f-662a32307220"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'Boolean Questions': ['Is the encoder and decoder the same thing?',\n",
            "                       'Is t5 encoder and decoder the same?',\n",
            "                       'Is t5 an encoder and decoder model?'],\n",
            " 'Count': 4,\n",
            " 'Text': 'T5 is an encoder-decoder model and converts all NLP problems into a '\n",
            "         'text-to-text format. It is trained using teacher forcing. This means '\n",
            "         'that for training, we always need an input sequence and a '\n",
            "         'corresponding target sequence. The input sequence is fed to the '\n",
            "         'model using input_ids. The target sequence is shifted to the right, '\n",
            "         'i.e., prepended by a start-sequence token and fed to the decoder '\n",
            "         'using the decoder_input_ids. In teacher-forcing style, the target '\n",
            "         'sequence is then appended by the EOS token and corresponds to the '\n",
            "         'labels. The PAD token is hereby used as the start-sequence token. T5 '\n",
            "         'can be trained / fine-tuned both in a supervised and unsupervised '\n",
            "         'fashion.'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "qg = main.QGen()\n",
        "output = qg.predict_mcq(payload)\n",
        "pprint (output)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 346
        },
        "id": "_wfoaABf2uVQ",
        "outputId": "8390157b-87aa-436e-e7da-e4c9381caf53"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-9-1ba2426fbc5d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mqg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mQGen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mqg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_mcq\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpayload\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mpprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/Questgen/main.py\u001b[0m in \u001b[0;36mpredict_mcq\u001b[0;34m(self, payload)\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 74\u001b[0;31m         \u001b[0mkeywords\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_keywords\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnlp\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmodified_text\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0minp\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'max_questions'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0ms2v\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfdist\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormalized_levenshtein\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentences\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/Questgen/mcq/mcq.py\u001b[0m in \u001b[0;36mget_keywords\u001b[0;34m(nlp, text, max_keywords, s2v, fdist, normalized_levenshtein, no_of_sentences)\u001b[0m\n\u001b[1;32m    193\u001b[0m     \u001b[0mmax_keywords\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_keywords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    194\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 195\u001b[0;31m     \u001b[0mkeywords\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_nouns_multipartite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    196\u001b[0m     \u001b[0mkeywords\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeywords\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mfdist\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    197\u001b[0m     \u001b[0mkeywords\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfilter_phrases\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeywords\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_keywords\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnormalized_levenshtein\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/Questgen/mcq/mcq.py\u001b[0m in \u001b[0;36mget_nouns_multipartite\u001b[0;34m(text)\u001b[0m\n\u001b[1;32m    148\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0mextractor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpke\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsupervised\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMultipartiteRank\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m     \u001b[0mextractor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_document\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlanguage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'en'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0mpos\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'PROPN'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'NOUN'\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m     \u001b[0mstoplist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstring\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpunctuation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pke/base.py\u001b[0m in \u001b[0;36mload_document\u001b[0;34m(self, input, language, stoplist, normalization, spacy_model)\u001b[0m\n\u001b[1;32m     91\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m             \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRawTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlanguage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlanguage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 93\u001b[0;31m             \u001b[0msents\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mspacy_model\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mspacy_model\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     94\u001b[0m         \u001b[0;31m# check whether input is processed text\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mitem\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pke/readers.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, text, spacy_model)\u001b[0m\n\u001b[1;32m     76\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m             \u001b[0;31m# list installed models\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 78\u001b[0;31m             \u001b[0minstalled_models\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mm\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mm\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mspacy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_installed_models\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mm\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlanguage\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     79\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m             \u001b[0;31m# select first model for the language\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: module 'spacy.util' has no attribute 'get_installed_models'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "output = qg.predict_shortq(payload)\n",
        "pprint (output)"
      ],
      "metadata": {
        "id": "UC4rRA9o29uO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "aPd4Jvri3QWd"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3.9.12 ('nlp_env')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    },
    "orig_nbformat": 4,
    "vscode": {
      "interpreter": {
        "hash": "f029acb2f711f49d28553c1aa8ebd2978f943b3ff65a617c18c09b0c99b838a0"
      }
    },
    "colab": {
      "provenance": []
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}